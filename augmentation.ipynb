{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdbJEvG_OyVI",
        "outputId": "0390816d-5f5d-44f5-d6bf-e5ab2b659f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Prostate_MRI_Detection_3D_Model\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Prostate_MRI_Detection_3D_Model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7Bdt8J7TOxAw"
      },
      "outputs": [],
      "source": [
        "HOME_DIR =       \"./\"\n",
        "DATA_DIR =       \"./PROSTATEx_masks/Files/prostate/\"\n",
        "OUT_DIR =        \"./aug_results/prostate/\"\n",
        "SLICED_OUT_DIR = \"./data/sliced/prostate/\"\n",
        "AUG_OUT_DIR = \"./data/augmented_test/prostate/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP-vOXehpNzs",
        "outputId": "bcbd8aa2-8c7c-4bc8-bb9c-dd49934689b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r requirement.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r requirement.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from -r requirement.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from -r requirement.txt (line 4)) (7.7.1)\n",
            "Collecting elasticdeform\n",
            "  Downloading elasticdeform-0.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.3/91.3 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from -r requirement.txt (line 6)) (0.19.3)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirement.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirement.txt (line 1)) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas->-r requirement.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (4.39.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r requirement.txt (line 3)) (8.4.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (5.3.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (3.6.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r requirement.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from elasticdeform->-r requirement.txt (line 5)) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirement.txt (line 6)) (3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirement.txt (line 6)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirement.txt (line 6)) (2023.3.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->-r requirement.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics->-r requirement.txt (line 7)) (1.13.1+cu116)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->-r requirement.txt (line 3)) (3.15.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirement.txt (line 4)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r requirement.txt (line 4)) (6.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (67.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirement.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics->-r requirement.txt (line 7)) (4.5.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (6.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (0.8.3)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (21.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (5.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (6.5.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.17.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (5.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets->-r requirement.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (2.1.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (4.11.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (4.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirement.txt (line 4)) (2.21)\n",
            "Installing collected packages: jedi, torchmetrics, elasticdeform\n",
            "Successfully installed elasticdeform-0.5.0 jedi-0.18.2 torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqz-yLPCt7Fi",
        "outputId": "7239ec6f-63b4-46cb-e013-9e23fa386da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting monai\n",
            "  Downloading monai-1.1.0-202212191849-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.9/dist-packages (from monai) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from monai) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->monai) (4.5.0)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbW2jfHvuAZ0",
        "outputId": "2a9927fd-0a90-4582-f34a-4facfad89f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dicom2nifti\n",
            "  Downloading dicom2nifti-2.4.8-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m602.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydicom>=2.2.0\n",
            "  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-gdcm\n",
            "  Downloading python_gdcm-3.0.21-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.9/dist-packages (from dicom2nifti) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from dicom2nifti) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from dicom2nifti) (1.10.1)\n",
            "Installing collected packages: python-gdcm, pydicom, dicom2nifti\n",
            "Successfully installed dicom2nifti-2.4.8 pydicom-2.3.1 python-gdcm-3.0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install dicom2nifti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I5cxT2kOOxAz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import dicom2nifti\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
        "import os\n",
        "\n",
        "from monai.utils import first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IORwwTsBOxA2"
      },
      "outputs": [],
      "source": [
        "def get_data_path(path):\n",
        "  f = open( path + 'config.json')\n",
        "  jdata = json.load(f)\n",
        "  f.close()\n",
        "  return jdata[\"path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4rWc4SbgvPsF"
      },
      "outputs": [],
      "source": [
        "# create directries if does not exist\n",
        "if not os.path.exists(SLICED_OUT_DIR):\n",
        "    os.makedirs(SLICED_OUT_DIR)\n",
        "if not os.path.exists(SLICED_OUT_DIR + \"Images\"):\n",
        "    os.makedirs(SLICED_OUT_DIR + \"Images\")\n",
        "if not os.path.exists(SLICED_OUT_DIR + \"mask_prostate\"):\n",
        "    os.makedirs(SLICED_OUT_DIR + \"mask_prostate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTdrMrPBvbJu"
      },
      "outputs": [],
      "source": [
        "def makeLabelNo(name):\n",
        "  numb= name.split(\"-\")[1]\n",
        "  li=[80,81,83,85,86,87,88,89,90,91,93,96,98,125,127]\n",
        "  if(int(numb) in li):\n",
        "    return 'ProstateX-' + numb[1:]\n",
        "  return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2rUcFgGvj7n"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATA_DIR +'image_list.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HoTmTwyvfQe"
      },
      "outputs": [],
      "source": [
        "data = [{'image': DATA_DIR + 'Images/' + x + \".nii.gz\", \"label\":DATA_DIR + 'mask_prostate/' + makeLabelNo(x.split(\"_\")[0]) + \".nii.gz\"  } for x in df['T2']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzlMEqIKvnzV"
      },
      "outputs": [],
      "source": [
        "slice_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FVC_p72vTHz",
        "outputId": "2626b600-a23f-4ca8-8694-d1a2f46ac70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/204\n",
            "2/204\n",
            "3/204\n",
            "4/204\n",
            "5/204\n",
            "6/204\n",
            "7/204\n",
            "8/204\n",
            "9/204\n",
            "10/204\n",
            "11/204\n",
            "12/204\n",
            "13/204\n",
            "14/204\n",
            "15/204\n",
            "16/204\n",
            "17/204\n",
            "18/204\n",
            "19/204\n",
            "20/204\n",
            "21/204\n",
            "22/204\n",
            "23/204\n",
            "24/204\n",
            "25/204\n",
            "26/204\n",
            "27/204\n",
            "28/204\n",
            "29/204\n",
            "30/204\n",
            "31/204\n",
            "32/204\n",
            "33/204\n",
            "34/204\n",
            "35/204\n",
            "36/204\n",
            "37/204\n",
            "38/204\n",
            "39/204\n",
            "40/204\n",
            "41/204\n",
            "42/204\n",
            "43/204\n",
            "44/204\n",
            "45/204\n",
            "46/204\n",
            "47/204\n",
            "48/204\n",
            "49/204\n",
            "50/204\n",
            "51/204\n",
            "52/204\n",
            "53/204\n",
            "54/204\n",
            "55/204\n",
            "56/204\n",
            "57/204\n",
            "58/204\n",
            "59/204\n",
            "60/204\n",
            "61/204\n",
            "62/204\n",
            "63/204\n",
            "64/204\n",
            "65/204\n",
            "66/204\n",
            "67/204\n",
            "68/204\n",
            "69/204\n",
            "70/204\n",
            "71/204\n",
            "72/204\n",
            "73/204\n",
            "74/204\n",
            "75/204\n",
            "76/204\n",
            "77/204\n",
            "78/204\n",
            "79/204\n",
            "80/204\n",
            "81/204\n",
            "82/204\n",
            "83/204\n",
            "84/204\n",
            "85/204\n",
            "86/204\n",
            "87/204\n",
            "88/204\n",
            "89/204\n",
            "90/204\n",
            "91/204\n",
            "92/204\n",
            "93/204\n",
            "94/204\n",
            "95/204\n",
            "96/204\n",
            "97/204\n",
            "98/204\n",
            "99/204\n",
            "100/204\n",
            "101/204\n",
            "102/204\n",
            "103/204\n",
            "104/204\n",
            "105/204\n",
            "106/204\n",
            "107/204\n",
            "108/204\n",
            "109/204\n",
            "110/204\n",
            "111/204\n",
            "112/204\n",
            "113/204\n",
            "114/204\n",
            "115/204\n",
            "116/204\n",
            "117/204\n",
            "118/204\n",
            "119/204\n",
            "120/204\n",
            "121/204\n",
            "122/204\n",
            "123/204\n",
            "124/204\n",
            "125/204\n",
            "126/204\n",
            "127/204\n",
            "128/204\n",
            "129/204\n",
            "130/204\n",
            "131/204\n",
            "132/204\n",
            "133/204\n",
            "134/204\n",
            "135/204\n",
            "136/204\n",
            "137/204\n",
            "138/204\n",
            "139/204\n",
            "140/204\n",
            "141/204\n",
            "142/204\n",
            "143/204\n",
            "144/204\n",
            "145/204\n",
            "146/204\n",
            "147/204\n",
            "148/204\n",
            "149/204\n",
            "150/204\n",
            "151/204\n",
            "152/204\n",
            "153/204\n",
            "154/204\n",
            "155/204\n",
            "156/204\n",
            "157/204\n",
            "158/204\n",
            "159/204\n",
            "160/204\n",
            "161/204\n",
            "162/204\n",
            "163/204\n",
            "164/204\n",
            "165/204\n",
            "166/204\n",
            "167/204\n",
            "168/204\n",
            "169/204\n",
            "170/204\n",
            "171/204\n",
            "172/204\n",
            "173/204\n",
            "174/204\n",
            "175/204\n",
            "176/204\n",
            "177/204\n",
            "178/204\n",
            "179/204\n",
            "180/204\n",
            "181/204\n",
            "182/204\n",
            "183/204\n",
            "184/204\n",
            "185/204\n",
            "186/204\n",
            "187/204\n",
            "188/204\n",
            "189/204\n",
            "190/204\n",
            "191/204\n",
            "192/204\n",
            "193/204\n",
            "194/204\n",
            "195/204\n",
            "196/204\n",
            "197/204\n",
            "198/204\n",
            "199/204\n",
            "200/204\n",
            "201/204\n",
            "202/204\n",
            "203/204\n",
            "204/204\n"
          ]
        }
      ],
      "source": [
        "from utils.preprocessing import create_same_slice_nifti\n",
        "\n",
        "create_same_slice_nifti(data, slice_size, SLICED_OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bACxpGFCOxA4"
      },
      "outputs": [],
      "source": [
        "data = get_data_path(SLICED_OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptX2xP6jxJSG",
        "outputId": "88fb300a-48c4-460f-e34b-5d9c64340a58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirement.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBu_yD8MOxA5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import nibabel as nib\n",
        "\n",
        "import elasticdeform \n",
        "from skimage.util import random_noise\n",
        "import scipy\n",
        "from scipy.ndimage import affine_transform\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "import nibabel as nib\n",
        "#import torchio as tio\n",
        "\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import shift\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWkXqKQvOxA6"
      },
      "outputs": [],
      "source": [
        "def hFlipRotate(image, label):\n",
        "    angle =  random.uniform(-5, 5)\n",
        "    imgvol = np.array( image.dataobj )\n",
        "    lblvol = np.array( label.dataobj )\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(imgvol)\n",
        "    lbl = np.fliplr(lblvol)\n",
        "    \n",
        "    #Rotate\n",
        "    img = ndimage.rotate(img, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
        "    \n",
        "    image = nib.Nifti1Image ( img, image.affine )\n",
        "    label = nib.Nifti1Image ( lbl, label.affine )\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqIaVJ7DOxA7"
      },
      "outputs": [],
      "source": [
        "def hFlipRotateZoom(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(img)\n",
        "    lbl = np.fliplr(lbl)\n",
        "\n",
        "    # zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    zoomed_img = ndimage.zoom(img, zoom_factor, order=1)\n",
        "    zoomed_lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(zoomed_img, image.affine)\n",
        "    label = nib.Nifti1Image(zoomed_lbl, label.affine)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VJn1xRsOxA9"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "def hFlipShear(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    shear = random.uniform(-0.2,0.2)\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(imgvol)\n",
        "    lbl = np.fliplr(lblvol)\n",
        "\n",
        "    # apply shear transformation\n",
        "    matrix = np.array([[1, shear, 0], [0, 1, 0], [0, 0, 1]])\n",
        "    img = scipy.ndimage.affine_transform(img, matrix)\n",
        "    lbl = scipy.ndimage.affine_transform(lbl, matrix)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUbXNpaEOxA-"
      },
      "outputs": [],
      "source": [
        "def random_flip_rotate_noise(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes\n",
        "    flip_axes = tuple(np.random.choice([-1, 1], size=image.ndim, replace=True))\n",
        "    img = np.flip(imgvol, axis=flip_axes)\n",
        "    lbl = np.flip(lblvol, axis=flip_axes)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
        "\n",
        "    # Add noise\n",
        "    # Gaussian noise\n",
        "    img = random_noise(img, mode='gaussian', var=0.000001, clip=False)\n",
        "    # Salt & Pepper noise\n",
        "    img = random_noise(img, mode='s&p', salt_vs_pepper=0.5, amount=0.0000005, clip=False)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jLbdMK0OxA_"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy.ndimage import affine_transform\n",
        "\n",
        "def hFlipShearTrans(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    shear = random.uniform(-0.2,0.2)\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10), random.uniform(-10,10))\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(imgvol)\n",
        "    lbl = np.fliplr(lblvol)\n",
        "\n",
        "    # apply shear transformation\n",
        "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, translate[2]], [0, 0, 0, 1]])\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTZn7biqOxBA"
      },
      "outputs": [],
      "source": [
        "def hFlipRotateNoise(image, label):\n",
        "    angle =  random.uniform(-5, 5)\n",
        "    imgvol = np.array( image.dataobj )\n",
        "    lblvol = np.array( label.dataobj )\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(imgvol)\n",
        "    lbl = np.fliplr(lblvol)\n",
        "    \n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
        "    \n",
        "    # Noise\n",
        "    # # Gaussian noise\n",
        "    # img = random_noise(imgvol, mode='gaussian', var=0.0000001, clip=False)\n",
        "    # # Salt & Pepper noise\n",
        "    # img = random_noise(img, mode='s&p',salt_vs_pepper=0.5, amount=0.00000005, clip=False)\n",
        "\n",
        "\n",
        "    \n",
        "    image = nib.Nifti1Image ( img, image.affine )\n",
        "    label = nib.Nifti1Image ( lblvol, label.affine )\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0BjXS5NOxBC"
      },
      "outputs": [],
      "source": [
        "def random_flip_rotate_zoom_translate(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
        "    img = np.flip(img, axis=flip_axes)\n",
        "    lbl = np.flip(lbl, axis=flip_axes)\n",
        "\n",
        "    # zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
        "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    # Translate\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKz-gda1OxBD"
      },
      "outputs": [],
      "source": [
        "def random_flip_rotate_zoom_shear_translate(image, label):\n",
        "    \n",
        "    angle = random.uniform(-5, 5)\n",
        "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "    shear = random.uniform(-0.2,0.2)\n",
        "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
        "    \n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
        "    img = np.flip(img, axis=flip_axes)\n",
        "    lbl = np.flip(lbl, axis=flip_axes)\n",
        "\n",
        "    # zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
        "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    # Translate\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq3vouS2OxBE"
      },
      "outputs": [],
      "source": [
        "def random_flip_rotate_translate_deform(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
        "    sigma = random.choice([2, 3])\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
        "    img = np.flip(img, axis=flip_axes)\n",
        "    lbl = np.flip(lbl, axis=flip_axes)\n",
        "\n",
        "    # zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
        "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    # Elastic deformation\n",
        "    [img, lbl] = elasticdeform.deform_random_grid([img, lbl], sigma=sigma, axis=[(0, 1), (0, 1)], order=[1, 0], mode='constant')\n",
        "    \n",
        "\n",
        "\n",
        "    # Translate\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8h7c3XaOxBE"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "from skimage.exposure import adjust_gamma, rescale_intensity\n",
        "\n",
        "def random_flip_rotate_zoom_translate_brightness(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    flip_axes = [i for i in range(2) if i != 2 and np.random.choice([0, 1]) == 1]\n",
        "    translate = (random.uniform(-10, 10), random.uniform(-10, 10))\n",
        "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
        "    img = np.flip(img, axis=flip_axes)\n",
        "    lbl = np.flip(lbl, axis=flip_axes)\n",
        "\n",
        "    # Zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
        "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    # Translate\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    # Brightness\n",
        "    gamma = random.uniform(0.8, 1.2)\n",
        "    min_value = np.min(img)\n",
        "    img = img - min_value\n",
        "    img = adjust_gamma(img, gamma)\n",
        "\n",
        "    # Contrast\n",
        "    low = np.percentile(img, 10)\n",
        "    high = np.percentile(img, 98)\n",
        "    img = rescale_intensity(img, in_range=(low, high))\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5qDOzLrOxBF"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy.ndimage import affine_transform\n",
        "\n",
        "def hFlipRotateShearTrans(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    shear = random.uniform(-0.2,0.2)\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(img)\n",
        "    lbl = np.fliplr(lbl)\n",
        "\n",
        "\n",
        "    # apply shear transformation\n",
        "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC9PnHwrOxBF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import random\n",
        "import elasticdeform\n",
        "from scipy import ndimage\n",
        "\n",
        "def hFlipRotateTranslateElasticDeform(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    shear = random.uniform(-0.2,0.2)\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
        "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # horizontal flip\n",
        "    img = np.fliplr(img)\n",
        "    lbl = np.fliplr(lbl)\n",
        "\n",
        "\n",
        "    # apply shear transformation\n",
        "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
        "    img = affine_transform(img, matrix, order=1)\n",
        "    lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    # Elastic deformation\n",
        "    sigma = random.choice([2, 3])\n",
        "    print(sigma)\n",
        "    # img_deformed = elasticdeform.deform_random_grid(img, sigma=sigma, order=3, axis=(0, 1, 2))\n",
        "    # lbl_deformed = elasticdeform.deform_random_grid(lbl, sigma=sigma, order=0, axis=(0, 1, 2))\n",
        "    [img_deformed, lbl_deformed] = elasticdeform.deform_random_grid([img, lbl], sigma=sigma, axis=[(0, 1), (0, 1)], order=[1, 0], mode='constant')\n",
        "    \n",
        "\n",
        "    image = nib.Nifti1Image(img_deformed, image.affine)\n",
        "    label = nib.Nifti1Image(lbl_deformed, label.affine)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jg4xLPTOxBG"
      },
      "outputs": [],
      "source": [
        "from Augmentation.augmentation import changeContrast, vFlipRotate, hFlipRotate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlP-eVU9OxBH"
      },
      "outputs": [],
      "source": [
        "# first image, label from orignal image\n",
        "imagea =nib.load(data[0][\"image\"])\n",
        "labela =nib.load(data[0][\"label\"])\n",
        "\n",
        "imagea, labela = imagea.get_fdata(), labela.get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvaME2OXOxBH",
        "outputId": "c46aac5d-b6f8-4773-813e-70d75f3a6187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(384, 384, 16) (384, 384, 16)\n"
          ]
        }
      ],
      "source": [
        "# first image, label from orignal image\n",
        "imagea =nib.load(data[0][\"image\"])\n",
        "labela =nib.load(data[0][\"label\"])\n",
        "print(imagea.shape,labela.shape)\n",
        "imagea, labela = random_flip_rotate_zoom_translate_brightness(imagea, labela)\n",
        "imagea, labela = imagea.get_fdata(), labela.get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZVlM-JkOxBI"
      },
      "outputs": [],
      "source": [
        "# Define a function to visualize the data\n",
        "def explore_3dimage(layer):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    channel = 2\n",
        "    # plt.imshow(image11[0,0,:,:,layer], cmap='gray');\n",
        "    # plt.title('Explore Layers of Prostate MRI', fontsize=20)\n",
        "    # plt.axis('off')\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
        "\n",
        "    ax[0].imshow(imagea[:,:,layer], cmap='gray')\n",
        "    ax[0].set_title(f\"Image\", fontsize=15)\n",
        "    ax[0].axis('off');\n",
        "\n",
        "    ax[1].imshow(labela[:,:,layer])\n",
        "    ax[1].axis('off');\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "dbf88925314f48e285bfda6128cf58e7"
          ]
        },
        "id": "QAy_DnWsOxBI",
        "outputId": "74a12e96-a46d-476e-8153-59f922b0571c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbf88925314f48e285bfda6128cf58e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=7, description='layer', max=15), Output()), _dom_classes=('widget-intera…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<function __main__.explore_3dimage(layer)>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Explore the preprocessed image, label\n",
        "interact(explore_3dimage, layer=(0, 15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEJRBuDIOxBJ"
      },
      "outputs": [],
      "source": [
        "# first image, label from orignal image\n",
        "image =nib.load(data[0][\"image\"])\n",
        "label =nib.load(data[0][\"label\"])\n",
        "\n",
        "image, label = image.get_fdata(), label.get_fdata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GnWb3ePOxBJ"
      },
      "outputs": [],
      "source": [
        "# Define a function to visualize the data\n",
        "def explore_3dimage(layer):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    channel = 2\n",
        "    # plt.imshow(image11[0,0,:,:,layer], cmap='gray');\n",
        "    # plt.title('Explore Layers of Prostate MRI', fontsize=20)\n",
        "    # plt.axis('off')\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
        "\n",
        "    ax[0].imshow(image[:,:,layer], cmap='gray')\n",
        "    ax[0].set_title(f\"Image\", fontsize=15)\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].imshow(label[:,:,layer])\n",
        "    ax[1].axis('off')\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b0034d68d18f42a79dad9485eeca7d54"
          ]
        },
        "id": "KznrjqkhOxBK",
        "outputId": "a60f4775-9310-4055-d319-1054aa7c3127"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0034d68d18f42a79dad9485eeca7d54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=7, description='layer', max=15), Output()), _dom_classes=('widget-intera…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<function __main__.explore_3dimage(layer)>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Explore the preprocessed image, label\n",
        "interact(explore_3dimage, layer=(0, 15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px0x-18mOxBL"
      },
      "outputs": [],
      "source": [
        "data = data[:16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPb4-C3SOxBL"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import random\n",
        "import elasticdeform \n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "from scipy.ndimage import affine_transform, rotate, zoom\n",
        "from skimage.exposure import adjust_gamma, rescale_intensity\n",
        "from skimage.util import random_noise\n",
        "\n",
        "\n",
        "def random_flip_rotate_zoom(image, label):\n",
        "    angle = random.uniform(-5, 5)\n",
        "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
        "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
        "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
        "\n",
        "    imgvol = np.array(image.dataobj)\n",
        "    lblvol = np.array(label.dataobj)\n",
        "\n",
        "    # Rotate\n",
        "    img = rotate(imgvol, angle, reshape=False)\n",
        "    lbl = rotate(lblvol, angle, reshape=False)\n",
        "\n",
        "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
        "    img = np.flip(img, axis=flip_axes)\n",
        "    lbl = np.flip(lbl, axis=flip_axes)\n",
        "\n",
        "    # zoom\n",
        "    zoom_factor = random.uniform(0.8, 1.2)\n",
        "    img = zoom(img, zoom_factor, order=1)\n",
        "    lbl = zoom(lbl, zoom_factor, order=0)\n",
        "\n",
        "    # # Translate\n",
        "    # img = affine_transform(img, matrix, order=1)\n",
        "    # lbl = affine_transform(lbl, matrix, order=0)\n",
        "\n",
        "    image = nib.Nifti1Image(img, image.affine)\n",
        "    label = nib.Nifti1Image(lbl, label.affine)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amqdy0IxOxBL"
      },
      "outputs": [],
      "source": [
        "from Augmentation.augmentation import rotate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30B5eWNrOxBL"
      },
      "outputs": [],
      "source": [
        "from Augmentation.combine_augmentation import random_flip_rotate_zoom_translate, random_flip_rotate_zoom_shear_translate, random_flip_rotate_translate_deform, random_flip_rotate_zoom_translate_brightness, random_flip_rotate_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-kx-gloOxBM"
      },
      "outputs": [],
      "source": [
        "data = get_data_path(SLICED_OUT_DIR)\n",
        "data = data[:16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBNAmMr8OxBN"
      },
      "outputs": [],
      "source": [
        "types = {  'FRZT' :  random_flip_rotate_zoom_translate }\n",
        "\n",
        "for type,func in types.items():\n",
        "    # create directries if does not exist\n",
        "    if not os.path.exists(AUG_OUT_DIR + type ):\n",
        "        os.makedirs(AUG_OUT_DIR + type)\n",
        "    if not os.path.exists(AUG_OUT_DIR + type + \"/Images\"):\n",
        "        os.makedirs(AUG_OUT_DIR + type + \"/Images\")\n",
        "    if not os.path.exists(AUG_OUT_DIR + type + \"/mask_prostate\"):\n",
        "        os.makedirs(AUG_OUT_DIR + type + \"/mask_prostate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59HvjqFOOxBN"
      },
      "outputs": [],
      "source": [
        "from utils.preprocessing import load_nifti\n",
        "\n",
        "def augment(func, entry, name, paths):\n",
        "    img, lbl = load_nifti(entry[\"image\"], entry[\"label\"])\n",
        "    \n",
        "    image, label = func(img, lbl)\n",
        "    image_path = entry[\"image\"].replace(\"data/sliced/prostate\", \"data/augmented_test/prostate/\" + name)\n",
        "    label_path = entry[\"label\"].replace(\"data/sliced/prostate\", \"data/augmented_test/prostate/\" + name)\n",
        "    paths.append({\"image\":image_path, \"label\":label_path})\n",
        "    image.to_filename(image_path )\n",
        "    label.to_filename(label_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fPWF0abOxBO",
        "outputId": "97e5badc-5260-4284-adb6-bc443bf0d98f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVU6ht1nOxBP"
      },
      "outputs": [],
      "source": [
        "from utils.preprocessing import save_to_json\n",
        "\n",
        "paths = []\n",
        "for type, func in types.items():\n",
        "    #create augmented data\n",
        "    \n",
        "    for entry in data:\n",
        "        augment(func, entry, type, paths)\n",
        "        \n",
        "   \n",
        "save_to_json({\"path\": paths}, AUG_OUT_DIR + '/config.json')    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r38kcqP6OxBP"
      },
      "source": [
        "# Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rHb3PtszOxBR"
      },
      "outputs": [],
      "source": [
        "def get_data_path(path):\n",
        "  f = open( path + 'config.json')\n",
        "  jdata = json.load(f)\n",
        "  f.close()\n",
        "  return jdata[\"path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "88H4mbOiOxBR"
      },
      "outputs": [],
      "source": [
        "data = get_data_path(SLICED_OUT_DIR)\n",
        "aug_data = get_data_path(AUG_OUT_DIR)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(data))\n",
        "train_aug_size = int(0.8 * len(aug_data))\n",
        "train_data = data[:train_size] + aug_data[:train_aug_size]\n",
        "test_data = data[train_size:]+ data[train_aug_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KujFCnGcOxBS",
        "outputId": "59c827bb-9db1-4bf4-dbff-a83d046e5ae8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iIrfN58YOxBT"
      },
      "outputs": [],
      "source": [
        "pixdim =(1.5, 1.5, 1.0)\n",
        "a_min=0\n",
        "a_max=500\n",
        "spatial_size= [128, 128,16] #[384, 384,18]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuD5dlJJOxBT",
        "outputId": "9ae4d4ef-7534-4596-b1ed-f0e289eb9066"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\envy\\Desktop\\Prostate_MRI\\Prostate_MRI_Detection_3D_Model\\packages\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
            "  warn_deprecated(obj, msg, warning_category)\n"
          ]
        }
      ],
      "source": [
        "from utils.transform import transform\n",
        "\n",
        "train_loader = transform(train_data, a_min, a_max, spatial_size, pixdim)\n",
        "test_loader = transform(test_data, a_min, a_max, spatial_size, pixdim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "75Vo69HwOxBU"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from monai.losses import DiceLoss\n",
        "from tqdm import tqdm\n",
        "from utils.train import train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EmAjiRapOxBU"
      },
      "outputs": [],
      "source": [
        "model_dir = OUT_DIR \n",
        "data_in = [train_loader, test_loader]\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CdTlUu69OxBV"
      },
      "outputs": [],
      "source": [
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "\n",
        "unet = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=( 64, 128, 256,512), \n",
        "    strides=(2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "krVsXagCuxbP"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "\n",
        "path = OUT_DIR+ \"best_metric_model.pth\"\n",
        "\n",
        "if (os.path.exists(path)):\n",
        "    unet.load_state_dict(torch.load(\n",
        "        os.path.join(path), map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rm3cFyExOxBV"
      },
      "outputs": [],
      "source": [
        "#loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\n",
        "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
        "optimizer = torch.optim.Adam(unet.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4JlLEYQOxBX",
        "outputId": "a39c8d05-f0c3-4328-fdd4-f2099ca88f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 128/250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\envy\\Desktop\\Prostate_MRI\\Prostate_MRI_Detection_3D_Model\\packages\\lib\\site-packages\\monai\\losses\\dice.py:144: UserWarning: single channel prediction, `to_onehot_y=True` ignored.\n",
            "  warnings.warn(\"single channel prediction, `to_onehot_y=True` ignored.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/326, Train_loss: 0.1908 Train_dice: 0.8092\n",
            "2/326, Train_loss: 0.2573 Train_dice: 0.7427\n",
            "3/326, Train_loss: 0.2991 Train_dice: 0.7009\n",
            "4/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "5/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "6/326, Train_loss: 0.2163 Train_dice: 0.7837\n",
            "7/326, Train_loss: 0.1108 Train_dice: 0.8892\n",
            "8/326, Train_loss: 0.0740 Train_dice: 0.9260\n",
            "9/326, Train_loss: 0.1235 Train_dice: 0.8765\n",
            "10/326, Train_loss: 0.0863 Train_dice: 0.9137\n",
            "11/326, Train_loss: 0.2391 Train_dice: 0.7609\n",
            "12/326, Train_loss: 0.2615 Train_dice: 0.7385\n",
            "13/326, Train_loss: 0.1540 Train_dice: 0.8460\n",
            "14/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "15/326, Train_loss: 0.3233 Train_dice: 0.6767\n",
            "16/326, Train_loss: 0.1207 Train_dice: 0.8793\n",
            "17/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "18/326, Train_loss: 0.2655 Train_dice: 0.7345\n",
            "19/326, Train_loss: 0.1203 Train_dice: 0.8797\n",
            "20/326, Train_loss: 0.2043 Train_dice: 0.7957\n",
            "21/326, Train_loss: 0.1044 Train_dice: 0.8956\n",
            "22/326, Train_loss: 0.1222 Train_dice: 0.8778\n",
            "23/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "24/326, Train_loss: 0.2286 Train_dice: 0.7714\n",
            "25/326, Train_loss: 0.1457 Train_dice: 0.8543\n",
            "26/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "27/326, Train_loss: 0.1183 Train_dice: 0.8817\n",
            "28/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "29/326, Train_loss: 0.1509 Train_dice: 0.8491\n",
            "30/326, Train_loss: 0.0980 Train_dice: 0.9020\n",
            "31/326, Train_loss: 0.3037 Train_dice: 0.6963\n",
            "32/326, Train_loss: 0.2012 Train_dice: 0.7988\n",
            "33/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "34/326, Train_loss: 0.1060 Train_dice: 0.8940\n",
            "35/326, Train_loss: 0.1054 Train_dice: 0.8946\n",
            "36/326, Train_loss: 0.0841 Train_dice: 0.9159\n",
            "37/326, Train_loss: 0.0892 Train_dice: 0.9108\n",
            "38/326, Train_loss: 0.2231 Train_dice: 0.7769\n",
            "39/326, Train_loss: 0.1635 Train_dice: 0.8365\n",
            "40/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "41/326, Train_loss: 0.1219 Train_dice: 0.8781\n",
            "42/326, Train_loss: 0.0997 Train_dice: 0.9003\n",
            "43/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "44/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "45/326, Train_loss: 0.0733 Train_dice: 0.9267\n",
            "46/326, Train_loss: 0.0503 Train_dice: 0.9497\n",
            "47/326, Train_loss: 0.2776 Train_dice: 0.7224\n",
            "48/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "49/326, Train_loss: 0.1598 Train_dice: 0.8402\n",
            "50/326, Train_loss: 0.1863 Train_dice: 0.8137\n",
            "51/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "52/326, Train_loss: 0.2018 Train_dice: 0.7982\n",
            "53/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "54/326, Train_loss: 0.1199 Train_dice: 0.8801\n",
            "55/326, Train_loss: 0.0947 Train_dice: 0.9053\n",
            "56/326, Train_loss: 0.1164 Train_dice: 0.8836\n",
            "57/326, Train_loss: 0.0845 Train_dice: 0.9155\n",
            "58/326, Train_loss: 0.0836 Train_dice: 0.9164\n",
            "59/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "60/326, Train_loss: 0.0958 Train_dice: 0.9042\n",
            "61/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "62/326, Train_loss: 0.0780 Train_dice: 0.9220\n",
            "63/326, Train_loss: 0.2018 Train_dice: 0.7982\n",
            "64/326, Train_loss: 0.0903 Train_dice: 0.9097\n",
            "65/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "66/326, Train_loss: 0.1748 Train_dice: 0.8252\n",
            "67/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "68/326, Train_loss: 0.1639 Train_dice: 0.8361\n",
            "69/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "70/326, Train_loss: 0.3231 Train_dice: 0.6769\n",
            "71/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "72/326, Train_loss: 0.2476 Train_dice: 0.7524\n",
            "73/326, Train_loss: 0.1100 Train_dice: 0.8900\n",
            "74/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "75/326, Train_loss: 0.1155 Train_dice: 0.8845\n",
            "76/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "77/326, Train_loss: 0.2324 Train_dice: 0.7676\n",
            "78/326, Train_loss: 0.1811 Train_dice: 0.8189\n",
            "79/326, Train_loss: 0.2458 Train_dice: 0.7542\n",
            "80/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "81/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "82/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "83/326, Train_loss: 0.1783 Train_dice: 0.8217\n",
            "84/326, Train_loss: 0.3199 Train_dice: 0.6801\n",
            "85/326, Train_loss: 0.1494 Train_dice: 0.8506\n",
            "86/326, Train_loss: 0.0743 Train_dice: 0.9257\n",
            "87/326, Train_loss: 0.0915 Train_dice: 0.9085\n",
            "88/326, Train_loss: 0.1797 Train_dice: 0.8203\n",
            "89/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "90/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "91/326, Train_loss: 0.1222 Train_dice: 0.8778\n",
            "92/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "93/326, Train_loss: 0.2577 Train_dice: 0.7423\n",
            "94/326, Train_loss: 0.1883 Train_dice: 0.8117\n",
            "95/326, Train_loss: 0.3381 Train_dice: 0.6619\n",
            "96/326, Train_loss: 0.1288 Train_dice: 0.8712\n",
            "97/326, Train_loss: 0.1008 Train_dice: 0.8992\n",
            "98/326, Train_loss: 0.2321 Train_dice: 0.7679\n",
            "99/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "100/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "101/326, Train_loss: 0.1301 Train_dice: 0.8699\n",
            "102/326, Train_loss: 0.1124 Train_dice: 0.8876\n",
            "103/326, Train_loss: 0.0978 Train_dice: 0.9022\n",
            "104/326, Train_loss: 0.1375 Train_dice: 0.8625\n",
            "105/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "106/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "107/326, Train_loss: 0.1443 Train_dice: 0.8557\n",
            "108/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "109/326, Train_loss: 0.1324 Train_dice: 0.8676\n",
            "110/326, Train_loss: 0.2448 Train_dice: 0.7552\n",
            "111/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "112/326, Train_loss: 0.2686 Train_dice: 0.7314\n",
            "113/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "114/326, Train_loss: 0.1395 Train_dice: 0.8605\n",
            "115/326, Train_loss: 0.1939 Train_dice: 0.8061\n",
            "116/326, Train_loss: 0.3241 Train_dice: 0.6759\n",
            "117/326, Train_loss: 0.1258 Train_dice: 0.8742\n",
            "118/326, Train_loss: 0.2840 Train_dice: 0.7160\n",
            "119/326, Train_loss: 0.1636 Train_dice: 0.8364\n",
            "120/326, Train_loss: 0.0947 Train_dice: 0.9053\n",
            "121/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "122/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "123/326, Train_loss: 0.1185 Train_dice: 0.8815\n",
            "124/326, Train_loss: 0.1851 Train_dice: 0.8149\n",
            "125/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "126/326, Train_loss: 0.2470 Train_dice: 0.7530\n",
            "127/326, Train_loss: 0.1258 Train_dice: 0.8742\n",
            "128/326, Train_loss: 0.2075 Train_dice: 0.7925\n",
            "129/326, Train_loss: 0.3829 Train_dice: 0.6171\n",
            "130/326, Train_loss: 0.2382 Train_dice: 0.7618\n",
            "131/326, Train_loss: 0.0619 Train_dice: 0.9381\n",
            "132/326, Train_loss: 0.2346 Train_dice: 0.7654\n",
            "133/326, Train_loss: 0.1745 Train_dice: 0.8255\n",
            "134/326, Train_loss: 0.3785 Train_dice: 0.6215\n",
            "135/326, Train_loss: 0.1806 Train_dice: 0.8194\n",
            "136/326, Train_loss: 0.2478 Train_dice: 0.7522\n",
            "137/326, Train_loss: 0.1779 Train_dice: 0.8221\n",
            "138/326, Train_loss: 0.1093 Train_dice: 0.8907\n",
            "139/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "140/326, Train_loss: 0.1841 Train_dice: 0.8159\n",
            "141/326, Train_loss: 0.0944 Train_dice: 0.9056\n",
            "142/326, Train_loss: 0.2489 Train_dice: 0.7511\n",
            "143/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "144/326, Train_loss: 0.1560 Train_dice: 0.8440\n",
            "145/326, Train_loss: 0.3127 Train_dice: 0.6873\n",
            "146/326, Train_loss: 0.1590 Train_dice: 0.8410\n",
            "147/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "148/326, Train_loss: 0.2184 Train_dice: 0.7816\n",
            "149/326, Train_loss: 0.1409 Train_dice: 0.8591\n",
            "150/326, Train_loss: 0.2474 Train_dice: 0.7526\n",
            "151/326, Train_loss: 0.1712 Train_dice: 0.8288\n",
            "152/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "153/326, Train_loss: 0.2817 Train_dice: 0.7183\n",
            "154/326, Train_loss: 0.1419 Train_dice: 0.8581\n",
            "155/326, Train_loss: 0.0771 Train_dice: 0.9229\n",
            "156/326, Train_loss: 0.1456 Train_dice: 0.8544\n",
            "157/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "158/326, Train_loss: 0.3337 Train_dice: 0.6663\n",
            "159/326, Train_loss: 0.1202 Train_dice: 0.8798\n",
            "160/326, Train_loss: 0.1173 Train_dice: 0.8827\n",
            "161/326, Train_loss: 0.1816 Train_dice: 0.8184\n",
            "162/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "163/326, Train_loss: 0.0671 Train_dice: 0.9329\n",
            "164/326, Train_loss: 0.3172 Train_dice: 0.6828\n",
            "165/326, Train_loss: 0.5906 Train_dice: 0.4094\n",
            "166/326, Train_loss: 0.3266 Train_dice: 0.6734\n",
            "167/326, Train_loss: 0.4022 Train_dice: 0.5978\n",
            "168/326, Train_loss: 0.2124 Train_dice: 0.7876\n",
            "169/326, Train_loss: 0.5179 Train_dice: 0.4821\n",
            "170/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "171/326, Train_loss: 0.1083 Train_dice: 0.8917\n",
            "172/326, Train_loss: 0.5715 Train_dice: 0.4285\n",
            "173/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "174/326, Train_loss: 0.1493 Train_dice: 0.8507\n",
            "175/326, Train_loss: 0.2135 Train_dice: 0.7865\n",
            "176/326, Train_loss: 0.2162 Train_dice: 0.7838\n",
            "177/326, Train_loss: 0.0501 Train_dice: 0.9499\n",
            "178/326, Train_loss: 0.2488 Train_dice: 0.7512\n",
            "179/326, Train_loss: 0.1162 Train_dice: 0.8838\n",
            "180/326, Train_loss: 0.2254 Train_dice: 0.7746\n",
            "181/326, Train_loss: 0.2110 Train_dice: 0.7890\n",
            "182/326, Train_loss: 0.1401 Train_dice: 0.8599\n",
            "183/326, Train_loss: 0.7713 Train_dice: 0.2287\n",
            "184/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "185/326, Train_loss: 0.0905 Train_dice: 0.9095\n",
            "186/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "187/326, Train_loss: 0.1631 Train_dice: 0.8369\n",
            "188/326, Train_loss: 0.0834 Train_dice: 0.9166\n",
            "189/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "190/326, Train_loss: 0.7165 Train_dice: 0.2835\n",
            "191/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "192/326, Train_loss: 0.7260 Train_dice: 0.2740\n",
            "193/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "194/326, Train_loss: 0.1924 Train_dice: 0.8076\n",
            "195/326, Train_loss: 0.7764 Train_dice: 0.2236\n",
            "196/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "197/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "198/326, Train_loss: 0.1366 Train_dice: 0.8634\n",
            "199/326, Train_loss: 0.6405 Train_dice: 0.3595\n",
            "200/326, Train_loss: 0.0495 Train_dice: 0.9505\n",
            "201/326, Train_loss: 0.1472 Train_dice: 0.8528\n",
            "202/326, Train_loss: 0.1050 Train_dice: 0.8950\n",
            "203/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "204/326, Train_loss: 0.1033 Train_dice: 0.8967\n",
            "205/326, Train_loss: 0.6919 Train_dice: 0.3081\n",
            "206/326, Train_loss: 0.1029 Train_dice: 0.8971\n",
            "207/326, Train_loss: 0.1081 Train_dice: 0.8919\n",
            "208/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "209/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "210/326, Train_loss: 0.8193 Train_dice: 0.1807\n",
            "211/326, Train_loss: 0.0595 Train_dice: 0.9405\n",
            "212/326, Train_loss: 0.0949 Train_dice: 0.9051\n",
            "213/326, Train_loss: 0.0887 Train_dice: 0.9113\n",
            "214/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "215/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "216/326, Train_loss: 0.0798 Train_dice: 0.9202\n",
            "217/326, Train_loss: 0.7149 Train_dice: 0.2851\n",
            "218/326, Train_loss: 0.6798 Train_dice: 0.3202\n",
            "219/326, Train_loss: 0.6785 Train_dice: 0.3215\n",
            "220/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "221/326, Train_loss: 0.0585 Train_dice: 0.9415\n",
            "222/326, Train_loss: 0.1782 Train_dice: 0.8218\n",
            "223/326, Train_loss: 0.1448 Train_dice: 0.8552\n",
            "224/326, Train_loss: 0.0848 Train_dice: 0.9152\n",
            "225/326, Train_loss: 0.0790 Train_dice: 0.9210\n",
            "226/326, Train_loss: 0.1077 Train_dice: 0.8923\n",
            "227/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "228/326, Train_loss: 0.1400 Train_dice: 0.8600\n",
            "229/326, Train_loss: 0.1240 Train_dice: 0.8760\n",
            "230/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "231/326, Train_loss: 0.7307 Train_dice: 0.2693\n",
            "232/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "233/326, Train_loss: 0.8359 Train_dice: 0.1641\n",
            "234/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "235/326, Train_loss: 0.8247 Train_dice: 0.1753\n",
            "236/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "237/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "238/326, Train_loss: 0.0748 Train_dice: 0.9252\n",
            "239/326, Train_loss: 0.1025 Train_dice: 0.8975\n",
            "240/326, Train_loss: 0.8058 Train_dice: 0.1942\n",
            "241/326, Train_loss: 0.7807 Train_dice: 0.2193\n",
            "242/326, Train_loss: 0.7872 Train_dice: 0.2128\n",
            "243/326, Train_loss: 0.0636 Train_dice: 0.9364\n",
            "244/326, Train_loss: 0.0587 Train_dice: 0.9413\n",
            "245/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "246/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "247/326, Train_loss: 0.1013 Train_dice: 0.8987\n",
            "248/326, Train_loss: 0.7388 Train_dice: 0.2612\n",
            "249/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "250/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "251/326, Train_loss: 0.0932 Train_dice: 0.9068\n",
            "252/326, Train_loss: 0.0587 Train_dice: 0.9413\n",
            "253/326, Train_loss: 0.0606 Train_dice: 0.9394\n",
            "254/326, Train_loss: 0.1085 Train_dice: 0.8915\n",
            "255/326, Train_loss: 0.0773 Train_dice: 0.9227\n",
            "256/326, Train_loss: 0.7659 Train_dice: 0.2341\n",
            "257/326, Train_loss: 0.1545 Train_dice: 0.8455\n",
            "258/326, Train_loss: 0.8438 Train_dice: 0.1562\n",
            "259/326, Train_loss: 0.6755 Train_dice: 0.3245\n",
            "260/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "261/326, Train_loss: 0.7850 Train_dice: 0.2150\n",
            "262/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "263/326, Train_loss: 0.6148 Train_dice: 0.3852\n",
            "264/326, Train_loss: 0.0789 Train_dice: 0.9211\n",
            "265/326, Train_loss: 0.7301 Train_dice: 0.2699\n",
            "266/326, Train_loss: 0.6666 Train_dice: 0.3334\n",
            "267/326, Train_loss: 0.6826 Train_dice: 0.3174\n",
            "268/326, Train_loss: 0.6980 Train_dice: 0.3020\n",
            "269/326, Train_loss: 0.6920 Train_dice: 0.3080\n",
            "270/326, Train_loss: 0.6790 Train_dice: 0.3210\n",
            "271/326, Train_loss: 0.1849 Train_dice: 0.8151\n",
            "272/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "273/326, Train_loss: 0.1235 Train_dice: 0.8765\n",
            "274/326, Train_loss: 0.6569 Train_dice: 0.3431\n",
            "275/326, Train_loss: 0.7757 Train_dice: 0.2243\n",
            "276/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "277/326, Train_loss: 0.1272 Train_dice: 0.8728\n",
            "278/326, Train_loss: 0.6825 Train_dice: 0.3175\n",
            "279/326, Train_loss: 0.7578 Train_dice: 0.2422\n",
            "280/326, Train_loss: 0.6674 Train_dice: 0.3326\n",
            "281/326, Train_loss: 0.0959 Train_dice: 0.9041\n",
            "282/326, Train_loss: 0.6869 Train_dice: 0.3131\n",
            "283/326, Train_loss: 0.5648 Train_dice: 0.4352\n",
            "284/326, Train_loss: 0.1667 Train_dice: 0.8333\n",
            "285/326, Train_loss: 0.5985 Train_dice: 0.4015\n",
            "286/326, Train_loss: 0.0867 Train_dice: 0.9133\n",
            "287/326, Train_loss: 0.6297 Train_dice: 0.3703\n",
            "288/326, Train_loss: 0.2177 Train_dice: 0.7823\n",
            "289/326, Train_loss: 0.2038 Train_dice: 0.7962\n",
            "290/326, Train_loss: 0.2211 Train_dice: 0.7789\n",
            "291/326, Train_loss: 0.1501 Train_dice: 0.8499\n",
            "292/326, Train_loss: 0.1136 Train_dice: 0.8864\n",
            "293/326, Train_loss: 0.1148 Train_dice: 0.8852\n",
            "294/326, Train_loss: 0.1353 Train_dice: 0.8647\n",
            "295/326, Train_loss: 0.6666 Train_dice: 0.3334\n",
            "296/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "297/326, Train_loss: 0.1753 Train_dice: 0.8247\n",
            "298/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "299/326, Train_loss: 0.1624 Train_dice: 0.8376\n",
            "300/326, Train_loss: 0.7048 Train_dice: 0.2952\n",
            "301/326, Train_loss: 0.0907 Train_dice: 0.9093\n",
            "302/326, Train_loss: 0.1466 Train_dice: 0.8534\n",
            "303/326, Train_loss: 0.7238 Train_dice: 0.2762\n",
            "304/326, Train_loss: 0.0676 Train_dice: 0.9324\n",
            "305/326, Train_loss: 0.2838 Train_dice: 0.7162\n",
            "306/326, Train_loss: 0.0777 Train_dice: 0.9223\n",
            "307/326, Train_loss: 0.1147 Train_dice: 0.8853\n",
            "308/326, Train_loss: 0.1181 Train_dice: 0.8819\n",
            "309/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "310/326, Train_loss: 0.0740 Train_dice: 0.9260\n",
            "311/326, Train_loss: 0.1538 Train_dice: 0.8462\n",
            "312/326, Train_loss: 0.0707 Train_dice: 0.9293\n",
            "313/326, Train_loss: 0.1133 Train_dice: 0.8867\n",
            "314/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "315/326, Train_loss: 0.0704 Train_dice: 0.9296\n",
            "316/326, Train_loss: 0.0936 Train_dice: 0.9064\n",
            "317/326, Train_loss: 0.0902 Train_dice: 0.9098\n",
            "318/326, Train_loss: 0.0435 Train_dice: 0.9565\n",
            "319/326, Train_loss: 0.1111 Train_dice: 0.8889\n",
            "320/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "321/326, Train_loss: 0.2462 Train_dice: 0.7538\n",
            "322/326, Train_loss: 0.1076 Train_dice: 0.8924\n",
            "323/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "324/326, Train_loss: 0.1661 Train_dice: 0.8339\n",
            "325/326, Train_loss: 0.0936 Train_dice: 0.9064\n",
            "326/326, Train_loss: 0.0743 Train_dice: 0.9257\n",
            "--------------------\n",
            "Epoch_loss: 0.2062\n",
            "Epoch_metric: 0.7938\n",
            "----------\n",
            "epoch 129/250\n",
            "1/326, Train_loss: 0.6292 Train_dice: 0.3708\n",
            "2/326, Train_loss: 0.6156 Train_dice: 0.3844\n",
            "3/326, Train_loss: 0.6140 Train_dice: 0.3860\n",
            "4/326, Train_loss: 0.4142 Train_dice: 0.5858\n",
            "5/326, Train_loss: 0.1312 Train_dice: 0.8688\n",
            "6/326, Train_loss: 0.4142 Train_dice: 0.5858\n",
            "7/326, Train_loss: 0.1421 Train_dice: 0.8579\n",
            "8/326, Train_loss: 0.1025 Train_dice: 0.8975\n",
            "9/326, Train_loss: 0.1488 Train_dice: 0.8512\n",
            "10/326, Train_loss: 0.1045 Train_dice: 0.8955\n",
            "11/326, Train_loss: 0.2732 Train_dice: 0.7268\n",
            "12/326, Train_loss: 0.2779 Train_dice: 0.7221\n",
            "13/326, Train_loss: 0.1797 Train_dice: 0.8203\n",
            "14/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "15/326, Train_loss: 0.3340 Train_dice: 0.6660\n",
            "16/326, Train_loss: 0.1290 Train_dice: 0.8710\n",
            "17/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "18/326, Train_loss: 0.2738 Train_dice: 0.7262\n",
            "19/326, Train_loss: 0.1247 Train_dice: 0.8753\n",
            "20/326, Train_loss: 0.2076 Train_dice: 0.7924\n",
            "21/326, Train_loss: 0.1081 Train_dice: 0.8919\n",
            "22/326, Train_loss: 0.1272 Train_dice: 0.8728\n",
            "23/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "24/326, Train_loss: 0.2316 Train_dice: 0.7684\n",
            "25/326, Train_loss: 0.1535 Train_dice: 0.8465\n",
            "26/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "27/326, Train_loss: 0.1184 Train_dice: 0.8816\n",
            "28/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "29/326, Train_loss: 0.1532 Train_dice: 0.8468\n",
            "30/326, Train_loss: 0.0938 Train_dice: 0.9062\n",
            "31/326, Train_loss: 0.2985 Train_dice: 0.7015\n",
            "32/326, Train_loss: 0.2019 Train_dice: 0.7981\n",
            "33/326, Train_loss: 0.0775 Train_dice: 0.9225\n",
            "34/326, Train_loss: 0.1067 Train_dice: 0.8933\n",
            "35/326, Train_loss: 0.1047 Train_dice: 0.8953\n",
            "36/326, Train_loss: 0.0872 Train_dice: 0.9128\n",
            "37/326, Train_loss: 0.0867 Train_dice: 0.9133\n",
            "38/326, Train_loss: 0.2202 Train_dice: 0.7798\n",
            "39/326, Train_loss: 0.1639 Train_dice: 0.8361\n",
            "40/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "41/326, Train_loss: 0.1292 Train_dice: 0.8708\n",
            "42/326, Train_loss: 0.1030 Train_dice: 0.8970\n",
            "43/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "44/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "45/326, Train_loss: 0.0806 Train_dice: 0.9194\n",
            "46/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "47/326, Train_loss: 0.2857 Train_dice: 0.7143\n",
            "48/326, Train_loss: 0.0775 Train_dice: 0.9225\n",
            "49/326, Train_loss: 0.1668 Train_dice: 0.8332\n",
            "50/326, Train_loss: 0.1838 Train_dice: 0.8162\n",
            "51/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "52/326, Train_loss: 0.2001 Train_dice: 0.7999\n",
            "53/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "54/326, Train_loss: 0.1168 Train_dice: 0.8832\n",
            "55/326, Train_loss: 0.0907 Train_dice: 0.9093\n",
            "56/326, Train_loss: 0.1122 Train_dice: 0.8878\n",
            "57/326, Train_loss: 0.0824 Train_dice: 0.9176\n",
            "58/326, Train_loss: 0.0752 Train_dice: 0.9248\n",
            "59/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "60/326, Train_loss: 0.0926 Train_dice: 0.9074\n",
            "61/326, Train_loss: 0.0314 Train_dice: 0.9686\n",
            "62/326, Train_loss: 0.0815 Train_dice: 0.9185\n",
            "63/326, Train_loss: 0.1972 Train_dice: 0.8028\n",
            "64/326, Train_loss: 0.0875 Train_dice: 0.9125\n",
            "65/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "66/326, Train_loss: 0.1739 Train_dice: 0.8261\n",
            "67/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "68/326, Train_loss: 0.1632 Train_dice: 0.8368\n",
            "69/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "70/326, Train_loss: 0.3167 Train_dice: 0.6833\n",
            "71/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "72/326, Train_loss: 0.2508 Train_dice: 0.7492\n",
            "73/326, Train_loss: 0.1129 Train_dice: 0.8871\n",
            "74/326, Train_loss: 0.0877 Train_dice: 0.9123\n",
            "75/326, Train_loss: 0.1182 Train_dice: 0.8818\n",
            "76/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "77/326, Train_loss: 0.2349 Train_dice: 0.7651\n",
            "78/326, Train_loss: 0.1811 Train_dice: 0.8189\n",
            "79/326, Train_loss: 0.2418 Train_dice: 0.7582\n",
            "80/326, Train_loss: 0.0858 Train_dice: 0.9142\n",
            "81/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "82/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "83/326, Train_loss: 0.1823 Train_dice: 0.8177\n",
            "84/326, Train_loss: 0.3127 Train_dice: 0.6873\n",
            "85/326, Train_loss: 0.1432 Train_dice: 0.8568\n",
            "86/326, Train_loss: 0.0728 Train_dice: 0.9272\n",
            "87/326, Train_loss: 0.0879 Train_dice: 0.9121\n",
            "88/326, Train_loss: 0.1733 Train_dice: 0.8267\n",
            "89/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "90/326, Train_loss: 0.0659 Train_dice: 0.9341\n",
            "91/326, Train_loss: 0.1188 Train_dice: 0.8812\n",
            "92/326, Train_loss: 0.1331 Train_dice: 0.8669\n",
            "93/326, Train_loss: 0.2517 Train_dice: 0.7483\n",
            "94/326, Train_loss: 0.1839 Train_dice: 0.8161\n",
            "95/326, Train_loss: 0.3339 Train_dice: 0.6661\n",
            "96/326, Train_loss: 0.1290 Train_dice: 0.8710\n",
            "97/326, Train_loss: 0.1003 Train_dice: 0.8997\n",
            "98/326, Train_loss: 0.2297 Train_dice: 0.7703\n",
            "99/326, Train_loss: 0.0681 Train_dice: 0.9319\n",
            "100/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "101/326, Train_loss: 0.1287 Train_dice: 0.8713\n",
            "102/326, Train_loss: 0.1120 Train_dice: 0.8880\n",
            "103/326, Train_loss: 0.0982 Train_dice: 0.9018\n",
            "104/326, Train_loss: 0.1377 Train_dice: 0.8623\n",
            "105/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "106/326, Train_loss: 0.1333 Train_dice: 0.8667\n",
            "107/326, Train_loss: 0.1364 Train_dice: 0.8636\n",
            "108/326, Train_loss: 0.0442 Train_dice: 0.9558\n",
            "109/326, Train_loss: 0.1305 Train_dice: 0.8695\n",
            "110/326, Train_loss: 0.2384 Train_dice: 0.7616\n",
            "111/326, Train_loss: 0.0922 Train_dice: 0.9078\n",
            "112/326, Train_loss: 0.2627 Train_dice: 0.7373\n",
            "113/326, Train_loss: 0.1003 Train_dice: 0.8997\n",
            "114/326, Train_loss: 0.1347 Train_dice: 0.8653\n",
            "115/326, Train_loss: 0.1906 Train_dice: 0.8094\n",
            "116/326, Train_loss: 0.3185 Train_dice: 0.6815\n",
            "117/326, Train_loss: 0.1224 Train_dice: 0.8776\n",
            "118/326, Train_loss: 0.2823 Train_dice: 0.7177\n",
            "119/326, Train_loss: 0.1606 Train_dice: 0.8394\n",
            "120/326, Train_loss: 0.0946 Train_dice: 0.9054\n",
            "121/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "122/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "123/326, Train_loss: 0.1151 Train_dice: 0.8849\n",
            "124/326, Train_loss: 0.1810 Train_dice: 0.8190\n",
            "125/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "126/326, Train_loss: 0.2427 Train_dice: 0.7573\n",
            "127/326, Train_loss: 0.1177 Train_dice: 0.8823\n",
            "128/326, Train_loss: 0.1965 Train_dice: 0.8035\n",
            "129/326, Train_loss: 0.3749 Train_dice: 0.6251\n",
            "130/326, Train_loss: 0.2325 Train_dice: 0.7675\n",
            "131/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "132/326, Train_loss: 0.2291 Train_dice: 0.7709\n",
            "133/326, Train_loss: 0.1754 Train_dice: 0.8246\n",
            "134/326, Train_loss: 0.3701 Train_dice: 0.6299\n",
            "135/326, Train_loss: 0.1809 Train_dice: 0.8191\n",
            "136/326, Train_loss: 0.2477 Train_dice: 0.7523\n",
            "137/326, Train_loss: 0.1779 Train_dice: 0.8221\n",
            "138/326, Train_loss: 0.1161 Train_dice: 0.8839\n",
            "139/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "140/326, Train_loss: 0.1842 Train_dice: 0.8158\n",
            "141/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "142/326, Train_loss: 0.2464 Train_dice: 0.7536\n",
            "143/326, Train_loss: 0.0688 Train_dice: 0.9312\n",
            "144/326, Train_loss: 0.1532 Train_dice: 0.8468\n",
            "145/326, Train_loss: 0.3065 Train_dice: 0.6935\n",
            "146/326, Train_loss: 0.1575 Train_dice: 0.8425\n",
            "147/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "148/326, Train_loss: 0.2124 Train_dice: 0.7876\n",
            "149/326, Train_loss: 0.1351 Train_dice: 0.8649\n",
            "150/326, Train_loss: 0.2388 Train_dice: 0.7612\n",
            "151/326, Train_loss: 0.1678 Train_dice: 0.8322\n",
            "152/326, Train_loss: 0.0659 Train_dice: 0.9341\n",
            "153/326, Train_loss: 0.2813 Train_dice: 0.7187\n",
            "154/326, Train_loss: 0.1401 Train_dice: 0.8599\n",
            "155/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "156/326, Train_loss: 0.1429 Train_dice: 0.8571\n",
            "157/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "158/326, Train_loss: 0.3284 Train_dice: 0.6716\n",
            "159/326, Train_loss: 0.1182 Train_dice: 0.8818\n",
            "160/326, Train_loss: 0.1196 Train_dice: 0.8804\n",
            "161/326, Train_loss: 0.1754 Train_dice: 0.8246\n",
            "162/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "163/326, Train_loss: 0.0705 Train_dice: 0.9295\n",
            "164/326, Train_loss: 0.1859 Train_dice: 0.8141\n",
            "165/326, Train_loss: 0.2883 Train_dice: 0.7117\n",
            "166/326, Train_loss: 0.2701 Train_dice: 0.7299\n",
            "167/326, Train_loss: 0.3228 Train_dice: 0.6772\n",
            "168/326, Train_loss: 0.0839 Train_dice: 0.9161\n",
            "169/326, Train_loss: 0.3641 Train_dice: 0.6359\n",
            "170/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "171/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "172/326, Train_loss: 0.5121 Train_dice: 0.4879\n",
            "173/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "174/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "175/326, Train_loss: 0.0778 Train_dice: 0.9222\n",
            "176/326, Train_loss: 0.0857 Train_dice: 0.9143\n",
            "177/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "178/326, Train_loss: 0.1606 Train_dice: 0.8394\n",
            "179/326, Train_loss: 0.0831 Train_dice: 0.9169\n",
            "180/326, Train_loss: 0.1534 Train_dice: 0.8466\n",
            "181/326, Train_loss: 0.0987 Train_dice: 0.9013\n",
            "182/326, Train_loss: 0.1488 Train_dice: 0.8512\n",
            "183/326, Train_loss: 0.6640 Train_dice: 0.3360\n",
            "184/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "185/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "186/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "187/326, Train_loss: 0.1241 Train_dice: 0.8759\n",
            "188/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "189/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "190/326, Train_loss: 0.6601 Train_dice: 0.3399\n",
            "191/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "192/326, Train_loss: 0.6520 Train_dice: 0.3480\n",
            "193/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "194/326, Train_loss: 0.1511 Train_dice: 0.8489\n",
            "195/326, Train_loss: 0.7550 Train_dice: 0.2450\n",
            "196/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "197/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "198/326, Train_loss: 0.1225 Train_dice: 0.8775\n",
            "199/326, Train_loss: 0.6424 Train_dice: 0.3576\n",
            "200/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "201/326, Train_loss: 0.1008 Train_dice: 0.8992\n",
            "202/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "203/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "204/326, Train_loss: 0.0979 Train_dice: 0.9021\n",
            "205/326, Train_loss: 0.6938 Train_dice: 0.3062\n",
            "206/326, Train_loss: 0.0673 Train_dice: 0.9327\n",
            "207/326, Train_loss: 0.0827 Train_dice: 0.9173\n",
            "208/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "209/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "210/326, Train_loss: 0.7900 Train_dice: 0.2100\n",
            "211/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "212/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "213/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "214/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "215/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "216/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "217/326, Train_loss: 0.6951 Train_dice: 0.3049\n",
            "218/326, Train_loss: 0.6742 Train_dice: 0.3258\n",
            "219/326, Train_loss: 0.6603 Train_dice: 0.3397\n",
            "220/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "221/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "222/326, Train_loss: 0.1486 Train_dice: 0.8514\n",
            "223/326, Train_loss: 0.1449 Train_dice: 0.8551\n",
            "224/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "225/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "226/326, Train_loss: 0.0961 Train_dice: 0.9039\n",
            "227/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "228/326, Train_loss: 0.1027 Train_dice: 0.8973\n",
            "229/326, Train_loss: 0.1059 Train_dice: 0.8941\n",
            "230/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "231/326, Train_loss: 0.7158 Train_dice: 0.2842\n",
            "232/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "233/326, Train_loss: 0.8266 Train_dice: 0.1734\n",
            "234/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "235/326, Train_loss: 0.8139 Train_dice: 0.1861\n",
            "236/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "237/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "238/326, Train_loss: 0.0658 Train_dice: 0.9342\n",
            "239/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "240/326, Train_loss: 0.7777 Train_dice: 0.2223\n",
            "241/326, Train_loss: 0.7336 Train_dice: 0.2664\n",
            "242/326, Train_loss: 0.7743 Train_dice: 0.2257\n",
            "243/326, Train_loss: 0.0536 Train_dice: 0.9464\n",
            "244/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "245/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "246/326, Train_loss: 0.0546 Train_dice: 0.9454\n",
            "247/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "248/326, Train_loss: 0.7292 Train_dice: 0.2708\n",
            "249/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "250/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "251/326, Train_loss: 0.0919 Train_dice: 0.9081\n",
            "252/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "253/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "254/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "255/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "256/326, Train_loss: 0.7439 Train_dice: 0.2561\n",
            "257/326, Train_loss: 0.1150 Train_dice: 0.8850\n",
            "258/326, Train_loss: 0.8281 Train_dice: 0.1719\n",
            "259/326, Train_loss: 0.6623 Train_dice: 0.3377\n",
            "260/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "261/326, Train_loss: 0.7501 Train_dice: 0.2499\n",
            "262/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "263/326, Train_loss: 0.5913 Train_dice: 0.4087\n",
            "264/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "265/326, Train_loss: 0.7154 Train_dice: 0.2846\n",
            "266/326, Train_loss: 0.6503 Train_dice: 0.3497\n",
            "267/326, Train_loss: 0.5575 Train_dice: 0.4425\n",
            "268/326, Train_loss: 0.6705 Train_dice: 0.3295\n",
            "269/326, Train_loss: 0.6560 Train_dice: 0.3440\n",
            "270/326, Train_loss: 0.4883 Train_dice: 0.5117\n",
            "271/326, Train_loss: 0.1687 Train_dice: 0.8313\n",
            "272/326, Train_loss: 0.0815 Train_dice: 0.9185\n",
            "273/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "274/326, Train_loss: 0.5995 Train_dice: 0.4005\n",
            "275/326, Train_loss: 0.6794 Train_dice: 0.3206\n",
            "276/326, Train_loss: 0.1043 Train_dice: 0.8957\n",
            "277/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "278/326, Train_loss: 0.3703 Train_dice: 0.6297\n",
            "279/326, Train_loss: 0.6198 Train_dice: 0.3802\n",
            "280/326, Train_loss: 0.5786 Train_dice: 0.4214\n",
            "281/326, Train_loss: 0.1686 Train_dice: 0.8314\n",
            "282/326, Train_loss: 0.5771 Train_dice: 0.4229\n",
            "283/326, Train_loss: 0.3884 Train_dice: 0.6116\n",
            "284/326, Train_loss: 0.1837 Train_dice: 0.8163\n",
            "285/326, Train_loss: 0.4158 Train_dice: 0.5842\n",
            "286/326, Train_loss: 0.0822 Train_dice: 0.9178\n",
            "287/326, Train_loss: 0.2227 Train_dice: 0.7773\n",
            "288/326, Train_loss: 0.2002 Train_dice: 0.7998\n",
            "289/326, Train_loss: 0.2849 Train_dice: 0.7151\n",
            "290/326, Train_loss: 0.4669 Train_dice: 0.5331\n",
            "291/326, Train_loss: 0.5063 Train_dice: 0.4937\n",
            "292/326, Train_loss: 0.3559 Train_dice: 0.6441\n",
            "293/326, Train_loss: 0.1259 Train_dice: 0.8741\n",
            "294/326, Train_loss: 0.1152 Train_dice: 0.8848\n",
            "295/326, Train_loss: 0.2552 Train_dice: 0.7448\n",
            "296/326, Train_loss: 0.2570 Train_dice: 0.7430\n",
            "297/326, Train_loss: 0.2106 Train_dice: 0.7894\n",
            "298/326, Train_loss: 0.0752 Train_dice: 0.9248\n",
            "299/326, Train_loss: 0.1662 Train_dice: 0.8338\n",
            "300/326, Train_loss: 0.7053 Train_dice: 0.2947\n",
            "301/326, Train_loss: 0.0816 Train_dice: 0.9184\n",
            "302/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "303/326, Train_loss: 0.7228 Train_dice: 0.2772\n",
            "304/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "305/326, Train_loss: 0.2259 Train_dice: 0.7741\n",
            "306/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "307/326, Train_loss: 0.0970 Train_dice: 0.9030\n",
            "308/326, Train_loss: 0.1100 Train_dice: 0.8900\n",
            "309/326, Train_loss: 0.0759 Train_dice: 0.9241\n",
            "310/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "311/326, Train_loss: 0.1394 Train_dice: 0.8606\n",
            "312/326, Train_loss: 0.0603 Train_dice: 0.9397\n",
            "313/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "314/326, Train_loss: 0.0753 Train_dice: 0.9247\n",
            "315/326, Train_loss: 0.0550 Train_dice: 0.9450\n",
            "316/326, Train_loss: 0.1082 Train_dice: 0.8918\n",
            "317/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "318/326, Train_loss: 0.0444 Train_dice: 0.9556\n",
            "319/326, Train_loss: 0.1011 Train_dice: 0.8989\n",
            "320/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "321/326, Train_loss: 0.1911 Train_dice: 0.8089\n",
            "322/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "323/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "324/326, Train_loss: 0.1101 Train_dice: 0.8899\n",
            "325/326, Train_loss: 0.0811 Train_dice: 0.9189\n",
            "326/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "--------------------\n",
            "Epoch_loss: 0.1967\n",
            "Epoch_metric: 0.8033\n",
            "----------\n",
            "epoch 130/250\n",
            "1/326, Train_loss: 0.2452 Train_dice: 0.7548\n",
            "2/326, Train_loss: 0.3136 Train_dice: 0.6864\n",
            "3/326, Train_loss: 0.3194 Train_dice: 0.6806\n",
            "4/326, Train_loss: 0.2942 Train_dice: 0.7058\n",
            "5/326, Train_loss: 0.0923 Train_dice: 0.9077\n",
            "6/326, Train_loss: 0.2382 Train_dice: 0.7618\n",
            "7/326, Train_loss: 0.1693 Train_dice: 0.8307\n",
            "8/326, Train_loss: 0.1059 Train_dice: 0.8941\n",
            "9/326, Train_loss: 0.4944 Train_dice: 0.5056\n",
            "10/326, Train_loss: 0.1042 Train_dice: 0.8958\n",
            "11/326, Train_loss: 0.3341 Train_dice: 0.6659\n",
            "12/326, Train_loss: 0.2833 Train_dice: 0.7167\n",
            "13/326, Train_loss: 0.2021 Train_dice: 0.7979\n",
            "14/326, Train_loss: 0.0750 Train_dice: 0.9250\n",
            "15/326, Train_loss: 0.3514 Train_dice: 0.6486\n",
            "16/326, Train_loss: 0.1221 Train_dice: 0.8779\n",
            "17/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "18/326, Train_loss: 0.2616 Train_dice: 0.7384\n",
            "19/326, Train_loss: 0.1184 Train_dice: 0.8816\n",
            "20/326, Train_loss: 0.2042 Train_dice: 0.7958\n",
            "21/326, Train_loss: 0.1024 Train_dice: 0.8976\n",
            "22/326, Train_loss: 0.1182 Train_dice: 0.8818\n",
            "23/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "24/326, Train_loss: 0.2220 Train_dice: 0.7780\n",
            "25/326, Train_loss: 0.1440 Train_dice: 0.8560\n",
            "26/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "27/326, Train_loss: 0.1135 Train_dice: 0.8865\n",
            "28/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "29/326, Train_loss: 0.1439 Train_dice: 0.8561\n",
            "30/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "31/326, Train_loss: 0.2846 Train_dice: 0.7154\n",
            "32/326, Train_loss: 0.1921 Train_dice: 0.8079\n",
            "33/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "34/326, Train_loss: 0.1058 Train_dice: 0.8942\n",
            "35/326, Train_loss: 0.0978 Train_dice: 0.9022\n",
            "36/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "37/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "38/326, Train_loss: 0.2143 Train_dice: 0.7857\n",
            "39/326, Train_loss: 0.1536 Train_dice: 0.8464\n",
            "40/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "41/326, Train_loss: 0.1176 Train_dice: 0.8824\n",
            "42/326, Train_loss: 0.0953 Train_dice: 0.9047\n",
            "43/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "44/326, Train_loss: 0.0623 Train_dice: 0.9377\n",
            "45/326, Train_loss: 0.0742 Train_dice: 0.9258\n",
            "46/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "47/326, Train_loss: 0.2777 Train_dice: 0.7223\n",
            "48/326, Train_loss: 0.0732 Train_dice: 0.9268\n",
            "49/326, Train_loss: 0.1551 Train_dice: 0.8449\n",
            "50/326, Train_loss: 0.1741 Train_dice: 0.8259\n",
            "51/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "52/326, Train_loss: 0.1915 Train_dice: 0.8085\n",
            "53/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "54/326, Train_loss: 0.1127 Train_dice: 0.8873\n",
            "55/326, Train_loss: 0.0859 Train_dice: 0.9141\n",
            "56/326, Train_loss: 0.1065 Train_dice: 0.8935\n",
            "57/326, Train_loss: 0.0804 Train_dice: 0.9196\n",
            "58/326, Train_loss: 0.0745 Train_dice: 0.9255\n",
            "59/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "60/326, Train_loss: 0.0869 Train_dice: 0.9131\n",
            "61/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "62/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "63/326, Train_loss: 0.1886 Train_dice: 0.8114\n",
            "64/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "65/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "66/326, Train_loss: 0.1627 Train_dice: 0.8373\n",
            "67/326, Train_loss: 0.0715 Train_dice: 0.9285\n",
            "68/326, Train_loss: 0.1544 Train_dice: 0.8456\n",
            "69/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "70/326, Train_loss: 0.3084 Train_dice: 0.6916\n",
            "71/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "72/326, Train_loss: 0.2379 Train_dice: 0.7621\n",
            "73/326, Train_loss: 0.1044 Train_dice: 0.8956\n",
            "74/326, Train_loss: 0.0801 Train_dice: 0.9199\n",
            "75/326, Train_loss: 0.1097 Train_dice: 0.8903\n",
            "76/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "77/326, Train_loss: 0.2189 Train_dice: 0.7811\n",
            "78/326, Train_loss: 0.1702 Train_dice: 0.8298\n",
            "79/326, Train_loss: 0.2286 Train_dice: 0.7714\n",
            "80/326, Train_loss: 0.0841 Train_dice: 0.9159\n",
            "81/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "82/326, Train_loss: 0.0750 Train_dice: 0.9250\n",
            "83/326, Train_loss: 0.1674 Train_dice: 0.8326\n",
            "84/326, Train_loss: 0.3031 Train_dice: 0.6969\n",
            "85/326, Train_loss: 0.1351 Train_dice: 0.8649\n",
            "86/326, Train_loss: 0.0683 Train_dice: 0.9317\n",
            "87/326, Train_loss: 0.0839 Train_dice: 0.9161\n",
            "88/326, Train_loss: 0.1656 Train_dice: 0.8344\n",
            "89/326, Train_loss: 0.0551 Train_dice: 0.9449\n",
            "90/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "91/326, Train_loss: 0.1129 Train_dice: 0.8871\n",
            "92/326, Train_loss: 0.1269 Train_dice: 0.8731\n",
            "93/326, Train_loss: 0.2395 Train_dice: 0.7605\n",
            "94/326, Train_loss: 0.1734 Train_dice: 0.8266\n",
            "95/326, Train_loss: 0.3212 Train_dice: 0.6788\n",
            "96/326, Train_loss: 0.1196 Train_dice: 0.8804\n",
            "97/326, Train_loss: 0.0939 Train_dice: 0.9061\n",
            "98/326, Train_loss: 0.2176 Train_dice: 0.7824\n",
            "99/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "100/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "101/326, Train_loss: 0.1220 Train_dice: 0.8780\n",
            "102/326, Train_loss: 0.1069 Train_dice: 0.8931\n",
            "103/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "104/326, Train_loss: 0.1301 Train_dice: 0.8699\n",
            "105/326, Train_loss: 0.0939 Train_dice: 0.9061\n",
            "106/326, Train_loss: 0.1258 Train_dice: 0.8742\n",
            "107/326, Train_loss: 0.1299 Train_dice: 0.8701\n",
            "108/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "109/326, Train_loss: 0.1235 Train_dice: 0.8765\n",
            "110/326, Train_loss: 0.2285 Train_dice: 0.7715\n",
            "111/326, Train_loss: 0.0889 Train_dice: 0.9111\n",
            "112/326, Train_loss: 0.2544 Train_dice: 0.7456\n",
            "113/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "114/326, Train_loss: 0.1293 Train_dice: 0.8707\n",
            "115/326, Train_loss: 0.1832 Train_dice: 0.8168\n",
            "116/326, Train_loss: 0.3086 Train_dice: 0.6914\n",
            "117/326, Train_loss: 0.1156 Train_dice: 0.8844\n",
            "118/326, Train_loss: 0.2718 Train_dice: 0.7282\n",
            "119/326, Train_loss: 0.1531 Train_dice: 0.8469\n",
            "120/326, Train_loss: 0.0884 Train_dice: 0.9116\n",
            "121/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "122/326, Train_loss: 0.0755 Train_dice: 0.9245\n",
            "123/326, Train_loss: 0.1081 Train_dice: 0.8919\n",
            "124/326, Train_loss: 0.1709 Train_dice: 0.8291\n",
            "125/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "126/326, Train_loss: 0.2327 Train_dice: 0.7673\n",
            "127/326, Train_loss: 0.1141 Train_dice: 0.8859\n",
            "128/326, Train_loss: 0.1891 Train_dice: 0.8109\n",
            "129/326, Train_loss: 0.4965 Train_dice: 0.5035\n",
            "130/326, Train_loss: 0.2213 Train_dice: 0.7787\n",
            "131/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "132/326, Train_loss: 0.2197 Train_dice: 0.7803\n",
            "133/326, Train_loss: 0.1657 Train_dice: 0.8343\n",
            "134/326, Train_loss: 0.3588 Train_dice: 0.6412\n",
            "135/326, Train_loss: 0.1713 Train_dice: 0.8287\n",
            "136/326, Train_loss: 0.2323 Train_dice: 0.7677\n",
            "137/326, Train_loss: 0.1695 Train_dice: 0.8305\n",
            "138/326, Train_loss: 0.1085 Train_dice: 0.8915\n",
            "139/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "140/326, Train_loss: 0.1761 Train_dice: 0.8239\n",
            "141/326, Train_loss: 0.0891 Train_dice: 0.9109\n",
            "142/326, Train_loss: 0.2341 Train_dice: 0.7659\n",
            "143/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "144/326, Train_loss: 0.1481 Train_dice: 0.8519\n",
            "145/326, Train_loss: 0.2943 Train_dice: 0.7057\n",
            "146/326, Train_loss: 0.1497 Train_dice: 0.8503\n",
            "147/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "148/326, Train_loss: 0.2034 Train_dice: 0.7966\n",
            "149/326, Train_loss: 0.1276 Train_dice: 0.8724\n",
            "150/326, Train_loss: 0.2286 Train_dice: 0.7714\n",
            "151/326, Train_loss: 0.1596 Train_dice: 0.8404\n",
            "152/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "153/326, Train_loss: 0.2687 Train_dice: 0.7313\n",
            "154/326, Train_loss: 0.1315 Train_dice: 0.8685\n",
            "155/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "156/326, Train_loss: 0.1339 Train_dice: 0.8661\n",
            "157/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "158/326, Train_loss: 0.3166 Train_dice: 0.6834\n",
            "159/326, Train_loss: 0.1104 Train_dice: 0.8896\n",
            "160/326, Train_loss: 0.1089 Train_dice: 0.8911\n",
            "161/326, Train_loss: 0.1635 Train_dice: 0.8365\n",
            "162/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "163/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "164/326, Train_loss: 0.1888 Train_dice: 0.8112\n",
            "165/326, Train_loss: 0.2546 Train_dice: 0.7454\n",
            "166/326, Train_loss: 0.2525 Train_dice: 0.7475\n",
            "167/326, Train_loss: 0.2621 Train_dice: 0.7379\n",
            "168/326, Train_loss: 0.0688 Train_dice: 0.9312\n",
            "169/326, Train_loss: 0.2799 Train_dice: 0.7201\n",
            "170/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "171/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "172/326, Train_loss: 0.5196 Train_dice: 0.4804\n",
            "173/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "174/326, Train_loss: 0.0673 Train_dice: 0.9327\n",
            "175/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "176/326, Train_loss: 0.2370 Train_dice: 0.7630\n",
            "177/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "178/326, Train_loss: 0.2238 Train_dice: 0.7762\n",
            "179/326, Train_loss: 0.0975 Train_dice: 0.9025\n",
            "180/326, Train_loss: 0.0752 Train_dice: 0.9248\n",
            "181/326, Train_loss: 0.0882 Train_dice: 0.9118\n",
            "182/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "183/326, Train_loss: 0.2721 Train_dice: 0.7279\n",
            "184/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "185/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "186/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "187/326, Train_loss: 0.1504 Train_dice: 0.8496\n",
            "188/326, Train_loss: 0.1019 Train_dice: 0.8981\n",
            "189/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "190/326, Train_loss: 0.6134 Train_dice: 0.3866\n",
            "191/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "192/326, Train_loss: 0.4779 Train_dice: 0.5221\n",
            "193/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "194/326, Train_loss: 0.1398 Train_dice: 0.8602\n",
            "195/326, Train_loss: 0.7175 Train_dice: 0.2825\n",
            "196/326, Train_loss: 0.0444 Train_dice: 0.9556\n",
            "197/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "198/326, Train_loss: 0.1074 Train_dice: 0.8926\n",
            "199/326, Train_loss: 0.6018 Train_dice: 0.3982\n",
            "200/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "201/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "202/326, Train_loss: 0.0917 Train_dice: 0.9083\n",
            "203/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "204/326, Train_loss: 0.0724 Train_dice: 0.9276\n",
            "205/326, Train_loss: 0.6805 Train_dice: 0.3195\n",
            "206/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "207/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "208/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "209/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "210/326, Train_loss: 0.7634 Train_dice: 0.2366\n",
            "211/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "212/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "213/326, Train_loss: 0.0587 Train_dice: 0.9413\n",
            "214/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "215/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "216/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "217/326, Train_loss: 0.6497 Train_dice: 0.3503\n",
            "218/326, Train_loss: 0.6593 Train_dice: 0.3407\n",
            "219/326, Train_loss: 0.6227 Train_dice: 0.3773\n",
            "220/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "221/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "222/326, Train_loss: 0.1318 Train_dice: 0.8682\n",
            "223/326, Train_loss: 0.1354 Train_dice: 0.8646\n",
            "224/326, Train_loss: 0.0626 Train_dice: 0.9374\n",
            "225/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "226/326, Train_loss: 0.0784 Train_dice: 0.9216\n",
            "227/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "228/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "229/326, Train_loss: 0.0863 Train_dice: 0.9137\n",
            "230/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "231/326, Train_loss: 0.6893 Train_dice: 0.3107\n",
            "232/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "233/326, Train_loss: 0.8259 Train_dice: 0.1741\n",
            "234/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "235/326, Train_loss: 0.7952 Train_dice: 0.2048\n",
            "236/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "237/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "238/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "239/326, Train_loss: 0.0723 Train_dice: 0.9277\n",
            "240/326, Train_loss: 0.7367 Train_dice: 0.2633\n",
            "241/326, Train_loss: 0.5778 Train_dice: 0.4222\n",
            "242/326, Train_loss: 0.7608 Train_dice: 0.2392\n",
            "243/326, Train_loss: 0.0431 Train_dice: 0.9569\n",
            "244/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "245/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "246/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "247/326, Train_loss: 0.0498 Train_dice: 0.9502\n",
            "248/326, Train_loss: 0.6856 Train_dice: 0.3144\n",
            "249/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "250/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "251/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "252/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "253/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "254/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "255/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "256/326, Train_loss: 0.6490 Train_dice: 0.3510\n",
            "257/326, Train_loss: 0.1078 Train_dice: 0.8922\n",
            "258/326, Train_loss: 0.7488 Train_dice: 0.2512\n",
            "259/326, Train_loss: 0.6220 Train_dice: 0.3780\n",
            "260/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "261/326, Train_loss: 0.6338 Train_dice: 0.3662\n",
            "262/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "263/326, Train_loss: 0.5391 Train_dice: 0.4609\n",
            "264/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "265/326, Train_loss: 0.6937 Train_dice: 0.3063\n",
            "266/326, Train_loss: 0.6195 Train_dice: 0.3805\n",
            "267/326, Train_loss: 0.1603 Train_dice: 0.8397\n",
            "268/326, Train_loss: 0.5948 Train_dice: 0.4052\n",
            "269/326, Train_loss: 0.5115 Train_dice: 0.4885\n",
            "270/326, Train_loss: 0.2026 Train_dice: 0.7974\n",
            "271/326, Train_loss: 0.1377 Train_dice: 0.8623\n",
            "272/326, Train_loss: 0.1174 Train_dice: 0.8826\n",
            "273/326, Train_loss: 0.1440 Train_dice: 0.8560\n",
            "274/326, Train_loss: 0.4888 Train_dice: 0.5112\n",
            "275/326, Train_loss: 0.5318 Train_dice: 0.4682\n",
            "276/326, Train_loss: 0.1028 Train_dice: 0.8972\n",
            "277/326, Train_loss: 0.0869 Train_dice: 0.9131\n",
            "278/326, Train_loss: 0.2083 Train_dice: 0.7917\n",
            "279/326, Train_loss: 0.4449 Train_dice: 0.5551\n",
            "280/326, Train_loss: 0.3986 Train_dice: 0.6014\n",
            "281/326, Train_loss: 0.1076 Train_dice: 0.8924\n",
            "282/326, Train_loss: 0.3014 Train_dice: 0.6986\n",
            "283/326, Train_loss: 0.2497 Train_dice: 0.7503\n",
            "284/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "285/326, Train_loss: 0.1946 Train_dice: 0.8054\n",
            "286/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "287/326, Train_loss: 0.1612 Train_dice: 0.8388\n",
            "288/326, Train_loss: 0.0707 Train_dice: 0.9293\n",
            "289/326, Train_loss: 0.1091 Train_dice: 0.8909\n",
            "290/326, Train_loss: 0.1412 Train_dice: 0.8588\n",
            "291/326, Train_loss: 0.2243 Train_dice: 0.7757\n",
            "292/326, Train_loss: 0.1490 Train_dice: 0.8510\n",
            "293/326, Train_loss: 0.1462 Train_dice: 0.8538\n",
            "294/326, Train_loss: 0.0868 Train_dice: 0.9132\n",
            "295/326, Train_loss: 0.2029 Train_dice: 0.7971\n",
            "296/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "297/326, Train_loss: 0.1542 Train_dice: 0.8458\n",
            "298/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "299/326, Train_loss: 0.1343 Train_dice: 0.8657\n",
            "300/326, Train_loss: 0.5551 Train_dice: 0.4449\n",
            "301/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "302/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "303/326, Train_loss: 0.5927 Train_dice: 0.4073\n",
            "304/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "305/326, Train_loss: 0.3746 Train_dice: 0.6254\n",
            "306/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "307/326, Train_loss: 0.2222 Train_dice: 0.7778\n",
            "308/326, Train_loss: 0.0966 Train_dice: 0.9034\n",
            "309/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "310/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "311/326, Train_loss: 0.1166 Train_dice: 0.8834\n",
            "312/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "313/326, Train_loss: 0.0904 Train_dice: 0.9096\n",
            "314/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "315/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "316/326, Train_loss: 0.1167 Train_dice: 0.8833\n",
            "317/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "318/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "319/326, Train_loss: 0.0811 Train_dice: 0.9189\n",
            "320/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "321/326, Train_loss: 0.1770 Train_dice: 0.8230\n",
            "322/326, Train_loss: 0.0763 Train_dice: 0.9237\n",
            "323/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "324/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "325/326, Train_loss: 0.0662 Train_dice: 0.9338\n",
            "326/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "--------------------\n",
            "Epoch_loss: 0.1720\n",
            "Epoch_metric: 0.8280\n",
            "test_loss_epoch: 0.6774\n",
            "test_dice_epoch: 0.3226\n",
            "current epoch: 130 current mean dice: 0.3226\n",
            "best mean dice: 0.6180 \n",
            "mean jaccard index: 0.0000 at epoch: -2\n",
            "Time Taken:  1621.440414905548\n",
            "Maximum GPU Memory taken for training:  0\n",
            "Maximum CPU Memory taken for training:  229\n",
            "----------\n",
            "epoch 131/250\n",
            "1/326, Train_loss: 0.2119 Train_dice: 0.7881\n",
            "2/326, Train_loss: 0.2610 Train_dice: 0.7390\n",
            "3/326, Train_loss: 0.2895 Train_dice: 0.7105\n",
            "4/326, Train_loss: 0.1100 Train_dice: 0.8900\n",
            "5/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "6/326, Train_loss: 0.2161 Train_dice: 0.7839\n",
            "7/326, Train_loss: 0.1119 Train_dice: 0.8881\n",
            "8/326, Train_loss: 0.0799 Train_dice: 0.9201\n",
            "9/326, Train_loss: 0.1428 Train_dice: 0.8572\n",
            "10/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "11/326, Train_loss: 0.2288 Train_dice: 0.7712\n",
            "12/326, Train_loss: 0.2523 Train_dice: 0.7477\n",
            "13/326, Train_loss: 0.1758 Train_dice: 0.8242\n",
            "14/326, Train_loss: 0.0937 Train_dice: 0.9063\n",
            "15/326, Train_loss: 0.4613 Train_dice: 0.5387\n",
            "16/326, Train_loss: 0.1121 Train_dice: 0.8879\n",
            "17/326, Train_loss: 0.2960 Train_dice: 0.7040\n",
            "18/326, Train_loss: 0.2483 Train_dice: 0.7517\n",
            "19/326, Train_loss: 0.1140 Train_dice: 0.8860\n",
            "20/326, Train_loss: 0.1890 Train_dice: 0.8110\n",
            "21/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "22/326, Train_loss: 0.1109 Train_dice: 0.8891\n",
            "23/326, Train_loss: 0.0873 Train_dice: 0.9127\n",
            "24/326, Train_loss: 0.2239 Train_dice: 0.7761\n",
            "25/326, Train_loss: 0.1351 Train_dice: 0.8649\n",
            "26/326, Train_loss: 0.0626 Train_dice: 0.9374\n",
            "27/326, Train_loss: 0.1018 Train_dice: 0.8982\n",
            "28/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "29/326, Train_loss: 0.1327 Train_dice: 0.8673\n",
            "30/326, Train_loss: 0.0853 Train_dice: 0.9147\n",
            "31/326, Train_loss: 0.2720 Train_dice: 0.7280\n",
            "32/326, Train_loss: 0.1824 Train_dice: 0.8176\n",
            "33/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "34/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "35/326, Train_loss: 0.0921 Train_dice: 0.9079\n",
            "36/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "37/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "38/326, Train_loss: 0.2053 Train_dice: 0.7947\n",
            "39/326, Train_loss: 0.1485 Train_dice: 0.8515\n",
            "40/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "41/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "42/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "43/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "44/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "45/326, Train_loss: 0.0681 Train_dice: 0.9319\n",
            "46/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "47/326, Train_loss: 0.2616 Train_dice: 0.7384\n",
            "48/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "49/326, Train_loss: 0.1456 Train_dice: 0.8544\n",
            "50/326, Train_loss: 0.1642 Train_dice: 0.8358\n",
            "51/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "52/326, Train_loss: 0.1851 Train_dice: 0.8149\n",
            "53/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "54/326, Train_loss: 0.1055 Train_dice: 0.8945\n",
            "55/326, Train_loss: 0.0821 Train_dice: 0.9179\n",
            "56/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "57/326, Train_loss: 0.0728 Train_dice: 0.9272\n",
            "58/326, Train_loss: 0.0686 Train_dice: 0.9314\n",
            "59/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "60/326, Train_loss: 0.0829 Train_dice: 0.9171\n",
            "61/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "62/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "63/326, Train_loss: 0.1798 Train_dice: 0.8202\n",
            "64/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "65/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "66/326, Train_loss: 0.1576 Train_dice: 0.8424\n",
            "67/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "68/326, Train_loss: 0.1467 Train_dice: 0.8533\n",
            "69/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "70/326, Train_loss: 0.2973 Train_dice: 0.7027\n",
            "71/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "72/326, Train_loss: 0.2283 Train_dice: 0.7717\n",
            "73/326, Train_loss: 0.1006 Train_dice: 0.8994\n",
            "74/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "75/326, Train_loss: 0.1028 Train_dice: 0.8972\n",
            "76/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "77/326, Train_loss: 0.2082 Train_dice: 0.7918\n",
            "78/326, Train_loss: 0.1599 Train_dice: 0.8401\n",
            "79/326, Train_loss: 0.2217 Train_dice: 0.7783\n",
            "80/326, Train_loss: 0.0763 Train_dice: 0.9237\n",
            "81/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "82/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "83/326, Train_loss: 0.1588 Train_dice: 0.8412\n",
            "84/326, Train_loss: 0.2915 Train_dice: 0.7085\n",
            "85/326, Train_loss: 0.1291 Train_dice: 0.8709\n",
            "86/326, Train_loss: 0.0664 Train_dice: 0.9336\n",
            "87/326, Train_loss: 0.0796 Train_dice: 0.9204\n",
            "88/326, Train_loss: 0.1569 Train_dice: 0.8431\n",
            "89/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "90/326, Train_loss: 0.0584 Train_dice: 0.9416\n",
            "91/326, Train_loss: 0.1066 Train_dice: 0.8934\n",
            "92/326, Train_loss: 0.1184 Train_dice: 0.8816\n",
            "93/326, Train_loss: 0.2294 Train_dice: 0.7706\n",
            "94/326, Train_loss: 0.1660 Train_dice: 0.8340\n",
            "95/326, Train_loss: 0.3105 Train_dice: 0.6895\n",
            "96/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "97/326, Train_loss: 0.0888 Train_dice: 0.9112\n",
            "98/326, Train_loss: 0.2092 Train_dice: 0.7908\n",
            "99/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "100/326, Train_loss: 0.0685 Train_dice: 0.9315\n",
            "101/326, Train_loss: 0.1162 Train_dice: 0.8838\n",
            "102/326, Train_loss: 0.0989 Train_dice: 0.9011\n",
            "103/326, Train_loss: 0.0877 Train_dice: 0.9123\n",
            "104/326, Train_loss: 0.1224 Train_dice: 0.8776\n",
            "105/326, Train_loss: 0.0896 Train_dice: 0.9104\n",
            "106/326, Train_loss: 0.1190 Train_dice: 0.8810\n",
            "107/326, Train_loss: 0.1227 Train_dice: 0.8773\n",
            "108/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "109/326, Train_loss: 0.1166 Train_dice: 0.8834\n",
            "110/326, Train_loss: 0.2221 Train_dice: 0.7779\n",
            "111/326, Train_loss: 0.0839 Train_dice: 0.9161\n",
            "112/326, Train_loss: 0.2438 Train_dice: 0.7562\n",
            "113/326, Train_loss: 0.0898 Train_dice: 0.9102\n",
            "114/326, Train_loss: 0.1223 Train_dice: 0.8777\n",
            "115/326, Train_loss: 0.1737 Train_dice: 0.8263\n",
            "116/326, Train_loss: 0.2983 Train_dice: 0.7017\n",
            "117/326, Train_loss: 0.1085 Train_dice: 0.8915\n",
            "118/326, Train_loss: 0.2599 Train_dice: 0.7401\n",
            "119/326, Train_loss: 0.1447 Train_dice: 0.8553\n",
            "120/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "121/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "122/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "123/326, Train_loss: 0.1045 Train_dice: 0.8955\n",
            "124/326, Train_loss: 0.1632 Train_dice: 0.8368\n",
            "125/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "126/326, Train_loss: 0.2220 Train_dice: 0.7780\n",
            "127/326, Train_loss: 0.1058 Train_dice: 0.8942\n",
            "128/326, Train_loss: 0.1800 Train_dice: 0.8200\n",
            "129/326, Train_loss: 0.3534 Train_dice: 0.6466\n",
            "130/326, Train_loss: 0.2125 Train_dice: 0.7875\n",
            "131/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "132/326, Train_loss: 0.2089 Train_dice: 0.7911\n",
            "133/326, Train_loss: 0.1535 Train_dice: 0.8465\n",
            "134/326, Train_loss: 0.3482 Train_dice: 0.6518\n",
            "135/326, Train_loss: 0.1606 Train_dice: 0.8394\n",
            "136/326, Train_loss: 0.2227 Train_dice: 0.7773\n",
            "137/326, Train_loss: 0.1594 Train_dice: 0.8406\n",
            "138/326, Train_loss: 0.0981 Train_dice: 0.9019\n",
            "139/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "140/326, Train_loss: 0.1650 Train_dice: 0.8350\n",
            "141/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "142/326, Train_loss: 0.2226 Train_dice: 0.7774\n",
            "143/326, Train_loss: 0.0595 Train_dice: 0.9405\n",
            "144/326, Train_loss: 0.1367 Train_dice: 0.8633\n",
            "145/326, Train_loss: 0.2833 Train_dice: 0.7167\n",
            "146/326, Train_loss: 0.1423 Train_dice: 0.8577\n",
            "147/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "148/326, Train_loss: 0.1976 Train_dice: 0.8024\n",
            "149/326, Train_loss: 0.1222 Train_dice: 0.8778\n",
            "150/326, Train_loss: 0.2185 Train_dice: 0.7815\n",
            "151/326, Train_loss: 0.1532 Train_dice: 0.8468\n",
            "152/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "153/326, Train_loss: 0.2555 Train_dice: 0.7445\n",
            "154/326, Train_loss: 0.1251 Train_dice: 0.8749\n",
            "155/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "156/326, Train_loss: 0.1289 Train_dice: 0.8711\n",
            "157/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "158/326, Train_loss: 0.3036 Train_dice: 0.6964\n",
            "159/326, Train_loss: 0.1039 Train_dice: 0.8961\n",
            "160/326, Train_loss: 0.1020 Train_dice: 0.8980\n",
            "161/326, Train_loss: 0.1538 Train_dice: 0.8462\n",
            "162/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "163/326, Train_loss: 0.0558 Train_dice: 0.9442\n",
            "164/326, Train_loss: 0.1006 Train_dice: 0.8994\n",
            "165/326, Train_loss: 0.2383 Train_dice: 0.7617\n",
            "166/326, Train_loss: 0.2384 Train_dice: 0.7616\n",
            "167/326, Train_loss: 0.2356 Train_dice: 0.7644\n",
            "168/326, Train_loss: 0.0585 Train_dice: 0.9415\n",
            "169/326, Train_loss: 0.1872 Train_dice: 0.8128\n",
            "170/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "171/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "172/326, Train_loss: 0.3637 Train_dice: 0.6363\n",
            "173/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "174/326, Train_loss: 0.0616 Train_dice: 0.9384\n",
            "175/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "176/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "177/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "178/326, Train_loss: 0.1020 Train_dice: 0.8980\n",
            "179/326, Train_loss: 0.0728 Train_dice: 0.9272\n",
            "180/326, Train_loss: 0.2742 Train_dice: 0.7258\n",
            "181/326, Train_loss: 0.1095 Train_dice: 0.8905\n",
            "182/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "183/326, Train_loss: 0.1818 Train_dice: 0.8182\n",
            "184/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "185/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "186/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "187/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "188/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "189/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "190/326, Train_loss: 0.5575 Train_dice: 0.4425\n",
            "191/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "192/326, Train_loss: 0.1344 Train_dice: 0.8656\n",
            "193/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "194/326, Train_loss: 0.0914 Train_dice: 0.9086\n",
            "195/326, Train_loss: 0.7263 Train_dice: 0.2737\n",
            "196/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "197/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "198/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "199/326, Train_loss: 0.5159 Train_dice: 0.4841\n",
            "200/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "201/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "202/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "203/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "204/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "205/326, Train_loss: 0.6698 Train_dice: 0.3302\n",
            "206/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "207/326, Train_loss: 0.0510 Train_dice: 0.9490\n",
            "208/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "209/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "210/326, Train_loss: 0.7343 Train_dice: 0.2657\n",
            "211/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "212/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "213/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "214/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "215/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "216/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "217/326, Train_loss: 0.5591 Train_dice: 0.4409\n",
            "218/326, Train_loss: 0.6446 Train_dice: 0.3554\n",
            "219/326, Train_loss: 0.5794 Train_dice: 0.4206\n",
            "220/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "221/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "222/326, Train_loss: 0.1083 Train_dice: 0.8917\n",
            "223/326, Train_loss: 0.1143 Train_dice: 0.8857\n",
            "224/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "225/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "226/326, Train_loss: 0.0951 Train_dice: 0.9049\n",
            "227/326, Train_loss: 0.0363 Train_dice: 0.9637\n",
            "228/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "229/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "230/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "231/326, Train_loss: 0.5882 Train_dice: 0.4118\n",
            "232/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "233/326, Train_loss: 0.7882 Train_dice: 0.2118\n",
            "234/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "235/326, Train_loss: 0.6962 Train_dice: 0.3038\n",
            "236/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "237/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "238/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "239/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "240/326, Train_loss: 0.4326 Train_dice: 0.5674\n",
            "241/326, Train_loss: 0.2437 Train_dice: 0.7563\n",
            "242/326, Train_loss: 0.7230 Train_dice: 0.2770\n",
            "243/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "244/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "245/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "246/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "247/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "248/326, Train_loss: 0.4029 Train_dice: 0.5971\n",
            "249/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "250/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "251/326, Train_loss: 0.0778 Train_dice: 0.9222\n",
            "252/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "253/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "254/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "255/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "256/326, Train_loss: 0.5722 Train_dice: 0.4278\n",
            "257/326, Train_loss: 0.0857 Train_dice: 0.9143\n",
            "258/326, Train_loss: 0.4482 Train_dice: 0.5518\n",
            "259/326, Train_loss: 0.5156 Train_dice: 0.4844\n",
            "260/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "261/326, Train_loss: 0.2491 Train_dice: 0.7509\n",
            "262/326, Train_loss: 0.0431 Train_dice: 0.9569\n",
            "263/326, Train_loss: 0.4843 Train_dice: 0.5157\n",
            "264/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "265/326, Train_loss: 0.6417 Train_dice: 0.3583\n",
            "266/326, Train_loss: 0.5375 Train_dice: 0.4625\n",
            "267/326, Train_loss: 0.1467 Train_dice: 0.8533\n",
            "268/326, Train_loss: 0.5082 Train_dice: 0.4918\n",
            "269/326, Train_loss: 0.1749 Train_dice: 0.8251\n",
            "270/326, Train_loss: 0.1768 Train_dice: 0.8232\n",
            "271/326, Train_loss: 0.1033 Train_dice: 0.8967\n",
            "272/326, Train_loss: 0.0882 Train_dice: 0.9118\n",
            "273/326, Train_loss: 0.1906 Train_dice: 0.8094\n",
            "274/326, Train_loss: 0.2499 Train_dice: 0.7501\n",
            "275/326, Train_loss: 0.2652 Train_dice: 0.7348\n",
            "276/326, Train_loss: 0.1121 Train_dice: 0.8879\n",
            "277/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "278/326, Train_loss: 0.1854 Train_dice: 0.8146\n",
            "279/326, Train_loss: 0.2678 Train_dice: 0.7322\n",
            "280/326, Train_loss: 0.2218 Train_dice: 0.7782\n",
            "281/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "282/326, Train_loss: 0.1790 Train_dice: 0.8210\n",
            "283/326, Train_loss: 0.1665 Train_dice: 0.8335\n",
            "284/326, Train_loss: 0.0500 Train_dice: 0.9500\n",
            "285/326, Train_loss: 0.1350 Train_dice: 0.8650\n",
            "286/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "287/326, Train_loss: 0.1456 Train_dice: 0.8544\n",
            "288/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "289/326, Train_loss: 0.0901 Train_dice: 0.9099\n",
            "290/326, Train_loss: 0.0815 Train_dice: 0.9185\n",
            "291/326, Train_loss: 0.1271 Train_dice: 0.8729\n",
            "292/326, Train_loss: 0.1117 Train_dice: 0.8883\n",
            "293/326, Train_loss: 0.0905 Train_dice: 0.9095\n",
            "294/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "295/326, Train_loss: 0.1848 Train_dice: 0.8152\n",
            "296/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "297/326, Train_loss: 0.1361 Train_dice: 0.8639\n",
            "298/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "299/326, Train_loss: 0.1110 Train_dice: 0.8890\n",
            "300/326, Train_loss: 0.2531 Train_dice: 0.7469\n",
            "301/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "302/326, Train_loss: 0.0439 Train_dice: 0.9561\n",
            "303/326, Train_loss: 0.2799 Train_dice: 0.7201\n",
            "304/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "305/326, Train_loss: 0.1340 Train_dice: 0.8660\n",
            "306/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "307/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "308/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "309/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "310/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "311/326, Train_loss: 0.0921 Train_dice: 0.9079\n",
            "312/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "313/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "314/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "315/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "316/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "317/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "318/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "319/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "320/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "321/326, Train_loss: 0.1873 Train_dice: 0.8127\n",
            "322/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "323/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "324/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "325/326, Train_loss: 0.0515 Train_dice: 0.9485\n",
            "326/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "--------------------\n",
            "Epoch_loss: 0.1437\n",
            "Epoch_metric: 0.8563\n",
            "----------\n",
            "epoch 132/250\n",
            "1/326, Train_loss: 0.1834 Train_dice: 0.8166\n",
            "2/326, Train_loss: 0.2370 Train_dice: 0.7630\n",
            "3/326, Train_loss: 0.2707 Train_dice: 0.7293\n",
            "4/326, Train_loss: 0.0681 Train_dice: 0.9319\n",
            "5/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "6/326, Train_loss: 0.2042 Train_dice: 0.7958\n",
            "7/326, Train_loss: 0.1012 Train_dice: 0.8988\n",
            "8/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "9/326, Train_loss: 0.1276 Train_dice: 0.8724\n",
            "10/326, Train_loss: 0.0858 Train_dice: 0.9142\n",
            "11/326, Train_loss: 0.2207 Train_dice: 0.7793\n",
            "12/326, Train_loss: 0.2417 Train_dice: 0.7583\n",
            "13/326, Train_loss: 0.1442 Train_dice: 0.8558\n",
            "14/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "15/326, Train_loss: 0.2950 Train_dice: 0.7050\n",
            "16/326, Train_loss: 0.1064 Train_dice: 0.8936\n",
            "17/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "18/326, Train_loss: 0.2602 Train_dice: 0.7398\n",
            "19/326, Train_loss: 0.5862 Train_dice: 0.4138\n",
            "20/326, Train_loss: 0.1789 Train_dice: 0.8211\n",
            "21/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "22/326, Train_loss: 0.1064 Train_dice: 0.8936\n",
            "23/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "24/326, Train_loss: 0.2357 Train_dice: 0.7643\n",
            "25/326, Train_loss: 0.1326 Train_dice: 0.8674\n",
            "26/326, Train_loss: 0.0592 Train_dice: 0.9408\n",
            "27/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "28/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "29/326, Train_loss: 0.1284 Train_dice: 0.8716\n",
            "30/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "31/326, Train_loss: 0.2594 Train_dice: 0.7406\n",
            "32/326, Train_loss: 0.1706 Train_dice: 0.8294\n",
            "33/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "34/326, Train_loss: 0.0885 Train_dice: 0.9115\n",
            "35/326, Train_loss: 0.0884 Train_dice: 0.9116\n",
            "36/326, Train_loss: 0.0739 Train_dice: 0.9261\n",
            "37/326, Train_loss: 0.0756 Train_dice: 0.9244\n",
            "38/326, Train_loss: 0.1941 Train_dice: 0.8059\n",
            "39/326, Train_loss: 0.1410 Train_dice: 0.8590\n",
            "40/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "41/326, Train_loss: 0.1036 Train_dice: 0.8964\n",
            "42/326, Train_loss: 0.0861 Train_dice: 0.9139\n",
            "43/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "44/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "45/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "46/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "47/326, Train_loss: 0.2517 Train_dice: 0.7483\n",
            "48/326, Train_loss: 0.0631 Train_dice: 0.9369\n",
            "49/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "50/326, Train_loss: 0.1552 Train_dice: 0.8448\n",
            "51/326, Train_loss: 0.0392 Train_dice: 0.9608\n",
            "52/326, Train_loss: 0.1725 Train_dice: 0.8275\n",
            "53/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "54/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "55/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "56/326, Train_loss: 0.0937 Train_dice: 0.9063\n",
            "57/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "58/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "59/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "60/326, Train_loss: 0.0791 Train_dice: 0.9209\n",
            "61/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "62/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "63/326, Train_loss: 0.1705 Train_dice: 0.8295\n",
            "64/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "65/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "66/326, Train_loss: 0.1490 Train_dice: 0.8510\n",
            "67/326, Train_loss: 0.0546 Train_dice: 0.9454\n",
            "68/326, Train_loss: 0.1392 Train_dice: 0.8608\n",
            "69/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "70/326, Train_loss: 0.2853 Train_dice: 0.7147\n",
            "71/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "72/326, Train_loss: 0.2168 Train_dice: 0.7832\n",
            "73/326, Train_loss: 0.0941 Train_dice: 0.9059\n",
            "74/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "75/326, Train_loss: 0.0979 Train_dice: 0.9021\n",
            "76/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "77/326, Train_loss: 0.1996 Train_dice: 0.8004\n",
            "78/326, Train_loss: 0.1532 Train_dice: 0.8468\n",
            "79/326, Train_loss: 0.2098 Train_dice: 0.7902\n",
            "80/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "81/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "82/326, Train_loss: 0.0654 Train_dice: 0.9346\n",
            "83/326, Train_loss: 0.1517 Train_dice: 0.8483\n",
            "84/326, Train_loss: 0.2813 Train_dice: 0.7187\n",
            "85/326, Train_loss: 0.1274 Train_dice: 0.8726\n",
            "86/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "87/326, Train_loss: 0.0747 Train_dice: 0.9253\n",
            "88/326, Train_loss: 0.1522 Train_dice: 0.8478\n",
            "89/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "90/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "91/326, Train_loss: 0.1013 Train_dice: 0.8987\n",
            "92/326, Train_loss: 0.1109 Train_dice: 0.8891\n",
            "93/326, Train_loss: 0.2188 Train_dice: 0.7812\n",
            "94/326, Train_loss: 0.1570 Train_dice: 0.8430\n",
            "95/326, Train_loss: 0.2983 Train_dice: 0.7017\n",
            "96/326, Train_loss: 0.1086 Train_dice: 0.8914\n",
            "97/326, Train_loss: 0.0843 Train_dice: 0.9157\n",
            "98/326, Train_loss: 0.2002 Train_dice: 0.7998\n",
            "99/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "100/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "101/326, Train_loss: 0.1088 Train_dice: 0.8912\n",
            "102/326, Train_loss: 0.0934 Train_dice: 0.9066\n",
            "103/326, Train_loss: 0.0831 Train_dice: 0.9169\n",
            "104/326, Train_loss: 0.1156 Train_dice: 0.8844\n",
            "105/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "106/326, Train_loss: 0.1128 Train_dice: 0.8872\n",
            "107/326, Train_loss: 0.1169 Train_dice: 0.8831\n",
            "108/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "109/326, Train_loss: 0.1112 Train_dice: 0.8888\n",
            "110/326, Train_loss: 0.2115 Train_dice: 0.7885\n",
            "111/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "112/326, Train_loss: 0.2331 Train_dice: 0.7669\n",
            "113/326, Train_loss: 0.0847 Train_dice: 0.9153\n",
            "114/326, Train_loss: 0.1157 Train_dice: 0.8843\n",
            "115/326, Train_loss: 0.1652 Train_dice: 0.8348\n",
            "116/326, Train_loss: 0.2857 Train_dice: 0.7143\n",
            "117/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "118/326, Train_loss: 0.2480 Train_dice: 0.7520\n",
            "119/326, Train_loss: 0.1375 Train_dice: 0.8625\n",
            "120/326, Train_loss: 0.0778 Train_dice: 0.9222\n",
            "121/326, Train_loss: 0.0538 Train_dice: 0.9462\n",
            "122/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "123/326, Train_loss: 0.0964 Train_dice: 0.9036\n",
            "124/326, Train_loss: 0.1538 Train_dice: 0.8462\n",
            "125/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "126/326, Train_loss: 0.2139 Train_dice: 0.7861\n",
            "127/326, Train_loss: 0.1008 Train_dice: 0.8992\n",
            "128/326, Train_loss: 0.1706 Train_dice: 0.8294\n",
            "129/326, Train_loss: 0.3426 Train_dice: 0.6574\n",
            "130/326, Train_loss: 0.2033 Train_dice: 0.7967\n",
            "131/326, Train_loss: 0.0491 Train_dice: 0.9509\n",
            "132/326, Train_loss: 0.1988 Train_dice: 0.8012\n",
            "133/326, Train_loss: 0.1471 Train_dice: 0.8529\n",
            "134/326, Train_loss: 0.3353 Train_dice: 0.6647\n",
            "135/326, Train_loss: 0.1531 Train_dice: 0.8469\n",
            "136/326, Train_loss: 0.2110 Train_dice: 0.7890\n",
            "137/326, Train_loss: 0.1497 Train_dice: 0.8503\n",
            "138/326, Train_loss: 0.0915 Train_dice: 0.9085\n",
            "139/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "140/326, Train_loss: 0.1560 Train_dice: 0.8440\n",
            "141/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "142/326, Train_loss: 0.2113 Train_dice: 0.7887\n",
            "143/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "144/326, Train_loss: 0.1293 Train_dice: 0.8707\n",
            "145/326, Train_loss: 0.2711 Train_dice: 0.7289\n",
            "146/326, Train_loss: 0.1331 Train_dice: 0.8669\n",
            "147/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "148/326, Train_loss: 0.1861 Train_dice: 0.8139\n",
            "149/326, Train_loss: 0.1135 Train_dice: 0.8865\n",
            "150/326, Train_loss: 0.2086 Train_dice: 0.7914\n",
            "151/326, Train_loss: 0.1450 Train_dice: 0.8550\n",
            "152/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "153/326, Train_loss: 0.2432 Train_dice: 0.7568\n",
            "154/326, Train_loss: 0.1199 Train_dice: 0.8801\n",
            "155/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "156/326, Train_loss: 0.1216 Train_dice: 0.8784\n",
            "157/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "158/326, Train_loss: 0.2911 Train_dice: 0.7089\n",
            "159/326, Train_loss: 0.0980 Train_dice: 0.9020\n",
            "160/326, Train_loss: 0.0944 Train_dice: 0.9056\n",
            "161/326, Train_loss: 0.1455 Train_dice: 0.8545\n",
            "162/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "163/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "164/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "165/326, Train_loss: 0.2233 Train_dice: 0.7767\n",
            "166/326, Train_loss: 0.2217 Train_dice: 0.7783\n",
            "167/326, Train_loss: 0.1641 Train_dice: 0.8359\n",
            "168/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "169/326, Train_loss: 0.1355 Train_dice: 0.8645\n",
            "170/326, Train_loss: 0.0326 Train_dice: 0.9674\n",
            "171/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "172/326, Train_loss: 0.1580 Train_dice: 0.8420\n",
            "173/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "174/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "175/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "176/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "177/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "178/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "179/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "180/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "181/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "182/326, Train_loss: 0.3751 Train_dice: 0.6249\n",
            "183/326, Train_loss: 0.1633 Train_dice: 0.8367\n",
            "184/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "185/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "186/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "187/326, Train_loss: 0.2309 Train_dice: 0.7691\n",
            "188/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "189/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "190/326, Train_loss: 0.3806 Train_dice: 0.6194\n",
            "191/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "192/326, Train_loss: 0.1153 Train_dice: 0.8847\n",
            "193/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "194/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "195/326, Train_loss: 0.6980 Train_dice: 0.3020\n",
            "196/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "197/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "198/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "199/326, Train_loss: 0.3121 Train_dice: 0.6879\n",
            "200/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "201/326, Train_loss: 0.0671 Train_dice: 0.9329\n",
            "202/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "203/326, Train_loss: 0.0298 Train_dice: 0.9702\n",
            "204/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "205/326, Train_loss: 0.6609 Train_dice: 0.3391\n",
            "206/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "207/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "208/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "209/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "210/326, Train_loss: 0.6642 Train_dice: 0.3358\n",
            "211/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "212/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "213/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "214/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "215/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "216/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "217/326, Train_loss: 0.4418 Train_dice: 0.5582\n",
            "218/326, Train_loss: 0.5028 Train_dice: 0.4972\n",
            "219/326, Train_loss: 0.3587 Train_dice: 0.6413\n",
            "220/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "221/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "222/326, Train_loss: 0.1163 Train_dice: 0.8837\n",
            "223/326, Train_loss: 0.2773 Train_dice: 0.7227\n",
            "224/326, Train_loss: 0.0671 Train_dice: 0.9329\n",
            "225/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "226/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "227/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "228/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "229/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "230/326, Train_loss: 0.0634 Train_dice: 0.9366\n",
            "231/326, Train_loss: 0.1806 Train_dice: 0.8194\n",
            "232/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "233/326, Train_loss: 0.6704 Train_dice: 0.3296\n",
            "234/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "235/326, Train_loss: 0.3068 Train_dice: 0.6932\n",
            "236/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "237/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "238/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "239/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "240/326, Train_loss: 0.2039 Train_dice: 0.7961\n",
            "241/326, Train_loss: 0.2117 Train_dice: 0.7883\n",
            "242/326, Train_loss: 0.6608 Train_dice: 0.3392\n",
            "243/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "244/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "245/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "246/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "247/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "248/326, Train_loss: 0.1629 Train_dice: 0.8371\n",
            "249/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "250/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "251/326, Train_loss: 0.0597 Train_dice: 0.9403\n",
            "252/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "253/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "254/326, Train_loss: 0.0702 Train_dice: 0.9298\n",
            "255/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "256/326, Train_loss: 0.4387 Train_dice: 0.5613\n",
            "257/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "258/326, Train_loss: 0.3618 Train_dice: 0.6382\n",
            "259/326, Train_loss: 0.1922 Train_dice: 0.8078\n",
            "260/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "261/326, Train_loss: 0.2312 Train_dice: 0.7688\n",
            "262/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "263/326, Train_loss: 0.3193 Train_dice: 0.6807\n",
            "264/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "265/326, Train_loss: 0.3324 Train_dice: 0.6676\n",
            "266/326, Train_loss: 0.3695 Train_dice: 0.6305\n",
            "267/326, Train_loss: 0.1243 Train_dice: 0.8757\n",
            "268/326, Train_loss: 0.2962 Train_dice: 0.7038\n",
            "269/326, Train_loss: 0.1484 Train_dice: 0.8516\n",
            "270/326, Train_loss: 0.1522 Train_dice: 0.8478\n",
            "271/326, Train_loss: 0.1160 Train_dice: 0.8840\n",
            "272/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "273/326, Train_loss: 0.0790 Train_dice: 0.9210\n",
            "274/326, Train_loss: 0.1435 Train_dice: 0.8565\n",
            "275/326, Train_loss: 0.2362 Train_dice: 0.7638\n",
            "276/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "277/326, Train_loss: 0.1559 Train_dice: 0.8441\n",
            "278/326, Train_loss: 0.1676 Train_dice: 0.8324\n",
            "279/326, Train_loss: 0.2448 Train_dice: 0.7552\n",
            "280/326, Train_loss: 0.1687 Train_dice: 0.8313\n",
            "281/326, Train_loss: 0.1431 Train_dice: 0.8569\n",
            "282/326, Train_loss: 0.1550 Train_dice: 0.8450\n",
            "283/326, Train_loss: 0.1435 Train_dice: 0.8565\n",
            "284/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "285/326, Train_loss: 0.1214 Train_dice: 0.8786\n",
            "286/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "287/326, Train_loss: 0.1300 Train_dice: 0.8700\n",
            "288/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "289/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "290/326, Train_loss: 0.0717 Train_dice: 0.9283\n",
            "291/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "292/326, Train_loss: 0.0927 Train_dice: 0.9073\n",
            "293/326, Train_loss: 0.0822 Train_dice: 0.9178\n",
            "294/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "295/326, Train_loss: 0.1697 Train_dice: 0.8303\n",
            "296/326, Train_loss: 0.0619 Train_dice: 0.9381\n",
            "297/326, Train_loss: 0.1222 Train_dice: 0.8778\n",
            "298/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "299/326, Train_loss: 0.0790 Train_dice: 0.9210\n",
            "300/326, Train_loss: 0.1965 Train_dice: 0.8035\n",
            "301/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "302/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "303/326, Train_loss: 0.2104 Train_dice: 0.7896\n",
            "304/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "305/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "306/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "307/326, Train_loss: 0.0588 Train_dice: 0.9412\n",
            "308/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "309/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "310/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "311/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "312/326, Train_loss: 0.0754 Train_dice: 0.9246\n",
            "313/326, Train_loss: 0.0637 Train_dice: 0.9363\n",
            "314/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "315/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "316/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "317/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "318/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "319/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "320/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "321/326, Train_loss: 0.1877 Train_dice: 0.8123\n",
            "322/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "323/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "324/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "325/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "326/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "--------------------\n",
            "Epoch_loss: 0.1242\n",
            "Epoch_metric: 0.8758\n",
            "----------\n",
            "epoch 133/250\n",
            "1/326, Train_loss: 0.1731 Train_dice: 0.8269\n",
            "2/326, Train_loss: 0.2279 Train_dice: 0.7721\n",
            "3/326, Train_loss: 0.2595 Train_dice: 0.7405\n",
            "4/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "5/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "6/326, Train_loss: 0.1870 Train_dice: 0.8130\n",
            "7/326, Train_loss: 0.0926 Train_dice: 0.9074\n",
            "8/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "9/326, Train_loss: 0.1066 Train_dice: 0.8934\n",
            "10/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "11/326, Train_loss: 0.2029 Train_dice: 0.7971\n",
            "12/326, Train_loss: 0.2213 Train_dice: 0.7787\n",
            "13/326, Train_loss: 0.1305 Train_dice: 0.8695\n",
            "14/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "15/326, Train_loss: 0.2821 Train_dice: 0.7179\n",
            "16/326, Train_loss: 0.0991 Train_dice: 0.9009\n",
            "17/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "18/326, Train_loss: 0.2234 Train_dice: 0.7766\n",
            "19/326, Train_loss: 0.2687 Train_dice: 0.7313\n",
            "20/326, Train_loss: 0.1671 Train_dice: 0.8329\n",
            "21/326, Train_loss: 0.0889 Train_dice: 0.9111\n",
            "22/326, Train_loss: 0.1023 Train_dice: 0.8977\n",
            "23/326, Train_loss: 0.0857 Train_dice: 0.9143\n",
            "24/326, Train_loss: 0.5808 Train_dice: 0.4192\n",
            "25/326, Train_loss: 0.1233 Train_dice: 0.8767\n",
            "26/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "27/326, Train_loss: 0.0906 Train_dice: 0.9094\n",
            "28/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "29/326, Train_loss: 0.1391 Train_dice: 0.8609\n",
            "30/326, Train_loss: 0.0748 Train_dice: 0.9252\n",
            "31/326, Train_loss: 0.2505 Train_dice: 0.7495\n",
            "32/326, Train_loss: 0.1627 Train_dice: 0.8373\n",
            "33/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "34/326, Train_loss: 0.0844 Train_dice: 0.9156\n",
            "35/326, Train_loss: 0.0823 Train_dice: 0.9177\n",
            "36/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "37/326, Train_loss: 0.0702 Train_dice: 0.9298\n",
            "38/326, Train_loss: 0.1851 Train_dice: 0.8149\n",
            "39/326, Train_loss: 0.1337 Train_dice: 0.8663\n",
            "40/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "41/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "42/326, Train_loss: 0.0799 Train_dice: 0.9201\n",
            "43/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "44/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "45/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "46/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "47/326, Train_loss: 0.2392 Train_dice: 0.7608\n",
            "48/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "49/326, Train_loss: 0.1277 Train_dice: 0.8723\n",
            "50/326, Train_loss: 0.1488 Train_dice: 0.8512\n",
            "51/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "52/326, Train_loss: 0.1651 Train_dice: 0.8349\n",
            "53/326, Train_loss: 0.0365 Train_dice: 0.9635\n",
            "54/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "55/326, Train_loss: 0.0713 Train_dice: 0.9287\n",
            "56/326, Train_loss: 0.0882 Train_dice: 0.9118\n",
            "57/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "58/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "59/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "60/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "61/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "62/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "63/326, Train_loss: 0.1626 Train_dice: 0.8374\n",
            "64/326, Train_loss: 0.0710 Train_dice: 0.9290\n",
            "65/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "66/326, Train_loss: 0.1412 Train_dice: 0.8588\n",
            "67/326, Train_loss: 0.1549 Train_dice: 0.8451\n",
            "68/326, Train_loss: 0.1330 Train_dice: 0.8670\n",
            "69/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "70/326, Train_loss: 0.2763 Train_dice: 0.7237\n",
            "71/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "72/326, Train_loss: 0.2082 Train_dice: 0.7918\n",
            "73/326, Train_loss: 0.0888 Train_dice: 0.9112\n",
            "74/326, Train_loss: 0.0658 Train_dice: 0.9342\n",
            "75/326, Train_loss: 0.0931 Train_dice: 0.9069\n",
            "76/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "77/326, Train_loss: 0.1928 Train_dice: 0.8072\n",
            "78/326, Train_loss: 0.1466 Train_dice: 0.8534\n",
            "79/326, Train_loss: 0.2007 Train_dice: 0.7993\n",
            "80/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "81/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "82/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "83/326, Train_loss: 0.1431 Train_dice: 0.8569\n",
            "84/326, Train_loss: 0.2735 Train_dice: 0.7265\n",
            "85/326, Train_loss: 0.1170 Train_dice: 0.8830\n",
            "86/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "87/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "88/326, Train_loss: 0.1443 Train_dice: 0.8557\n",
            "89/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "90/326, Train_loss: 0.0558 Train_dice: 0.9442\n",
            "91/326, Train_loss: 0.0971 Train_dice: 0.9029\n",
            "92/326, Train_loss: 0.1073 Train_dice: 0.8927\n",
            "93/326, Train_loss: 0.2111 Train_dice: 0.7889\n",
            "94/326, Train_loss: 0.1501 Train_dice: 0.8499\n",
            "95/326, Train_loss: 0.2887 Train_dice: 0.7113\n",
            "96/326, Train_loss: 0.1025 Train_dice: 0.8975\n",
            "97/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "98/326, Train_loss: 0.1918 Train_dice: 0.8082\n",
            "99/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "100/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "101/326, Train_loss: 0.1045 Train_dice: 0.8955\n",
            "102/326, Train_loss: 0.0891 Train_dice: 0.9109\n",
            "103/326, Train_loss: 0.0832 Train_dice: 0.9168\n",
            "104/326, Train_loss: 0.1102 Train_dice: 0.8898\n",
            "105/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "106/326, Train_loss: 0.1073 Train_dice: 0.8927\n",
            "107/326, Train_loss: 0.1117 Train_dice: 0.8883\n",
            "108/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "109/326, Train_loss: 0.1048 Train_dice: 0.8952\n",
            "110/326, Train_loss: 0.2014 Train_dice: 0.7986\n",
            "111/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "112/326, Train_loss: 0.2298 Train_dice: 0.7702\n",
            "113/326, Train_loss: 0.0803 Train_dice: 0.9197\n",
            "114/326, Train_loss: 0.1101 Train_dice: 0.8899\n",
            "115/326, Train_loss: 0.1579 Train_dice: 0.8421\n",
            "116/326, Train_loss: 0.2758 Train_dice: 0.7242\n",
            "117/326, Train_loss: 0.0986 Train_dice: 0.9014\n",
            "118/326, Train_loss: 0.2383 Train_dice: 0.7617\n",
            "119/326, Train_loss: 0.1321 Train_dice: 0.8679\n",
            "120/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "121/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "122/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "123/326, Train_loss: 0.0924 Train_dice: 0.9076\n",
            "124/326, Train_loss: 0.1474 Train_dice: 0.8526\n",
            "125/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "126/326, Train_loss: 0.2040 Train_dice: 0.7960\n",
            "127/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "128/326, Train_loss: 0.1640 Train_dice: 0.8360\n",
            "129/326, Train_loss: 0.3302 Train_dice: 0.6698\n",
            "130/326, Train_loss: 0.1937 Train_dice: 0.8063\n",
            "131/326, Train_loss: 0.0465 Train_dice: 0.9535\n",
            "132/326, Train_loss: 0.1901 Train_dice: 0.8099\n",
            "133/326, Train_loss: 0.1416 Train_dice: 0.8584\n",
            "134/326, Train_loss: 0.3251 Train_dice: 0.6749\n",
            "135/326, Train_loss: 0.1456 Train_dice: 0.8544\n",
            "136/326, Train_loss: 0.2024 Train_dice: 0.7976\n",
            "137/326, Train_loss: 0.1417 Train_dice: 0.8583\n",
            "138/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "139/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "140/326, Train_loss: 0.1483 Train_dice: 0.8517\n",
            "141/326, Train_loss: 0.0768 Train_dice: 0.9232\n",
            "142/326, Train_loss: 0.2006 Train_dice: 0.7994\n",
            "143/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "144/326, Train_loss: 0.1230 Train_dice: 0.8770\n",
            "145/326, Train_loss: 0.2607 Train_dice: 0.7393\n",
            "146/326, Train_loss: 0.1258 Train_dice: 0.8742\n",
            "147/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "148/326, Train_loss: 0.1784 Train_dice: 0.8216\n",
            "149/326, Train_loss: 0.1087 Train_dice: 0.8913\n",
            "150/326, Train_loss: 0.2009 Train_dice: 0.7991\n",
            "151/326, Train_loss: 0.1370 Train_dice: 0.8630\n",
            "152/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "153/326, Train_loss: 0.2321 Train_dice: 0.7679\n",
            "154/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "155/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "156/326, Train_loss: 0.1156 Train_dice: 0.8844\n",
            "157/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "158/326, Train_loss: 0.2800 Train_dice: 0.7200\n",
            "159/326, Train_loss: 0.0925 Train_dice: 0.9075\n",
            "160/326, Train_loss: 0.0894 Train_dice: 0.9106\n",
            "161/326, Train_loss: 0.1382 Train_dice: 0.8618\n",
            "162/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "163/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "164/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "165/326, Train_loss: 0.2097 Train_dice: 0.7903\n",
            "166/326, Train_loss: 0.2110 Train_dice: 0.7890\n",
            "167/326, Train_loss: 0.1646 Train_dice: 0.8354\n",
            "168/326, Train_loss: 0.0530 Train_dice: 0.9470\n",
            "169/326, Train_loss: 0.1118 Train_dice: 0.8882\n",
            "170/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "171/326, Train_loss: 0.0544 Train_dice: 0.9456\n",
            "172/326, Train_loss: 0.1792 Train_dice: 0.8208\n",
            "173/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "174/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "175/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "176/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "177/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "178/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "179/326, Train_loss: 0.0523 Train_dice: 0.9477\n",
            "180/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "181/326, Train_loss: 0.0465 Train_dice: 0.9535\n",
            "182/326, Train_loss: 0.1243 Train_dice: 0.8757\n",
            "183/326, Train_loss: 0.1438 Train_dice: 0.8562\n",
            "184/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "185/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "186/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "187/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "188/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "189/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "190/326, Train_loss: 0.1869 Train_dice: 0.8131\n",
            "191/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "192/326, Train_loss: 0.1005 Train_dice: 0.8995\n",
            "193/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "194/326, Train_loss: 0.1802 Train_dice: 0.8198\n",
            "195/326, Train_loss: 0.5841 Train_dice: 0.4159\n",
            "196/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "197/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "198/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "199/326, Train_loss: 0.1180 Train_dice: 0.8820\n",
            "200/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "201/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "202/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "203/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "204/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "205/326, Train_loss: 0.6732 Train_dice: 0.3268\n",
            "206/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "207/326, Train_loss: 0.0444 Train_dice: 0.9556\n",
            "208/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "209/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "210/326, Train_loss: 0.4055 Train_dice: 0.5945\n",
            "211/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "212/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "213/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "214/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "215/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "216/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "217/326, Train_loss: 0.1724 Train_dice: 0.8276\n",
            "218/326, Train_loss: 0.1477 Train_dice: 0.8523\n",
            "219/326, Train_loss: 0.2335 Train_dice: 0.7665\n",
            "220/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "221/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "222/326, Train_loss: 0.1094 Train_dice: 0.8906\n",
            "223/326, Train_loss: 0.1145 Train_dice: 0.8855\n",
            "224/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "225/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "226/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "227/326, Train_loss: 0.0916 Train_dice: 0.9084\n",
            "228/326, Train_loss: 0.0698 Train_dice: 0.9302\n",
            "229/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "230/326, Train_loss: 0.5761 Train_dice: 0.4239\n",
            "231/326, Train_loss: 0.1538 Train_dice: 0.8462\n",
            "232/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "233/326, Train_loss: 0.3374 Train_dice: 0.6626\n",
            "234/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "235/326, Train_loss: 0.2195 Train_dice: 0.7805\n",
            "236/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "237/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "238/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "239/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "240/326, Train_loss: 0.1808 Train_dice: 0.8192\n",
            "241/326, Train_loss: 0.1818 Train_dice: 0.8182\n",
            "242/326, Train_loss: 0.3662 Train_dice: 0.6338\n",
            "243/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "244/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "245/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "246/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "247/326, Train_loss: 0.0647 Train_dice: 0.9353\n",
            "248/326, Train_loss: 0.1436 Train_dice: 0.8564\n",
            "249/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "250/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "251/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "252/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "253/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "254/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "255/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "256/326, Train_loss: 0.2543 Train_dice: 0.7457\n",
            "257/326, Train_loss: 0.0889 Train_dice: 0.9111\n",
            "258/326, Train_loss: 0.3297 Train_dice: 0.6703\n",
            "259/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "260/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "261/326, Train_loss: 0.2128 Train_dice: 0.7872\n",
            "262/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "263/326, Train_loss: 0.1161 Train_dice: 0.8839\n",
            "264/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "265/326, Train_loss: 0.1945 Train_dice: 0.8055\n",
            "266/326, Train_loss: 0.2409 Train_dice: 0.7591\n",
            "267/326, Train_loss: 0.1124 Train_dice: 0.8876\n",
            "268/326, Train_loss: 0.1715 Train_dice: 0.8285\n",
            "269/326, Train_loss: 0.1308 Train_dice: 0.8692\n",
            "270/326, Train_loss: 0.1352 Train_dice: 0.8648\n",
            "271/326, Train_loss: 0.0568 Train_dice: 0.9432\n",
            "272/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "273/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "274/326, Train_loss: 0.1737 Train_dice: 0.8263\n",
            "275/326, Train_loss: 0.2159 Train_dice: 0.7841\n",
            "276/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "277/326, Train_loss: 0.0936 Train_dice: 0.9064\n",
            "278/326, Train_loss: 0.1512 Train_dice: 0.8488\n",
            "279/326, Train_loss: 0.2227 Train_dice: 0.7773\n",
            "280/326, Train_loss: 0.1480 Train_dice: 0.8520\n",
            "281/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "282/326, Train_loss: 0.1402 Train_dice: 0.8598\n",
            "283/326, Train_loss: 0.1054 Train_dice: 0.8946\n",
            "284/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "285/326, Train_loss: 0.1027 Train_dice: 0.8973\n",
            "286/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "287/326, Train_loss: 0.1230 Train_dice: 0.8770\n",
            "288/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "289/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "290/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "291/326, Train_loss: 0.0587 Train_dice: 0.9413\n",
            "292/326, Train_loss: 0.0883 Train_dice: 0.9117\n",
            "293/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "294/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "295/326, Train_loss: 0.1567 Train_dice: 0.8433\n",
            "296/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "297/326, Train_loss: 0.0908 Train_dice: 0.9092\n",
            "298/326, Train_loss: 0.0409 Train_dice: 0.9591\n",
            "299/326, Train_loss: 0.1032 Train_dice: 0.8968\n",
            "300/326, Train_loss: 0.1726 Train_dice: 0.8274\n",
            "301/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "302/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "303/326, Train_loss: 0.1840 Train_dice: 0.8160\n",
            "304/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "305/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "306/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "307/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "308/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "309/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "310/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "311/326, Train_loss: 0.0834 Train_dice: 0.9166\n",
            "312/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "313/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "314/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "315/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "316/326, Train_loss: 0.0774 Train_dice: 0.9226\n",
            "317/326, Train_loss: 0.0846 Train_dice: 0.9154\n",
            "318/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "319/326, Train_loss: 0.0985 Train_dice: 0.9015\n",
            "320/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "321/326, Train_loss: 0.1047 Train_dice: 0.8953\n",
            "322/326, Train_loss: 0.1493 Train_dice: 0.8507\n",
            "323/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "324/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "325/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "326/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "--------------------\n",
            "Epoch_loss: 0.1103\n",
            "Epoch_metric: 0.8897\n",
            "----------\n",
            "epoch 134/250\n",
            "1/326, Train_loss: 0.1588 Train_dice: 0.8412\n",
            "2/326, Train_loss: 0.2131 Train_dice: 0.7869\n",
            "3/326, Train_loss: 0.2496 Train_dice: 0.7504\n",
            "4/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "5/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "6/326, Train_loss: 0.1800 Train_dice: 0.8200\n",
            "7/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "8/326, Train_loss: 0.0695 Train_dice: 0.9305\n",
            "9/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "10/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "11/326, Train_loss: 0.2014 Train_dice: 0.7986\n",
            "12/326, Train_loss: 0.2157 Train_dice: 0.7843\n",
            "13/326, Train_loss: 0.1234 Train_dice: 0.8766\n",
            "14/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "15/326, Train_loss: 0.2708 Train_dice: 0.7292\n",
            "16/326, Train_loss: 0.1038 Train_dice: 0.8962\n",
            "17/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "18/326, Train_loss: 0.2184 Train_dice: 0.7816\n",
            "19/326, Train_loss: 0.0950 Train_dice: 0.9050\n",
            "20/326, Train_loss: 0.1661 Train_dice: 0.8339\n",
            "21/326, Train_loss: 0.0912 Train_dice: 0.9088\n",
            "22/326, Train_loss: 0.0933 Train_dice: 0.9067\n",
            "23/326, Train_loss: 0.0849 Train_dice: 0.9151\n",
            "24/326, Train_loss: 0.1888 Train_dice: 0.8112\n",
            "25/326, Train_loss: 0.1209 Train_dice: 0.8791\n",
            "26/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "27/326, Train_loss: 0.0866 Train_dice: 0.9134\n",
            "28/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "29/326, Train_loss: 0.1133 Train_dice: 0.8867\n",
            "30/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "31/326, Train_loss: 0.6755 Train_dice: 0.3245\n",
            "32/326, Train_loss: 0.1574 Train_dice: 0.8426\n",
            "33/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "34/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "35/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "36/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "37/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "38/326, Train_loss: 0.1746 Train_dice: 0.8254\n",
            "39/326, Train_loss: 0.1254 Train_dice: 0.8746\n",
            "40/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "41/326, Train_loss: 0.0926 Train_dice: 0.9074\n",
            "42/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "43/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "44/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "45/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "46/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "47/326, Train_loss: 0.2295 Train_dice: 0.7705\n",
            "48/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "49/326, Train_loss: 0.1220 Train_dice: 0.8780\n",
            "50/326, Train_loss: 0.1427 Train_dice: 0.8573\n",
            "51/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "52/326, Train_loss: 0.1563 Train_dice: 0.8437\n",
            "53/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "54/326, Train_loss: 0.0912 Train_dice: 0.9088\n",
            "55/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "56/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "57/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "58/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "59/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "60/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "61/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "62/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "63/326, Train_loss: 0.1537 Train_dice: 0.8463\n",
            "64/326, Train_loss: 0.0662 Train_dice: 0.9338\n",
            "65/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "66/326, Train_loss: 0.1338 Train_dice: 0.8662\n",
            "67/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "68/326, Train_loss: 0.1260 Train_dice: 0.8740\n",
            "69/326, Train_loss: 0.0604 Train_dice: 0.9396\n",
            "70/326, Train_loss: 0.2644 Train_dice: 0.7356\n",
            "71/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "72/326, Train_loss: 0.1974 Train_dice: 0.8026\n",
            "73/326, Train_loss: 0.0841 Train_dice: 0.9159\n",
            "74/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "75/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "76/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "77/326, Train_loss: 0.1824 Train_dice: 0.8176\n",
            "78/326, Train_loss: 0.1370 Train_dice: 0.8630\n",
            "79/326, Train_loss: 0.1908 Train_dice: 0.8092\n",
            "80/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "81/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "82/326, Train_loss: 0.0563 Train_dice: 0.9437\n",
            "83/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "84/326, Train_loss: 0.2604 Train_dice: 0.7396\n",
            "85/326, Train_loss: 0.1106 Train_dice: 0.8894\n",
            "86/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "87/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "88/326, Train_loss: 0.1362 Train_dice: 0.8638\n",
            "89/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "90/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "91/326, Train_loss: 0.0913 Train_dice: 0.9087\n",
            "92/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "93/326, Train_loss: 0.2010 Train_dice: 0.7990\n",
            "94/326, Train_loss: 0.1413 Train_dice: 0.8587\n",
            "95/326, Train_loss: 0.2761 Train_dice: 0.7239\n",
            "96/326, Train_loss: 0.0966 Train_dice: 0.9034\n",
            "97/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "98/326, Train_loss: 0.1828 Train_dice: 0.8172\n",
            "99/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "100/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "101/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "102/326, Train_loss: 0.0855 Train_dice: 0.9145\n",
            "103/326, Train_loss: 0.0731 Train_dice: 0.9269\n",
            "104/326, Train_loss: 0.1037 Train_dice: 0.8963\n",
            "105/326, Train_loss: 0.0746 Train_dice: 0.9254\n",
            "106/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "107/326, Train_loss: 0.1050 Train_dice: 0.8950\n",
            "108/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "109/326, Train_loss: 0.0982 Train_dice: 0.9018\n",
            "110/326, Train_loss: 0.1915 Train_dice: 0.8085\n",
            "111/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "112/326, Train_loss: 0.2131 Train_dice: 0.7869\n",
            "113/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "114/326, Train_loss: 0.1040 Train_dice: 0.8960\n",
            "115/326, Train_loss: 0.1486 Train_dice: 0.8514\n",
            "116/326, Train_loss: 0.2646 Train_dice: 0.7354\n",
            "117/326, Train_loss: 0.0925 Train_dice: 0.9075\n",
            "118/326, Train_loss: 0.2258 Train_dice: 0.7742\n",
            "119/326, Train_loss: 0.1236 Train_dice: 0.8764\n",
            "120/326, Train_loss: 0.0711 Train_dice: 0.9289\n",
            "121/326, Train_loss: 0.0510 Train_dice: 0.9490\n",
            "122/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "123/326, Train_loss: 0.0877 Train_dice: 0.9123\n",
            "124/326, Train_loss: 0.1396 Train_dice: 0.8604\n",
            "125/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "126/326, Train_loss: 0.1926 Train_dice: 0.8074\n",
            "127/326, Train_loss: 0.0909 Train_dice: 0.9091\n",
            "128/326, Train_loss: 0.1556 Train_dice: 0.8444\n",
            "129/326, Train_loss: 0.3222 Train_dice: 0.6778\n",
            "130/326, Train_loss: 0.1827 Train_dice: 0.8173\n",
            "131/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "132/326, Train_loss: 0.1816 Train_dice: 0.8184\n",
            "133/326, Train_loss: 0.1328 Train_dice: 0.8672\n",
            "134/326, Train_loss: 0.3119 Train_dice: 0.6881\n",
            "135/326, Train_loss: 0.1389 Train_dice: 0.8611\n",
            "136/326, Train_loss: 0.1934 Train_dice: 0.8066\n",
            "137/326, Train_loss: 0.1342 Train_dice: 0.8658\n",
            "138/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "139/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "140/326, Train_loss: 0.1395 Train_dice: 0.8605\n",
            "141/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "142/326, Train_loss: 0.1909 Train_dice: 0.8091\n",
            "143/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "144/326, Train_loss: 0.1169 Train_dice: 0.8831\n",
            "145/326, Train_loss: 0.2493 Train_dice: 0.7507\n",
            "146/326, Train_loss: 0.1190 Train_dice: 0.8810\n",
            "147/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "148/326, Train_loss: 0.1691 Train_dice: 0.8309\n",
            "149/326, Train_loss: 0.1017 Train_dice: 0.8983\n",
            "150/326, Train_loss: 0.1906 Train_dice: 0.8094\n",
            "151/326, Train_loss: 0.1314 Train_dice: 0.8686\n",
            "152/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "153/326, Train_loss: 0.2229 Train_dice: 0.7771\n",
            "154/326, Train_loss: 0.1070 Train_dice: 0.8930\n",
            "155/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "156/326, Train_loss: 0.1091 Train_dice: 0.8909\n",
            "157/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "158/326, Train_loss: 0.2690 Train_dice: 0.7310\n",
            "159/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "160/326, Train_loss: 0.0853 Train_dice: 0.9147\n",
            "161/326, Train_loss: 0.1312 Train_dice: 0.8688\n",
            "162/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "163/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "164/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "165/326, Train_loss: 0.1962 Train_dice: 0.8038\n",
            "166/326, Train_loss: 0.1986 Train_dice: 0.8014\n",
            "167/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "168/326, Train_loss: 0.0501 Train_dice: 0.9499\n",
            "169/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "170/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "171/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "172/326, Train_loss: 0.1104 Train_dice: 0.8896\n",
            "173/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "174/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "175/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "176/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "177/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "178/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "179/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "180/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "181/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "182/326, Train_loss: 0.0501 Train_dice: 0.9499\n",
            "183/326, Train_loss: 0.1414 Train_dice: 0.8586\n",
            "184/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "185/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "186/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "187/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "188/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "189/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "190/326, Train_loss: 0.1329 Train_dice: 0.8671\n",
            "191/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "192/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "193/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "194/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "195/326, Train_loss: 0.2465 Train_dice: 0.7535\n",
            "196/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "197/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "198/326, Train_loss: 0.0710 Train_dice: 0.9290\n",
            "199/326, Train_loss: 0.1266 Train_dice: 0.8734\n",
            "200/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "201/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "202/326, Train_loss: 0.1987 Train_dice: 0.8013\n",
            "203/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "204/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "205/326, Train_loss: 0.6672 Train_dice: 0.3328\n",
            "206/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "207/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "208/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "209/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "210/326, Train_loss: 0.2544 Train_dice: 0.7456\n",
            "211/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "212/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "213/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "214/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "215/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "216/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "217/326, Train_loss: 0.1612 Train_dice: 0.8388\n",
            "218/326, Train_loss: 0.5233 Train_dice: 0.4767\n",
            "219/326, Train_loss: 0.4325 Train_dice: 0.5675\n",
            "220/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "221/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "222/326, Train_loss: 0.1496 Train_dice: 0.8504\n",
            "223/326, Train_loss: 0.1066 Train_dice: 0.8934\n",
            "224/326, Train_loss: 0.0933 Train_dice: 0.9067\n",
            "225/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "226/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "227/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "228/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "229/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "230/326, Train_loss: 0.4843 Train_dice: 0.5157\n",
            "231/326, Train_loss: 0.1322 Train_dice: 0.8678\n",
            "232/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "233/326, Train_loss: 0.2639 Train_dice: 0.7361\n",
            "234/326, Train_loss: 0.0982 Train_dice: 0.9018\n",
            "235/326, Train_loss: 0.2058 Train_dice: 0.7942\n",
            "236/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "237/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "238/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "239/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "240/326, Train_loss: 0.1679 Train_dice: 0.8321\n",
            "241/326, Train_loss: 0.1669 Train_dice: 0.8331\n",
            "242/326, Train_loss: 0.2069 Train_dice: 0.7931\n",
            "243/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "244/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "245/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "246/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "247/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "248/326, Train_loss: 0.1464 Train_dice: 0.8536\n",
            "249/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "250/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "251/326, Train_loss: 0.0584 Train_dice: 0.9416\n",
            "252/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "253/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "254/326, Train_loss: 0.0623 Train_dice: 0.9377\n",
            "255/326, Train_loss: 0.0435 Train_dice: 0.9565\n",
            "256/326, Train_loss: 0.1956 Train_dice: 0.8044\n",
            "257/326, Train_loss: 0.0792 Train_dice: 0.9208\n",
            "258/326, Train_loss: 0.3101 Train_dice: 0.6899\n",
            "259/326, Train_loss: 0.1105 Train_dice: 0.8895\n",
            "260/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "261/326, Train_loss: 0.1946 Train_dice: 0.8054\n",
            "262/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "263/326, Train_loss: 0.0991 Train_dice: 0.9009\n",
            "264/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "265/326, Train_loss: 0.1709 Train_dice: 0.8291\n",
            "266/326, Train_loss: 0.1365 Train_dice: 0.8635\n",
            "267/326, Train_loss: 0.1040 Train_dice: 0.8960\n",
            "268/326, Train_loss: 0.1390 Train_dice: 0.8610\n",
            "269/326, Train_loss: 0.1192 Train_dice: 0.8808\n",
            "270/326, Train_loss: 0.1228 Train_dice: 0.8772\n",
            "271/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "272/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "273/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "274/326, Train_loss: 0.1033 Train_dice: 0.8967\n",
            "275/326, Train_loss: 0.2073 Train_dice: 0.7927\n",
            "276/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "277/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "278/326, Train_loss: 0.1426 Train_dice: 0.8574\n",
            "279/326, Train_loss: 0.2117 Train_dice: 0.7883\n",
            "280/326, Train_loss: 0.1540 Train_dice: 0.8460\n",
            "281/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "282/326, Train_loss: 0.1468 Train_dice: 0.8532\n",
            "283/326, Train_loss: 0.2600 Train_dice: 0.7400\n",
            "284/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "285/326, Train_loss: 0.0992 Train_dice: 0.9008\n",
            "286/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "287/326, Train_loss: 0.1150 Train_dice: 0.8850\n",
            "288/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "289/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "290/326, Train_loss: 0.0747 Train_dice: 0.9253\n",
            "291/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "292/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "293/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "294/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "295/326, Train_loss: 0.1482 Train_dice: 0.8518\n",
            "296/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "297/326, Train_loss: 0.0718 Train_dice: 0.9282\n",
            "298/326, Train_loss: 0.0757 Train_dice: 0.9243\n",
            "299/326, Train_loss: 0.0989 Train_dice: 0.9011\n",
            "300/326, Train_loss: 0.1595 Train_dice: 0.8405\n",
            "301/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "302/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "303/326, Train_loss: 0.1653 Train_dice: 0.8347\n",
            "304/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "305/326, Train_loss: 0.1546 Train_dice: 0.8454\n",
            "306/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "307/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "308/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "309/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "310/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "311/326, Train_loss: 0.0805 Train_dice: 0.9195\n",
            "312/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "313/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "314/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "315/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "316/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "317/326, Train_loss: 0.0425 Train_dice: 0.9575\n",
            "318/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "319/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "320/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "321/326, Train_loss: 0.1049 Train_dice: 0.8951\n",
            "322/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "323/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "324/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "325/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "326/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "--------------------\n",
            "Epoch_loss: 0.1029\n",
            "Epoch_metric: 0.8971\n",
            "----------\n",
            "epoch 135/250\n",
            "1/326, Train_loss: 0.1490 Train_dice: 0.8510\n",
            "2/326, Train_loss: 0.2028 Train_dice: 0.7972\n",
            "3/326, Train_loss: 0.2383 Train_dice: 0.7617\n",
            "4/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "5/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "6/326, Train_loss: 0.1651 Train_dice: 0.8349\n",
            "7/326, Train_loss: 0.0832 Train_dice: 0.9168\n",
            "8/326, Train_loss: 0.0579 Train_dice: 0.9421\n",
            "9/326, Train_loss: 0.0923 Train_dice: 0.9077\n",
            "10/326, Train_loss: 0.0644 Train_dice: 0.9356\n",
            "11/326, Train_loss: 0.1850 Train_dice: 0.8150\n",
            "12/326, Train_loss: 0.2025 Train_dice: 0.7975\n",
            "13/326, Train_loss: 0.1166 Train_dice: 0.8834\n",
            "14/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "15/326, Train_loss: 0.2583 Train_dice: 0.7417\n",
            "16/326, Train_loss: 0.0876 Train_dice: 0.9124\n",
            "17/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "18/326, Train_loss: 0.2036 Train_dice: 0.7964\n",
            "19/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "20/326, Train_loss: 0.1549 Train_dice: 0.8451\n",
            "21/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "22/326, Train_loss: 0.0894 Train_dice: 0.9106\n",
            "23/326, Train_loss: 0.0701 Train_dice: 0.9299\n",
            "24/326, Train_loss: 0.1765 Train_dice: 0.8235\n",
            "25/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "26/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "27/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "28/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "29/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "30/326, Train_loss: 0.0791 Train_dice: 0.9209\n",
            "31/326, Train_loss: 0.2374 Train_dice: 0.7626\n",
            "32/326, Train_loss: 0.1758 Train_dice: 0.8242\n",
            "33/326, Train_loss: 0.0979 Train_dice: 0.9021\n",
            "34/326, Train_loss: 0.0732 Train_dice: 0.9268\n",
            "35/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "36/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "37/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "38/326, Train_loss: 0.1683 Train_dice: 0.8317\n",
            "39/326, Train_loss: 0.5958 Train_dice: 0.4042\n",
            "40/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "41/326, Train_loss: 0.1075 Train_dice: 0.8925\n",
            "42/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "43/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "44/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "45/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "46/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "47/326, Train_loss: 0.2193 Train_dice: 0.7807\n",
            "48/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "49/326, Train_loss: 0.1158 Train_dice: 0.8842\n",
            "50/326, Train_loss: 0.1360 Train_dice: 0.8640\n",
            "51/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "52/326, Train_loss: 0.1505 Train_dice: 0.8495\n",
            "53/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "54/326, Train_loss: 0.0855 Train_dice: 0.9145\n",
            "55/326, Train_loss: 0.0631 Train_dice: 0.9369\n",
            "56/326, Train_loss: 0.0817 Train_dice: 0.9183\n",
            "57/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "58/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "59/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "60/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "61/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "62/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "63/326, Train_loss: 0.1478 Train_dice: 0.8522\n",
            "64/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "65/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "66/326, Train_loss: 0.1277 Train_dice: 0.8723\n",
            "67/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "68/326, Train_loss: 0.1198 Train_dice: 0.8802\n",
            "69/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "70/326, Train_loss: 0.2550 Train_dice: 0.7450\n",
            "71/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "72/326, Train_loss: 0.1896 Train_dice: 0.8104\n",
            "73/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "74/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "75/326, Train_loss: 0.0826 Train_dice: 0.9174\n",
            "76/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "77/326, Train_loss: 0.1739 Train_dice: 0.8261\n",
            "78/326, Train_loss: 0.1300 Train_dice: 0.8700\n",
            "79/326, Train_loss: 0.1827 Train_dice: 0.8173\n",
            "80/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "81/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "82/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "83/326, Train_loss: 0.1290 Train_dice: 0.8710\n",
            "84/326, Train_loss: 0.2494 Train_dice: 0.7506\n",
            "85/326, Train_loss: 0.1037 Train_dice: 0.8963\n",
            "86/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "87/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "88/326, Train_loss: 0.1289 Train_dice: 0.8711\n",
            "89/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "90/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "91/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "92/326, Train_loss: 0.0957 Train_dice: 0.9043\n",
            "93/326, Train_loss: 0.1914 Train_dice: 0.8086\n",
            "94/326, Train_loss: 0.1326 Train_dice: 0.8674\n",
            "95/326, Train_loss: 0.2642 Train_dice: 0.7358\n",
            "96/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "97/326, Train_loss: 0.0731 Train_dice: 0.9269\n",
            "98/326, Train_loss: 0.1745 Train_dice: 0.8255\n",
            "99/326, Train_loss: 0.0498 Train_dice: 0.9502\n",
            "100/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "101/326, Train_loss: 0.0925 Train_dice: 0.9075\n",
            "102/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "103/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "104/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "105/326, Train_loss: 0.0704 Train_dice: 0.9296\n",
            "106/326, Train_loss: 0.0947 Train_dice: 0.9053\n",
            "107/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "108/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "109/326, Train_loss: 0.0922 Train_dice: 0.9078\n",
            "110/326, Train_loss: 0.1833 Train_dice: 0.8167\n",
            "111/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "112/326, Train_loss: 0.2047 Train_dice: 0.7953\n",
            "113/326, Train_loss: 0.0711 Train_dice: 0.9289\n",
            "114/326, Train_loss: 0.0983 Train_dice: 0.9017\n",
            "115/326, Train_loss: 0.1413 Train_dice: 0.8587\n",
            "116/326, Train_loss: 0.2545 Train_dice: 0.7455\n",
            "117/326, Train_loss: 0.0890 Train_dice: 0.9110\n",
            "118/326, Train_loss: 0.2165 Train_dice: 0.7835\n",
            "119/326, Train_loss: 0.1179 Train_dice: 0.8821\n",
            "120/326, Train_loss: 0.0669 Train_dice: 0.9331\n",
            "121/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "122/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "123/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "124/326, Train_loss: 0.1326 Train_dice: 0.8674\n",
            "125/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "126/326, Train_loss: 0.1840 Train_dice: 0.8160\n",
            "127/326, Train_loss: 0.0858 Train_dice: 0.9142\n",
            "128/326, Train_loss: 0.1479 Train_dice: 0.8521\n",
            "129/326, Train_loss: 0.3062 Train_dice: 0.6938\n",
            "130/326, Train_loss: 0.1750 Train_dice: 0.8250\n",
            "131/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "132/326, Train_loss: 0.1727 Train_dice: 0.8273\n",
            "133/326, Train_loss: 0.1266 Train_dice: 0.8734\n",
            "134/326, Train_loss: 0.3012 Train_dice: 0.6988\n",
            "135/326, Train_loss: 0.1320 Train_dice: 0.8680\n",
            "136/326, Train_loss: 0.1838 Train_dice: 0.8162\n",
            "137/326, Train_loss: 0.1273 Train_dice: 0.8727\n",
            "138/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "139/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "140/326, Train_loss: 0.1323 Train_dice: 0.8677\n",
            "141/326, Train_loss: 0.0665 Train_dice: 0.9335\n",
            "142/326, Train_loss: 0.1825 Train_dice: 0.8175\n",
            "143/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "144/326, Train_loss: 0.1097 Train_dice: 0.8903\n",
            "145/326, Train_loss: 0.2395 Train_dice: 0.7605\n",
            "146/326, Train_loss: 0.1128 Train_dice: 0.8872\n",
            "147/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "148/326, Train_loss: 0.1628 Train_dice: 0.8372\n",
            "149/326, Train_loss: 0.0981 Train_dice: 0.9019\n",
            "150/326, Train_loss: 0.1814 Train_dice: 0.8186\n",
            "151/326, Train_loss: 0.1258 Train_dice: 0.8742\n",
            "152/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "153/326, Train_loss: 0.2121 Train_dice: 0.7879\n",
            "154/326, Train_loss: 0.1004 Train_dice: 0.8996\n",
            "155/326, Train_loss: 0.0530 Train_dice: 0.9470\n",
            "156/326, Train_loss: 0.1041 Train_dice: 0.8959\n",
            "157/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "158/326, Train_loss: 0.2582 Train_dice: 0.7418\n",
            "159/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "160/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "161/326, Train_loss: 0.1246 Train_dice: 0.8754\n",
            "162/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "163/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "164/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "165/326, Train_loss: 0.1860 Train_dice: 0.8140\n",
            "166/326, Train_loss: 0.1890 Train_dice: 0.8110\n",
            "167/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "168/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "169/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "170/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "171/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "172/326, Train_loss: 0.0788 Train_dice: 0.9212\n",
            "173/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "174/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "175/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "176/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "177/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "178/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "179/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "180/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "181/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "182/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "183/326, Train_loss: 0.1230 Train_dice: 0.8770\n",
            "184/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "185/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "186/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "187/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "188/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "189/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "190/326, Train_loss: 0.1085 Train_dice: 0.8915\n",
            "191/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "192/326, Train_loss: 0.0866 Train_dice: 0.9134\n",
            "193/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "194/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "195/326, Train_loss: 0.1706 Train_dice: 0.8294\n",
            "196/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "197/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "198/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "199/326, Train_loss: 0.0974 Train_dice: 0.9026\n",
            "200/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "201/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "202/326, Train_loss: 0.0563 Train_dice: 0.9437\n",
            "203/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "204/326, Train_loss: 0.1519 Train_dice: 0.8481\n",
            "205/326, Train_loss: 0.5909 Train_dice: 0.4091\n",
            "206/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "207/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "208/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "209/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "210/326, Train_loss: 0.2216 Train_dice: 0.7784\n",
            "211/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "212/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "213/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "214/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "215/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "216/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "217/326, Train_loss: 0.1209 Train_dice: 0.8791\n",
            "218/326, Train_loss: 0.1595 Train_dice: 0.8405\n",
            "219/326, Train_loss: 0.1755 Train_dice: 0.8245\n",
            "220/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "221/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "222/326, Train_loss: 0.0817 Train_dice: 0.9183\n",
            "223/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "224/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "225/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "226/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "227/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "228/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "229/326, Train_loss: 0.0772 Train_dice: 0.9228\n",
            "230/326, Train_loss: 0.1388 Train_dice: 0.8612\n",
            "231/326, Train_loss: 0.1316 Train_dice: 0.8684\n",
            "232/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "233/326, Train_loss: 0.2499 Train_dice: 0.7501\n",
            "234/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "235/326, Train_loss: 0.1924 Train_dice: 0.8076\n",
            "236/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "237/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "238/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "239/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "240/326, Train_loss: 0.1545 Train_dice: 0.8455\n",
            "241/326, Train_loss: 0.1535 Train_dice: 0.8465\n",
            "242/326, Train_loss: 0.1799 Train_dice: 0.8201\n",
            "243/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "244/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "245/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "246/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "247/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "248/326, Train_loss: 0.1175 Train_dice: 0.8825\n",
            "249/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "250/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "251/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "252/326, Train_loss: 0.0326 Train_dice: 0.9674\n",
            "253/326, Train_loss: 0.0220 Train_dice: 0.9780\n",
            "254/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "255/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "256/326, Train_loss: 0.1890 Train_dice: 0.8110\n",
            "257/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "258/326, Train_loss: 0.2802 Train_dice: 0.7198\n",
            "259/326, Train_loss: 0.1217 Train_dice: 0.8783\n",
            "260/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "261/326, Train_loss: 0.1844 Train_dice: 0.8156\n",
            "262/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "263/326, Train_loss: 0.0821 Train_dice: 0.9179\n",
            "264/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "265/326, Train_loss: 0.1467 Train_dice: 0.8533\n",
            "266/326, Train_loss: 0.0947 Train_dice: 0.9053\n",
            "267/326, Train_loss: 0.0971 Train_dice: 0.9029\n",
            "268/326, Train_loss: 0.1144 Train_dice: 0.8856\n",
            "269/326, Train_loss: 0.1121 Train_dice: 0.8879\n",
            "270/326, Train_loss: 0.1127 Train_dice: 0.8873\n",
            "271/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "272/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "273/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "274/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "275/326, Train_loss: 0.2089 Train_dice: 0.7911\n",
            "276/326, Train_loss: 0.0326 Train_dice: 0.9674\n",
            "277/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "278/326, Train_loss: 0.1307 Train_dice: 0.8693\n",
            "279/326, Train_loss: 0.1969 Train_dice: 0.8031\n",
            "280/326, Train_loss: 0.1164 Train_dice: 0.8836\n",
            "281/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "282/326, Train_loss: 0.1158 Train_dice: 0.8842\n",
            "283/326, Train_loss: 0.0995 Train_dice: 0.9005\n",
            "284/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "285/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "286/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "287/326, Train_loss: 0.1032 Train_dice: 0.8968\n",
            "288/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "289/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "290/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "291/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "292/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "293/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "294/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "295/326, Train_loss: 0.1367 Train_dice: 0.8633\n",
            "296/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "297/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "298/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "299/326, Train_loss: 0.0522 Train_dice: 0.9478\n",
            "300/326, Train_loss: 0.1405 Train_dice: 0.8595\n",
            "301/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "302/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "303/326, Train_loss: 0.1461 Train_dice: 0.8539\n",
            "304/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "305/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "306/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "307/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "308/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "309/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "310/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "311/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "312/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "313/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "314/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "315/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "316/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "317/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "318/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "319/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "320/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "321/326, Train_loss: 0.0832 Train_dice: 0.9168\n",
            "322/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "323/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "324/326, Train_loss: 0.0314 Train_dice: 0.9686\n",
            "325/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "326/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "--------------------\n",
            "Epoch_loss: 0.0896\n",
            "Epoch_metric: 0.9104\n",
            "----------\n",
            "epoch 136/250\n",
            "1/326, Train_loss: 0.1396 Train_dice: 0.8604\n",
            "2/326, Train_loss: 0.1930 Train_dice: 0.8070\n",
            "3/326, Train_loss: 0.2266 Train_dice: 0.7734\n",
            "4/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "5/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "6/326, Train_loss: 0.1562 Train_dice: 0.8438\n",
            "7/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "8/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "9/326, Train_loss: 0.0862 Train_dice: 0.9138\n",
            "10/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "11/326, Train_loss: 0.1749 Train_dice: 0.8251\n",
            "12/326, Train_loss: 0.1936 Train_dice: 0.8064\n",
            "13/326, Train_loss: 0.1104 Train_dice: 0.8896\n",
            "14/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "15/326, Train_loss: 0.2458 Train_dice: 0.7542\n",
            "16/326, Train_loss: 0.0823 Train_dice: 0.9177\n",
            "17/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "18/326, Train_loss: 0.1918 Train_dice: 0.8082\n",
            "19/326, Train_loss: 0.0817 Train_dice: 0.9183\n",
            "20/326, Train_loss: 0.1435 Train_dice: 0.8565\n",
            "21/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "22/326, Train_loss: 0.0813 Train_dice: 0.9187\n",
            "23/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "24/326, Train_loss: 0.1653 Train_dice: 0.8347\n",
            "25/326, Train_loss: 0.1023 Train_dice: 0.8977\n",
            "26/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "27/326, Train_loss: 0.0760 Train_dice: 0.9240\n",
            "28/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "29/326, Train_loss: 0.1009 Train_dice: 0.8991\n",
            "30/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "31/326, Train_loss: 0.2192 Train_dice: 0.7808\n",
            "32/326, Train_loss: 0.1395 Train_dice: 0.8605\n",
            "33/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "34/326, Train_loss: 0.0708 Train_dice: 0.9292\n",
            "35/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "36/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "37/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "38/326, Train_loss: 0.1584 Train_dice: 0.8416\n",
            "39/326, Train_loss: 0.1162 Train_dice: 0.8838\n",
            "40/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "41/326, Train_loss: 0.6359 Train_dice: 0.3641\n",
            "42/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "43/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "44/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "45/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "46/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "47/326, Train_loss: 0.2088 Train_dice: 0.7912\n",
            "48/326, Train_loss: 0.0541 Train_dice: 0.9459\n",
            "49/326, Train_loss: 0.1086 Train_dice: 0.8914\n",
            "50/326, Train_loss: 0.1271 Train_dice: 0.8729\n",
            "51/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "52/326, Train_loss: 0.1409 Train_dice: 0.8591\n",
            "53/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "54/326, Train_loss: 0.0771 Train_dice: 0.9229\n",
            "55/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "56/326, Train_loss: 0.0754 Train_dice: 0.9246\n",
            "57/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "58/326, Train_loss: 0.0530 Train_dice: 0.9470\n",
            "59/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "60/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "61/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "62/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "63/326, Train_loss: 0.1434 Train_dice: 0.8566\n",
            "64/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "65/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "66/326, Train_loss: 0.1208 Train_dice: 0.8792\n",
            "67/326, Train_loss: 0.0465 Train_dice: 0.9535\n",
            "68/326, Train_loss: 0.1135 Train_dice: 0.8865\n",
            "69/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "70/326, Train_loss: 0.2432 Train_dice: 0.7568\n",
            "71/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "72/326, Train_loss: 0.1801 Train_dice: 0.8199\n",
            "73/326, Train_loss: 0.0749 Train_dice: 0.9251\n",
            "74/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "75/326, Train_loss: 0.0775 Train_dice: 0.9225\n",
            "76/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "77/326, Train_loss: 0.1655 Train_dice: 0.8345\n",
            "78/326, Train_loss: 0.1238 Train_dice: 0.8762\n",
            "79/326, Train_loss: 0.1731 Train_dice: 0.8269\n",
            "80/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "81/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "82/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "83/326, Train_loss: 0.1238 Train_dice: 0.8762\n",
            "84/326, Train_loss: 0.2412 Train_dice: 0.7588\n",
            "85/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "86/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "87/326, Train_loss: 0.0595 Train_dice: 0.9405\n",
            "88/326, Train_loss: 0.1216 Train_dice: 0.8784\n",
            "89/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "90/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "91/326, Train_loss: 0.0822 Train_dice: 0.9178\n",
            "92/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "93/326, Train_loss: 0.1813 Train_dice: 0.8187\n",
            "94/326, Train_loss: 0.1239 Train_dice: 0.8761\n",
            "95/326, Train_loss: 0.2522 Train_dice: 0.7478\n",
            "96/326, Train_loss: 0.0852 Train_dice: 0.9148\n",
            "97/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "98/326, Train_loss: 0.1660 Train_dice: 0.8340\n",
            "99/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "100/326, Train_loss: 0.0498 Train_dice: 0.9502\n",
            "101/326, Train_loss: 0.0879 Train_dice: 0.9121\n",
            "102/326, Train_loss: 0.0748 Train_dice: 0.9252\n",
            "103/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "104/326, Train_loss: 0.0936 Train_dice: 0.9064\n",
            "105/326, Train_loss: 0.0668 Train_dice: 0.9332\n",
            "106/326, Train_loss: 0.0896 Train_dice: 0.9104\n",
            "107/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "108/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "109/326, Train_loss: 0.0872 Train_dice: 0.9128\n",
            "110/326, Train_loss: 0.1739 Train_dice: 0.8261\n",
            "111/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "112/326, Train_loss: 0.1942 Train_dice: 0.8058\n",
            "113/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "114/326, Train_loss: 0.0932 Train_dice: 0.9068\n",
            "115/326, Train_loss: 0.1336 Train_dice: 0.8664\n",
            "116/326, Train_loss: 0.2430 Train_dice: 0.7570\n",
            "117/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "118/326, Train_loss: 0.2071 Train_dice: 0.7929\n",
            "119/326, Train_loss: 0.1115 Train_dice: 0.8885\n",
            "120/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "121/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "122/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "123/326, Train_loss: 0.0782 Train_dice: 0.9218\n",
            "124/326, Train_loss: 0.1259 Train_dice: 0.8741\n",
            "125/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "126/326, Train_loss: 0.1735 Train_dice: 0.8265\n",
            "127/326, Train_loss: 0.0805 Train_dice: 0.9195\n",
            "128/326, Train_loss: 0.1403 Train_dice: 0.8597\n",
            "129/326, Train_loss: 0.2934 Train_dice: 0.7066\n",
            "130/326, Train_loss: 0.1674 Train_dice: 0.8326\n",
            "131/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "132/326, Train_loss: 0.1650 Train_dice: 0.8350\n",
            "133/326, Train_loss: 0.1206 Train_dice: 0.8794\n",
            "134/326, Train_loss: 0.2883 Train_dice: 0.7117\n",
            "135/326, Train_loss: 0.1249 Train_dice: 0.8751\n",
            "136/326, Train_loss: 0.1737 Train_dice: 0.8263\n",
            "137/326, Train_loss: 0.1199 Train_dice: 0.8801\n",
            "138/326, Train_loss: 0.0721 Train_dice: 0.9279\n",
            "139/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "140/326, Train_loss: 0.1250 Train_dice: 0.8750\n",
            "141/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "142/326, Train_loss: 0.1734 Train_dice: 0.8266\n",
            "143/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "144/326, Train_loss: 0.1031 Train_dice: 0.8969\n",
            "145/326, Train_loss: 0.2293 Train_dice: 0.7707\n",
            "146/326, Train_loss: 0.1067 Train_dice: 0.8933\n",
            "147/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "148/326, Train_loss: 0.1543 Train_dice: 0.8457\n",
            "149/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "150/326, Train_loss: 0.1742 Train_dice: 0.8258\n",
            "151/326, Train_loss: 0.1242 Train_dice: 0.8758\n",
            "152/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "153/326, Train_loss: 0.2026 Train_dice: 0.7974\n",
            "154/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "155/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "156/326, Train_loss: 0.0981 Train_dice: 0.9019\n",
            "157/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "158/326, Train_loss: 0.2465 Train_dice: 0.7535\n",
            "159/326, Train_loss: 0.0773 Train_dice: 0.9227\n",
            "160/326, Train_loss: 0.0756 Train_dice: 0.9244\n",
            "161/326, Train_loss: 0.1185 Train_dice: 0.8815\n",
            "162/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "163/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "164/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "165/326, Train_loss: 0.1744 Train_dice: 0.8256\n",
            "166/326, Train_loss: 0.1792 Train_dice: 0.8208\n",
            "167/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "168/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "169/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "170/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "171/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "172/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "173/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "174/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "175/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "176/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "177/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "178/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "179/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "180/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "181/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "182/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "183/326, Train_loss: 0.1147 Train_dice: 0.8853\n",
            "184/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "185/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "186/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "187/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "188/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "189/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "190/326, Train_loss: 0.0960 Train_dice: 0.9040\n",
            "191/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "192/326, Train_loss: 0.0787 Train_dice: 0.9213\n",
            "193/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "194/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "195/326, Train_loss: 0.1439 Train_dice: 0.8561\n",
            "196/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "197/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "198/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "199/326, Train_loss: 0.0827 Train_dice: 0.9173\n",
            "200/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "201/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "202/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "203/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "204/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "205/326, Train_loss: 0.4950 Train_dice: 0.5050\n",
            "206/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "207/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "208/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "209/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "210/326, Train_loss: 0.1897 Train_dice: 0.8103\n",
            "211/326, Train_loss: 0.0323 Train_dice: 0.9677\n",
            "212/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "213/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "214/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "215/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "216/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "217/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "218/326, Train_loss: 0.1259 Train_dice: 0.8741\n",
            "219/326, Train_loss: 0.1254 Train_dice: 0.8746\n",
            "220/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "221/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "222/326, Train_loss: 0.0683 Train_dice: 0.9317\n",
            "223/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "224/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "225/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "226/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "227/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "228/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "229/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "230/326, Train_loss: 0.0964 Train_dice: 0.9036\n",
            "231/326, Train_loss: 0.1073 Train_dice: 0.8927\n",
            "232/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "233/326, Train_loss: 0.2246 Train_dice: 0.7754\n",
            "234/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "235/326, Train_loss: 0.1764 Train_dice: 0.8236\n",
            "236/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "237/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "238/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "239/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "240/326, Train_loss: 0.1416 Train_dice: 0.8584\n",
            "241/326, Train_loss: 0.1380 Train_dice: 0.8620\n",
            "242/326, Train_loss: 0.1507 Train_dice: 0.8493\n",
            "243/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "244/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "245/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "246/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "247/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "248/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "249/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "250/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "251/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "252/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "253/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "254/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "255/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "256/326, Train_loss: 0.1574 Train_dice: 0.8426\n",
            "257/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "258/326, Train_loss: 0.2650 Train_dice: 0.7350\n",
            "259/326, Train_loss: 0.0926 Train_dice: 0.9074\n",
            "260/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "261/326, Train_loss: 0.1720 Train_dice: 0.8280\n",
            "262/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "263/326, Train_loss: 0.1014 Train_dice: 0.8986\n",
            "264/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "265/326, Train_loss: 0.1257 Train_dice: 0.8743\n",
            "266/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "267/326, Train_loss: 0.0877 Train_dice: 0.9123\n",
            "268/326, Train_loss: 0.0952 Train_dice: 0.9048\n",
            "269/326, Train_loss: 0.0960 Train_dice: 0.9040\n",
            "270/326, Train_loss: 0.1041 Train_dice: 0.8959\n",
            "271/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "272/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "273/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "274/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "275/326, Train_loss: 0.1785 Train_dice: 0.8215\n",
            "276/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "277/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "278/326, Train_loss: 0.1224 Train_dice: 0.8776\n",
            "279/326, Train_loss: 0.1835 Train_dice: 0.8165\n",
            "280/326, Train_loss: 0.1147 Train_dice: 0.8853\n",
            "281/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "282/326, Train_loss: 0.1056 Train_dice: 0.8944\n",
            "283/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "284/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "285/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "286/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "287/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "288/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "289/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "290/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "291/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "292/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "293/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "294/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "295/326, Train_loss: 0.1263 Train_dice: 0.8737\n",
            "296/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "297/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "298/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "299/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "300/326, Train_loss: 0.1239 Train_dice: 0.8761\n",
            "301/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "302/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "303/326, Train_loss: 0.1335 Train_dice: 0.8665\n",
            "304/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "305/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "306/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "307/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "308/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "309/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "310/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "311/326, Train_loss: 0.0466 Train_dice: 0.9534\n",
            "312/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "313/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "314/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "315/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "316/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "317/326, Train_loss: 0.0302 Train_dice: 0.9698\n",
            "318/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "319/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "320/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "321/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "322/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "323/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "324/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "325/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "326/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "--------------------\n",
            "Epoch_loss: 0.0814\n",
            "Epoch_metric: 0.9186\n",
            "----------\n",
            "epoch 137/250\n",
            "1/326, Train_loss: 0.1319 Train_dice: 0.8681\n",
            "2/326, Train_loss: 0.1814 Train_dice: 0.8186\n",
            "3/326, Train_loss: 0.2149 Train_dice: 0.7851\n",
            "4/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "5/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "6/326, Train_loss: 0.1479 Train_dice: 0.8521\n",
            "7/326, Train_loss: 0.0722 Train_dice: 0.9278\n",
            "8/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "9/326, Train_loss: 0.0796 Train_dice: 0.9204\n",
            "10/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "11/326, Train_loss: 0.1667 Train_dice: 0.8333\n",
            "12/326, Train_loss: 0.1825 Train_dice: 0.8175\n",
            "13/326, Train_loss: 0.1026 Train_dice: 0.8974\n",
            "14/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "15/326, Train_loss: 0.2350 Train_dice: 0.7650\n",
            "16/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "17/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "18/326, Train_loss: 0.1828 Train_dice: 0.8172\n",
            "19/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "20/326, Train_loss: 0.1355 Train_dice: 0.8645\n",
            "21/326, Train_loss: 0.0670 Train_dice: 0.9330\n",
            "22/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "23/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "24/326, Train_loss: 0.1565 Train_dice: 0.8435\n",
            "25/326, Train_loss: 0.0965 Train_dice: 0.9035\n",
            "26/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "27/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "28/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "29/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "30/326, Train_loss: 0.0579 Train_dice: 0.9421\n",
            "31/326, Train_loss: 0.2099 Train_dice: 0.7901\n",
            "32/326, Train_loss: 0.1327 Train_dice: 0.8673\n",
            "33/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "34/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "35/326, Train_loss: 0.0653 Train_dice: 0.9347\n",
            "36/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "37/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "38/326, Train_loss: 0.1482 Train_dice: 0.8518\n",
            "39/326, Train_loss: 0.1079 Train_dice: 0.8921\n",
            "40/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "41/326, Train_loss: 0.4428 Train_dice: 0.5572\n",
            "42/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "43/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "44/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "45/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "46/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "47/326, Train_loss: 0.2002 Train_dice: 0.7998\n",
            "48/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "49/326, Train_loss: 0.1030 Train_dice: 0.8970\n",
            "50/326, Train_loss: 0.1208 Train_dice: 0.8792\n",
            "51/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "52/326, Train_loss: 0.1387 Train_dice: 0.8613\n",
            "53/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "54/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "55/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "56/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "57/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "58/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "59/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "60/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "61/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "62/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "63/326, Train_loss: 0.1324 Train_dice: 0.8676\n",
            "64/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "65/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "66/326, Train_loss: 0.1158 Train_dice: 0.8842\n",
            "67/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "68/326, Train_loss: 0.1096 Train_dice: 0.8904\n",
            "69/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "70/326, Train_loss: 0.2321 Train_dice: 0.7679\n",
            "71/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "72/326, Train_loss: 0.1710 Train_dice: 0.8290\n",
            "73/326, Train_loss: 0.0705 Train_dice: 0.9295\n",
            "74/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "75/326, Train_loss: 0.0725 Train_dice: 0.9275\n",
            "76/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "77/326, Train_loss: 0.1578 Train_dice: 0.8422\n",
            "78/326, Train_loss: 0.1159 Train_dice: 0.8841\n",
            "79/326, Train_loss: 0.1646 Train_dice: 0.8354\n",
            "80/326, Train_loss: 0.0538 Train_dice: 0.9462\n",
            "81/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "82/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "83/326, Train_loss: 0.1162 Train_dice: 0.8838\n",
            "84/326, Train_loss: 0.2313 Train_dice: 0.7687\n",
            "85/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "86/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "87/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "88/326, Train_loss: 0.1163 Train_dice: 0.8837\n",
            "89/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "90/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "91/326, Train_loss: 0.0779 Train_dice: 0.9221\n",
            "92/326, Train_loss: 0.0851 Train_dice: 0.9149\n",
            "93/326, Train_loss: 0.1733 Train_dice: 0.8267\n",
            "94/326, Train_loss: 0.1175 Train_dice: 0.8825\n",
            "95/326, Train_loss: 0.2423 Train_dice: 0.7577\n",
            "96/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "97/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "98/326, Train_loss: 0.1579 Train_dice: 0.8421\n",
            "99/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "100/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "101/326, Train_loss: 0.0829 Train_dice: 0.9171\n",
            "102/326, Train_loss: 0.0698 Train_dice: 0.9302\n",
            "103/326, Train_loss: 0.0616 Train_dice: 0.9384\n",
            "104/326, Train_loss: 0.0887 Train_dice: 0.9113\n",
            "105/326, Train_loss: 0.0626 Train_dice: 0.9374\n",
            "106/326, Train_loss: 0.0844 Train_dice: 0.9156\n",
            "107/326, Train_loss: 0.0880 Train_dice: 0.9120\n",
            "108/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "109/326, Train_loss: 0.0826 Train_dice: 0.9174\n",
            "110/326, Train_loss: 0.1666 Train_dice: 0.8334\n",
            "111/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "112/326, Train_loss: 0.1849 Train_dice: 0.8151\n",
            "113/326, Train_loss: 0.0636 Train_dice: 0.9364\n",
            "114/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "115/326, Train_loss: 0.1265 Train_dice: 0.8735\n",
            "116/326, Train_loss: 0.2320 Train_dice: 0.7680\n",
            "117/326, Train_loss: 0.0783 Train_dice: 0.9217\n",
            "118/326, Train_loss: 0.1978 Train_dice: 0.8022\n",
            "119/326, Train_loss: 0.1056 Train_dice: 0.8944\n",
            "120/326, Train_loss: 0.0592 Train_dice: 0.9408\n",
            "121/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "122/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "123/326, Train_loss: 0.0735 Train_dice: 0.9265\n",
            "124/326, Train_loss: 0.1192 Train_dice: 0.8808\n",
            "125/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "126/326, Train_loss: 0.1652 Train_dice: 0.8348\n",
            "127/326, Train_loss: 0.0754 Train_dice: 0.9246\n",
            "128/326, Train_loss: 0.1330 Train_dice: 0.8670\n",
            "129/326, Train_loss: 0.2815 Train_dice: 0.7185\n",
            "130/326, Train_loss: 0.1581 Train_dice: 0.8419\n",
            "131/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "132/326, Train_loss: 0.1567 Train_dice: 0.8433\n",
            "133/326, Train_loss: 0.1145 Train_dice: 0.8855\n",
            "134/326, Train_loss: 0.2769 Train_dice: 0.7231\n",
            "135/326, Train_loss: 0.1182 Train_dice: 0.8818\n",
            "136/326, Train_loss: 0.1652 Train_dice: 0.8348\n",
            "137/326, Train_loss: 0.1133 Train_dice: 0.8867\n",
            "138/326, Train_loss: 0.0683 Train_dice: 0.9317\n",
            "139/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "140/326, Train_loss: 0.1185 Train_dice: 0.8815\n",
            "141/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "142/326, Train_loss: 0.1651 Train_dice: 0.8349\n",
            "143/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "144/326, Train_loss: 0.0979 Train_dice: 0.9021\n",
            "145/326, Train_loss: 0.2193 Train_dice: 0.7807\n",
            "146/326, Train_loss: 0.1001 Train_dice: 0.8999\n",
            "147/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "148/326, Train_loss: 0.1475 Train_dice: 0.8525\n",
            "149/326, Train_loss: 0.0857 Train_dice: 0.9143\n",
            "150/326, Train_loss: 0.1654 Train_dice: 0.8346\n",
            "151/326, Train_loss: 0.1108 Train_dice: 0.8892\n",
            "152/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "153/326, Train_loss: 0.1939 Train_dice: 0.8061\n",
            "154/326, Train_loss: 0.0896 Train_dice: 0.9104\n",
            "155/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "156/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "157/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "158/326, Train_loss: 0.2364 Train_dice: 0.7636\n",
            "159/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "160/326, Train_loss: 0.0715 Train_dice: 0.9285\n",
            "161/326, Train_loss: 0.1127 Train_dice: 0.8873\n",
            "162/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "163/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "164/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "165/326, Train_loss: 0.1654 Train_dice: 0.8346\n",
            "166/326, Train_loss: 0.1694 Train_dice: 0.8306\n",
            "167/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "168/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "169/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "170/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "171/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "172/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "173/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "174/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "175/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "176/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "177/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "178/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "179/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "180/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "181/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "182/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "183/326, Train_loss: 0.1076 Train_dice: 0.8924\n",
            "184/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "185/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "186/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "187/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "188/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "189/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "190/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "191/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "192/326, Train_loss: 0.0746 Train_dice: 0.9254\n",
            "193/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "194/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "195/326, Train_loss: 0.1273 Train_dice: 0.8727\n",
            "196/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "197/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "198/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "199/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "200/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "201/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "202/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "203/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "204/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "205/326, Train_loss: 0.4025 Train_dice: 0.5975\n",
            "206/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "207/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "208/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "209/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "210/326, Train_loss: 0.1711 Train_dice: 0.8289\n",
            "211/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "212/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "213/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "214/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "215/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "216/326, Train_loss: 0.0193 Train_dice: 0.9807\n",
            "217/326, Train_loss: 0.0896 Train_dice: 0.9104\n",
            "218/326, Train_loss: 0.1051 Train_dice: 0.8949\n",
            "219/326, Train_loss: 0.1042 Train_dice: 0.8958\n",
            "220/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "221/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "222/326, Train_loss: 0.0637 Train_dice: 0.9363\n",
            "223/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "224/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "225/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "226/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "227/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "228/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "229/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "230/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "231/326, Train_loss: 0.1043 Train_dice: 0.8957\n",
            "232/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "233/326, Train_loss: 0.2077 Train_dice: 0.7923\n",
            "234/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "235/326, Train_loss: 0.1651 Train_dice: 0.8349\n",
            "236/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "237/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "238/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "239/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "240/326, Train_loss: 0.1320 Train_dice: 0.8680\n",
            "241/326, Train_loss: 0.1288 Train_dice: 0.8712\n",
            "242/326, Train_loss: 0.1348 Train_dice: 0.8652\n",
            "243/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "244/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "245/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "246/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "247/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "248/326, Train_loss: 0.0951 Train_dice: 0.9049\n",
            "249/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "250/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "251/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "252/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "253/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "254/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "255/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "256/326, Train_loss: 0.1403 Train_dice: 0.8597\n",
            "257/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "258/326, Train_loss: 0.2500 Train_dice: 0.7500\n",
            "259/326, Train_loss: 0.0771 Train_dice: 0.9229\n",
            "260/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "261/326, Train_loss: 0.1608 Train_dice: 0.8392\n",
            "262/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "263/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "264/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "265/326, Train_loss: 0.1093 Train_dice: 0.8907\n",
            "266/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "267/326, Train_loss: 0.0810 Train_dice: 0.9190\n",
            "268/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "269/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "270/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "271/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "272/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "273/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "274/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "275/326, Train_loss: 0.1643 Train_dice: 0.8357\n",
            "276/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "277/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "278/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "279/326, Train_loss: 0.1756 Train_dice: 0.8244\n",
            "280/326, Train_loss: 0.0983 Train_dice: 0.9017\n",
            "281/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "282/326, Train_loss: 0.1062 Train_dice: 0.8938\n",
            "283/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "284/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "285/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "286/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "287/326, Train_loss: 0.0896 Train_dice: 0.9104\n",
            "288/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "289/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "290/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "291/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "292/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "293/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "294/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "295/326, Train_loss: 0.1173 Train_dice: 0.8827\n",
            "296/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "297/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "298/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "299/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "300/326, Train_loss: 0.1167 Train_dice: 0.8833\n",
            "301/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "302/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "303/326, Train_loss: 0.1283 Train_dice: 0.8717\n",
            "304/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "305/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "306/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "307/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "308/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "309/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "310/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "311/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "312/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "313/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "314/326, Train_loss: 0.0298 Train_dice: 0.9702\n",
            "315/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "316/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "317/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "318/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "319/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "320/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "321/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "322/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "323/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "324/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "325/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "326/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "--------------------\n",
            "Epoch_loss: 0.0743\n",
            "Epoch_metric: 0.9257\n",
            "----------\n",
            "epoch 138/250\n",
            "1/326, Train_loss: 0.1238 Train_dice: 0.8762\n",
            "2/326, Train_loss: 0.1725 Train_dice: 0.8275\n",
            "3/326, Train_loss: 0.2069 Train_dice: 0.7931\n",
            "4/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "5/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "6/326, Train_loss: 0.1397 Train_dice: 0.8603\n",
            "7/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "8/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "9/326, Train_loss: 0.0745 Train_dice: 0.9255\n",
            "10/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "11/326, Train_loss: 0.1582 Train_dice: 0.8418\n",
            "12/326, Train_loss: 0.1744 Train_dice: 0.8256\n",
            "13/326, Train_loss: 0.0968 Train_dice: 0.9032\n",
            "14/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "15/326, Train_loss: 0.2252 Train_dice: 0.7748\n",
            "16/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "17/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "18/326, Train_loss: 0.1743 Train_dice: 0.8257\n",
            "19/326, Train_loss: 0.0727 Train_dice: 0.9273\n",
            "20/326, Train_loss: 0.1284 Train_dice: 0.8716\n",
            "21/326, Train_loss: 0.0626 Train_dice: 0.9374\n",
            "22/326, Train_loss: 0.0725 Train_dice: 0.9275\n",
            "23/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "24/326, Train_loss: 0.1486 Train_dice: 0.8514\n",
            "25/326, Train_loss: 0.0912 Train_dice: 0.9088\n",
            "26/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "27/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "28/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "29/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "30/326, Train_loss: 0.0550 Train_dice: 0.9450\n",
            "31/326, Train_loss: 0.2003 Train_dice: 0.7997\n",
            "32/326, Train_loss: 0.1263 Train_dice: 0.8737\n",
            "33/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "34/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "35/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "36/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "37/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "38/326, Train_loss: 0.1412 Train_dice: 0.8588\n",
            "39/326, Train_loss: 0.1020 Train_dice: 0.8980\n",
            "40/326, Train_loss: 0.0343 Train_dice: 0.9657\n",
            "41/326, Train_loss: 0.0756 Train_dice: 0.9244\n",
            "42/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "43/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "44/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "45/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "46/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "47/326, Train_loss: 0.1905 Train_dice: 0.8095\n",
            "48/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "49/326, Train_loss: 0.0961 Train_dice: 0.9039\n",
            "50/326, Train_loss: 0.1127 Train_dice: 0.8873\n",
            "51/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "52/326, Train_loss: 0.1280 Train_dice: 0.8720\n",
            "53/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "54/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "55/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "56/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "57/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "58/326, Train_loss: 0.0466 Train_dice: 0.9534\n",
            "59/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "60/326, Train_loss: 0.0585 Train_dice: 0.9415\n",
            "61/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "62/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "63/326, Train_loss: 0.1250 Train_dice: 0.8750\n",
            "64/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "65/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "66/326, Train_loss: 0.1108 Train_dice: 0.8892\n",
            "67/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "68/326, Train_loss: 0.1053 Train_dice: 0.8947\n",
            "69/326, Train_loss: 0.0500 Train_dice: 0.9500\n",
            "70/326, Train_loss: 0.2224 Train_dice: 0.7776\n",
            "71/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "72/326, Train_loss: 0.1632 Train_dice: 0.8368\n",
            "73/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "74/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "75/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "76/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "77/326, Train_loss: 0.1514 Train_dice: 0.8486\n",
            "78/326, Train_loss: 0.1103 Train_dice: 0.8897\n",
            "79/326, Train_loss: 0.1572 Train_dice: 0.8428\n",
            "80/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "81/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "82/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "83/326, Train_loss: 0.1094 Train_dice: 0.8906\n",
            "84/326, Train_loss: 0.2211 Train_dice: 0.7789\n",
            "85/326, Train_loss: 0.0884 Train_dice: 0.9116\n",
            "86/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "87/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "88/326, Train_loss: 0.1100 Train_dice: 0.8900\n",
            "89/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "90/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "91/326, Train_loss: 0.0737 Train_dice: 0.9263\n",
            "92/326, Train_loss: 0.0808 Train_dice: 0.9192\n",
            "93/326, Train_loss: 0.1659 Train_dice: 0.8341\n",
            "94/326, Train_loss: 0.1120 Train_dice: 0.8880\n",
            "95/326, Train_loss: 0.2329 Train_dice: 0.7671\n",
            "96/326, Train_loss: 0.0772 Train_dice: 0.9228\n",
            "97/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "98/326, Train_loss: 0.1508 Train_dice: 0.8492\n",
            "99/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "100/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "101/326, Train_loss: 0.0783 Train_dice: 0.9217\n",
            "102/326, Train_loss: 0.0659 Train_dice: 0.9341\n",
            "103/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "104/326, Train_loss: 0.0838 Train_dice: 0.9162\n",
            "105/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "106/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "107/326, Train_loss: 0.0826 Train_dice: 0.9174\n",
            "108/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "109/326, Train_loss: 0.0779 Train_dice: 0.9221\n",
            "110/326, Train_loss: 0.1576 Train_dice: 0.8424\n",
            "111/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "112/326, Train_loss: 0.1760 Train_dice: 0.8240\n",
            "113/326, Train_loss: 0.0603 Train_dice: 0.9397\n",
            "114/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "115/326, Train_loss: 0.1198 Train_dice: 0.8802\n",
            "116/326, Train_loss: 0.2233 Train_dice: 0.7767\n",
            "117/326, Train_loss: 0.0732 Train_dice: 0.9268\n",
            "118/326, Train_loss: 0.1892 Train_dice: 0.8108\n",
            "119/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "120/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "121/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "122/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "123/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "124/326, Train_loss: 0.1131 Train_dice: 0.8869\n",
            "125/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "126/326, Train_loss: 0.1577 Train_dice: 0.8423\n",
            "127/326, Train_loss: 0.0714 Train_dice: 0.9286\n",
            "128/326, Train_loss: 0.1264 Train_dice: 0.8736\n",
            "129/326, Train_loss: 0.2704 Train_dice: 0.7296\n",
            "130/326, Train_loss: 0.1500 Train_dice: 0.8500\n",
            "131/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "132/326, Train_loss: 0.1485 Train_dice: 0.8515\n",
            "133/326, Train_loss: 0.1086 Train_dice: 0.8914\n",
            "134/326, Train_loss: 0.2665 Train_dice: 0.7335\n",
            "135/326, Train_loss: 0.1118 Train_dice: 0.8882\n",
            "136/326, Train_loss: 0.1570 Train_dice: 0.8430\n",
            "137/326, Train_loss: 0.1068 Train_dice: 0.8932\n",
            "138/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "139/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "140/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "141/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "142/326, Train_loss: 0.1571 Train_dice: 0.8429\n",
            "143/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "144/326, Train_loss: 0.0923 Train_dice: 0.9077\n",
            "145/326, Train_loss: 0.2099 Train_dice: 0.7901\n",
            "146/326, Train_loss: 0.0949 Train_dice: 0.9051\n",
            "147/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "148/326, Train_loss: 0.1383 Train_dice: 0.8617\n",
            "149/326, Train_loss: 0.0810 Train_dice: 0.9190\n",
            "150/326, Train_loss: 0.1575 Train_dice: 0.8425\n",
            "151/326, Train_loss: 0.1051 Train_dice: 0.8949\n",
            "152/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "153/326, Train_loss: 0.1840 Train_dice: 0.8160\n",
            "154/326, Train_loss: 0.0849 Train_dice: 0.9151\n",
            "155/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "156/326, Train_loss: 0.0885 Train_dice: 0.9115\n",
            "157/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "158/326, Train_loss: 0.2253 Train_dice: 0.7747\n",
            "159/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "160/326, Train_loss: 0.0677 Train_dice: 0.9323\n",
            "161/326, Train_loss: 0.1091 Train_dice: 0.8909\n",
            "162/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "163/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "164/326, Train_loss: 0.0193 Train_dice: 0.9807\n",
            "165/326, Train_loss: 0.1581 Train_dice: 0.8419\n",
            "166/326, Train_loss: 0.1595 Train_dice: 0.8405\n",
            "167/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "168/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "169/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "170/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "171/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "172/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "173/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "174/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "175/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "176/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "177/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "178/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "179/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "180/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "181/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "182/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "183/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "184/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "185/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "186/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "187/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "188/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "189/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "190/326, Train_loss: 0.0742 Train_dice: 0.9258\n",
            "191/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "192/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "193/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "194/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "195/326, Train_loss: 0.1135 Train_dice: 0.8865\n",
            "196/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "197/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "198/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "199/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "200/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "201/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "202/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "203/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "204/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "205/326, Train_loss: 0.3307 Train_dice: 0.6693\n",
            "206/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "207/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "208/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "209/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "210/326, Train_loss: 0.1569 Train_dice: 0.8431\n",
            "211/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "212/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "213/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "214/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "215/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "216/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "217/326, Train_loss: 0.0788 Train_dice: 0.9212\n",
            "218/326, Train_loss: 0.0859 Train_dice: 0.9141\n",
            "219/326, Train_loss: 0.0887 Train_dice: 0.9113\n",
            "220/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "221/326, Train_loss: 0.0176 Train_dice: 0.9824\n",
            "222/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "223/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "224/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "225/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "226/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "227/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "228/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "229/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "230/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "231/326, Train_loss: 0.0921 Train_dice: 0.9079\n",
            "232/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "233/326, Train_loss: 0.1921 Train_dice: 0.8079\n",
            "234/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "235/326, Train_loss: 0.1550 Train_dice: 0.8450\n",
            "236/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "237/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "238/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "239/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "240/326, Train_loss: 0.1231 Train_dice: 0.8769\n",
            "241/326, Train_loss: 0.1191 Train_dice: 0.8809\n",
            "242/326, Train_loss: 0.1229 Train_dice: 0.8771\n",
            "243/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "244/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "245/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "246/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "247/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "248/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "249/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "250/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "251/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "252/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "253/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "254/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "255/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "256/326, Train_loss: 0.1263 Train_dice: 0.8737\n",
            "257/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "258/326, Train_loss: 0.2356 Train_dice: 0.7644\n",
            "259/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "260/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "261/326, Train_loss: 0.1510 Train_dice: 0.8490\n",
            "262/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "263/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "264/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "265/326, Train_loss: 0.0932 Train_dice: 0.9068\n",
            "266/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "267/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "268/326, Train_loss: 0.0710 Train_dice: 0.9290\n",
            "269/326, Train_loss: 0.0816 Train_dice: 0.9184\n",
            "270/326, Train_loss: 0.0872 Train_dice: 0.9128\n",
            "271/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "272/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "273/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "274/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "275/326, Train_loss: 0.1538 Train_dice: 0.8462\n",
            "276/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "277/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "278/326, Train_loss: 0.1037 Train_dice: 0.8963\n",
            "279/326, Train_loss: 0.1641 Train_dice: 0.8359\n",
            "280/326, Train_loss: 0.0849 Train_dice: 0.9151\n",
            "281/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "282/326, Train_loss: 0.0957 Train_dice: 0.9043\n",
            "283/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "284/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "285/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "286/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "287/326, Train_loss: 0.0841 Train_dice: 0.9159\n",
            "288/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "289/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "290/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "291/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "292/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "293/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "294/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "295/326, Train_loss: 0.1123 Train_dice: 0.8877\n",
            "296/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "297/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "298/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "299/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "300/326, Train_loss: 0.1065 Train_dice: 0.8935\n",
            "301/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "302/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "303/326, Train_loss: 0.1191 Train_dice: 0.8809\n",
            "304/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "305/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "306/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "307/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "308/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "309/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "310/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "311/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "312/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "313/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "314/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "315/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "316/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "317/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "318/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "319/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "320/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "321/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "322/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "323/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "324/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "325/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "326/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "--------------------\n",
            "Epoch_loss: 0.0678\n",
            "Epoch_metric: 0.9322\n",
            "----------\n",
            "epoch 139/250\n",
            "1/326, Train_loss: 0.1176 Train_dice: 0.8824\n",
            "2/326, Train_loss: 0.1678 Train_dice: 0.8322\n",
            "3/326, Train_loss: 0.1973 Train_dice: 0.8027\n",
            "4/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "5/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "6/326, Train_loss: 0.1331 Train_dice: 0.8669\n",
            "7/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "8/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "9/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "10/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "11/326, Train_loss: 0.1531 Train_dice: 0.8469\n",
            "12/326, Train_loss: 0.1660 Train_dice: 0.8340\n",
            "13/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "14/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "15/326, Train_loss: 0.2171 Train_dice: 0.7829\n",
            "16/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "17/326, Train_loss: 0.0348 Train_dice: 0.9652\n",
            "18/326, Train_loss: 0.1660 Train_dice: 0.8340\n",
            "19/326, Train_loss: 0.0686 Train_dice: 0.9314\n",
            "20/326, Train_loss: 0.1222 Train_dice: 0.8778\n",
            "21/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "22/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "23/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "24/326, Train_loss: 0.1416 Train_dice: 0.8584\n",
            "25/326, Train_loss: 0.0867 Train_dice: 0.9133\n",
            "26/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "27/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "28/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "29/326, Train_loss: 0.0842 Train_dice: 0.9158\n",
            "30/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "31/326, Train_loss: 0.1920 Train_dice: 0.8080\n",
            "32/326, Train_loss: 0.1197 Train_dice: 0.8803\n",
            "33/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "34/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "35/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "36/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "37/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "38/326, Train_loss: 0.1351 Train_dice: 0.8649\n",
            "39/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "40/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "41/326, Train_loss: 0.0708 Train_dice: 0.9292\n",
            "42/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "43/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "44/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "45/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "46/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "47/326, Train_loss: 0.1821 Train_dice: 0.8179\n",
            "48/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "49/326, Train_loss: 0.0909 Train_dice: 0.9091\n",
            "50/326, Train_loss: 0.1070 Train_dice: 0.8930\n",
            "51/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "52/326, Train_loss: 0.1208 Train_dice: 0.8792\n",
            "53/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "54/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "55/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "56/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "57/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "58/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "59/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "60/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "61/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "62/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "63/326, Train_loss: 0.1172 Train_dice: 0.8828\n",
            "64/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "65/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "66/326, Train_loss: 0.1028 Train_dice: 0.8972\n",
            "67/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "68/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "69/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "70/326, Train_loss: 0.2117 Train_dice: 0.7883\n",
            "71/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "72/326, Train_loss: 0.1525 Train_dice: 0.8475\n",
            "73/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "74/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "75/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "76/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "77/326, Train_loss: 0.1437 Train_dice: 0.8563\n",
            "78/326, Train_loss: 0.1054 Train_dice: 0.8946\n",
            "79/326, Train_loss: 0.1495 Train_dice: 0.8505\n",
            "80/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "81/326, Train_loss: 0.0257 Train_dice: 0.9743\n",
            "82/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "83/326, Train_loss: 0.1041 Train_dice: 0.8959\n",
            "84/326, Train_loss: 0.2115 Train_dice: 0.7885\n",
            "85/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "86/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "87/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "88/326, Train_loss: 0.1037 Train_dice: 0.8963\n",
            "89/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "90/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "91/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "92/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "93/326, Train_loss: 0.1588 Train_dice: 0.8412\n",
            "94/326, Train_loss: 0.1067 Train_dice: 0.8933\n",
            "95/326, Train_loss: 0.2235 Train_dice: 0.7765\n",
            "96/326, Train_loss: 0.0729 Train_dice: 0.9271\n",
            "97/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "98/326, Train_loss: 0.1444 Train_dice: 0.8556\n",
            "99/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "100/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "101/326, Train_loss: 0.0747 Train_dice: 0.9253\n",
            "102/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "103/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "104/326, Train_loss: 0.0798 Train_dice: 0.9202\n",
            "105/326, Train_loss: 0.0558 Train_dice: 0.9442\n",
            "106/326, Train_loss: 0.0752 Train_dice: 0.9248\n",
            "107/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "108/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "109/326, Train_loss: 0.0742 Train_dice: 0.9258\n",
            "110/326, Train_loss: 0.1501 Train_dice: 0.8499\n",
            "111/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "112/326, Train_loss: 0.1680 Train_dice: 0.8320\n",
            "113/326, Train_loss: 0.0568 Train_dice: 0.9432\n",
            "114/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "115/326, Train_loss: 0.1139 Train_dice: 0.8861\n",
            "116/326, Train_loss: 0.2149 Train_dice: 0.7851\n",
            "117/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "118/326, Train_loss: 0.1811 Train_dice: 0.8189\n",
            "119/326, Train_loss: 0.0953 Train_dice: 0.9047\n",
            "120/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "121/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "122/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "123/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "124/326, Train_loss: 0.1076 Train_dice: 0.8924\n",
            "125/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "126/326, Train_loss: 0.1500 Train_dice: 0.8500\n",
            "127/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "128/326, Train_loss: 0.1199 Train_dice: 0.8801\n",
            "129/326, Train_loss: 0.2599 Train_dice: 0.7401\n",
            "130/326, Train_loss: 0.1428 Train_dice: 0.8572\n",
            "131/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "132/326, Train_loss: 0.1411 Train_dice: 0.8589\n",
            "133/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "134/326, Train_loss: 0.2565 Train_dice: 0.7435\n",
            "135/326, Train_loss: 0.1063 Train_dice: 0.8937\n",
            "136/326, Train_loss: 0.1496 Train_dice: 0.8504\n",
            "137/326, Train_loss: 0.1017 Train_dice: 0.8983\n",
            "138/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "139/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "140/326, Train_loss: 0.1069 Train_dice: 0.8931\n",
            "141/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "142/326, Train_loss: 0.1495 Train_dice: 0.8505\n",
            "143/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "144/326, Train_loss: 0.0875 Train_dice: 0.9125\n",
            "145/326, Train_loss: 0.2011 Train_dice: 0.7989\n",
            "146/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "147/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "148/326, Train_loss: 0.1320 Train_dice: 0.8680\n",
            "149/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "150/326, Train_loss: 0.1501 Train_dice: 0.8499\n",
            "151/326, Train_loss: 0.0999 Train_dice: 0.9001\n",
            "152/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "153/326, Train_loss: 0.1757 Train_dice: 0.8243\n",
            "154/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "155/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "156/326, Train_loss: 0.0843 Train_dice: 0.9157\n",
            "157/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "158/326, Train_loss: 0.2136 Train_dice: 0.7864\n",
            "159/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "160/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "161/326, Train_loss: 0.1021 Train_dice: 0.8979\n",
            "162/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "163/326, Train_loss: 0.0332 Train_dice: 0.9668\n",
            "164/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "165/326, Train_loss: 0.1494 Train_dice: 0.8506\n",
            "166/326, Train_loss: 0.1504 Train_dice: 0.8496\n",
            "167/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "168/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "169/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "170/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "171/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "172/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "173/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "174/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "175/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "176/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "177/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "178/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "179/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "180/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "181/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "182/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "183/326, Train_loss: 0.0933 Train_dice: 0.9067\n",
            "184/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "185/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "186/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "187/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "188/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "189/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "190/326, Train_loss: 0.0670 Train_dice: 0.9330\n",
            "191/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "192/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "193/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "194/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "195/326, Train_loss: 0.1040 Train_dice: 0.8960\n",
            "196/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "197/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "198/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "199/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "200/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "201/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "202/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "203/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "204/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "205/326, Train_loss: 0.2725 Train_dice: 0.7275\n",
            "206/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "207/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "208/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "209/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "210/326, Train_loss: 0.1457 Train_dice: 0.8543\n",
            "211/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "212/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "213/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "214/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "215/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "216/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "217/326, Train_loss: 0.0718 Train_dice: 0.9282\n",
            "218/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "219/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "220/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "221/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "222/326, Train_loss: 0.0544 Train_dice: 0.9456\n",
            "223/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "224/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "225/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "226/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "227/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "228/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "229/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "230/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "231/326, Train_loss: 0.0848 Train_dice: 0.9152\n",
            "232/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "233/326, Train_loss: 0.1803 Train_dice: 0.8197\n",
            "234/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "235/326, Train_loss: 0.1460 Train_dice: 0.8540\n",
            "236/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "237/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "238/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "239/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "240/326, Train_loss: 0.1167 Train_dice: 0.8833\n",
            "241/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "242/326, Train_loss: 0.1143 Train_dice: 0.8857\n",
            "243/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "244/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "245/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "246/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "247/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "248/326, Train_loss: 0.0812 Train_dice: 0.9188\n",
            "249/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "250/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "251/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "252/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "253/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "254/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "255/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "256/326, Train_loss: 0.1178 Train_dice: 0.8822\n",
            "257/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "258/326, Train_loss: 0.2223 Train_dice: 0.7777\n",
            "259/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "260/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "261/326, Train_loss: 0.1428 Train_dice: 0.8572\n",
            "262/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "263/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "264/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "265/326, Train_loss: 0.0812 Train_dice: 0.9188\n",
            "266/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "267/326, Train_loss: 0.0702 Train_dice: 0.9298\n",
            "268/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "269/326, Train_loss: 0.0754 Train_dice: 0.9246\n",
            "270/326, Train_loss: 0.0816 Train_dice: 0.9184\n",
            "271/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "272/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "273/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "274/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "275/326, Train_loss: 0.1443 Train_dice: 0.8557\n",
            "276/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "277/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "278/326, Train_loss: 0.0966 Train_dice: 0.9034\n",
            "279/326, Train_loss: 0.1553 Train_dice: 0.8447\n",
            "280/326, Train_loss: 0.0779 Train_dice: 0.9221\n",
            "281/326, Train_loss: 0.0302 Train_dice: 0.9698\n",
            "282/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "283/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "284/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "285/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "286/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "287/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "288/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "289/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "290/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "291/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "292/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "293/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "294/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "295/326, Train_loss: 0.1046 Train_dice: 0.8954\n",
            "296/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "297/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "298/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "299/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "300/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "301/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "302/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "303/326, Train_loss: 0.1088 Train_dice: 0.8912\n",
            "304/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "305/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "306/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "307/326, Train_loss: 0.0176 Train_dice: 0.9824\n",
            "308/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "309/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "310/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "311/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "312/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "313/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "314/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "315/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "316/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "317/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "318/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "319/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "320/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "321/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "322/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "323/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "324/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "325/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "326/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "--------------------\n",
            "Epoch_loss: 0.0634\n",
            "Epoch_metric: 0.9366\n",
            "----------\n",
            "epoch 140/250\n",
            "1/326, Train_loss: 0.1120 Train_dice: 0.8880\n",
            "2/326, Train_loss: 0.1604 Train_dice: 0.8396\n",
            "3/326, Train_loss: 0.1913 Train_dice: 0.8087\n",
            "4/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "5/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "6/326, Train_loss: 0.1254 Train_dice: 0.8746\n",
            "7/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "8/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "9/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "10/326, Train_loss: 0.0466 Train_dice: 0.9534\n",
            "11/326, Train_loss: 0.1472 Train_dice: 0.8528\n",
            "12/326, Train_loss: 0.1595 Train_dice: 0.8405\n",
            "13/326, Train_loss: 0.0875 Train_dice: 0.9125\n",
            "14/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "15/326, Train_loss: 0.2091 Train_dice: 0.7909\n",
            "16/326, Train_loss: 0.0658 Train_dice: 0.9342\n",
            "17/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "18/326, Train_loss: 0.1585 Train_dice: 0.8415\n",
            "19/326, Train_loss: 0.0652 Train_dice: 0.9348\n",
            "20/326, Train_loss: 0.1167 Train_dice: 0.8833\n",
            "21/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "22/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "23/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "24/326, Train_loss: 0.1361 Train_dice: 0.8639\n",
            "25/326, Train_loss: 0.0829 Train_dice: 0.9171\n",
            "26/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "27/326, Train_loss: 0.0604 Train_dice: 0.9396\n",
            "28/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "29/326, Train_loss: 0.0802 Train_dice: 0.9198\n",
            "30/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "31/326, Train_loss: 0.1842 Train_dice: 0.8158\n",
            "32/326, Train_loss: 0.1136 Train_dice: 0.8864\n",
            "33/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "34/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "35/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "36/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "37/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "38/326, Train_loss: 0.1281 Train_dice: 0.8719\n",
            "39/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "40/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "41/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "42/326, Train_loss: 0.0536 Train_dice: 0.9464\n",
            "43/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "44/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "45/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "46/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "47/326, Train_loss: 0.1756 Train_dice: 0.8244\n",
            "48/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "49/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "50/326, Train_loss: 0.1020 Train_dice: 0.8980\n",
            "51/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "52/326, Train_loss: 0.1151 Train_dice: 0.8849\n",
            "53/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "54/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "55/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "56/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "57/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "58/326, Train_loss: 0.0409 Train_dice: 0.9591\n",
            "59/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "60/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "61/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "62/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "63/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "64/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "65/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "66/326, Train_loss: 0.0974 Train_dice: 0.9026\n",
            "67/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "68/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "69/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "70/326, Train_loss: 0.2028 Train_dice: 0.7972\n",
            "71/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "72/326, Train_loss: 0.1443 Train_dice: 0.8557\n",
            "73/326, Train_loss: 0.0603 Train_dice: 0.9397\n",
            "74/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "75/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "76/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "77/326, Train_loss: 0.1359 Train_dice: 0.8641\n",
            "78/326, Train_loss: 0.0999 Train_dice: 0.9001\n",
            "79/326, Train_loss: 0.1422 Train_dice: 0.8578\n",
            "80/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "81/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "82/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "83/326, Train_loss: 0.0985 Train_dice: 0.9015\n",
            "84/326, Train_loss: 0.2025 Train_dice: 0.7975\n",
            "85/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "86/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "87/326, Train_loss: 0.0471 Train_dice: 0.9529\n",
            "88/326, Train_loss: 0.0984 Train_dice: 0.9016\n",
            "89/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "90/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "91/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "92/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "93/326, Train_loss: 0.1515 Train_dice: 0.8485\n",
            "94/326, Train_loss: 0.1006 Train_dice: 0.8994\n",
            "95/326, Train_loss: 0.2131 Train_dice: 0.7869\n",
            "96/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "97/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "98/326, Train_loss: 0.1373 Train_dice: 0.8627\n",
            "99/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "100/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "101/326, Train_loss: 0.0709 Train_dice: 0.9291\n",
            "102/326, Train_loss: 0.0597 Train_dice: 0.9403\n",
            "103/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "104/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "105/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "106/326, Train_loss: 0.0717 Train_dice: 0.9283\n",
            "107/326, Train_loss: 0.0750 Train_dice: 0.9250\n",
            "108/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "109/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "110/326, Train_loss: 0.1436 Train_dice: 0.8564\n",
            "111/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "112/326, Train_loss: 0.1613 Train_dice: 0.8387\n",
            "113/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "114/326, Train_loss: 0.0757 Train_dice: 0.9243\n",
            "115/326, Train_loss: 0.1082 Train_dice: 0.8918\n",
            "116/326, Train_loss: 0.2064 Train_dice: 0.7936\n",
            "117/326, Train_loss: 0.0658 Train_dice: 0.9342\n",
            "118/326, Train_loss: 0.1732 Train_dice: 0.8268\n",
            "119/326, Train_loss: 0.0904 Train_dice: 0.9096\n",
            "120/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "121/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "122/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "123/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "124/326, Train_loss: 0.1029 Train_dice: 0.8971\n",
            "125/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "126/326, Train_loss: 0.1438 Train_dice: 0.8562\n",
            "127/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "128/326, Train_loss: 0.1142 Train_dice: 0.8858\n",
            "129/326, Train_loss: 0.2506 Train_dice: 0.7494\n",
            "130/326, Train_loss: 0.1372 Train_dice: 0.8628\n",
            "131/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "132/326, Train_loss: 0.1350 Train_dice: 0.8650\n",
            "133/326, Train_loss: 0.0989 Train_dice: 0.9011\n",
            "134/326, Train_loss: 0.2469 Train_dice: 0.7531\n",
            "135/326, Train_loss: 0.1009 Train_dice: 0.8991\n",
            "136/326, Train_loss: 0.1428 Train_dice: 0.8572\n",
            "137/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "138/326, Train_loss: 0.0584 Train_dice: 0.9416\n",
            "139/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "140/326, Train_loss: 0.1017 Train_dice: 0.8983\n",
            "141/326, Train_loss: 0.0503 Train_dice: 0.9497\n",
            "142/326, Train_loss: 0.1426 Train_dice: 0.8574\n",
            "143/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "144/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "145/326, Train_loss: 0.1933 Train_dice: 0.8067\n",
            "146/326, Train_loss: 0.0861 Train_dice: 0.9139\n",
            "147/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "148/326, Train_loss: 0.1262 Train_dice: 0.8738\n",
            "149/326, Train_loss: 0.0737 Train_dice: 0.9263\n",
            "150/326, Train_loss: 0.1424 Train_dice: 0.8576\n",
            "151/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "152/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "153/326, Train_loss: 0.1681 Train_dice: 0.8319\n",
            "154/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "155/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "156/326, Train_loss: 0.0802 Train_dice: 0.9198\n",
            "157/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "158/326, Train_loss: 0.2033 Train_dice: 0.7967\n",
            "159/326, Train_loss: 0.0623 Train_dice: 0.9377\n",
            "160/326, Train_loss: 0.0609 Train_dice: 0.9391\n",
            "161/326, Train_loss: 0.0973 Train_dice: 0.9027\n",
            "162/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "163/326, Train_loss: 0.0314 Train_dice: 0.9686\n",
            "164/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "165/326, Train_loss: 0.1416 Train_dice: 0.8584\n",
            "166/326, Train_loss: 0.1431 Train_dice: 0.8569\n",
            "167/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "168/326, Train_loss: 0.0290 Train_dice: 0.9710\n",
            "169/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "170/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "171/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "172/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "173/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "174/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "175/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "176/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "177/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "178/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "179/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "180/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "181/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "182/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "183/326, Train_loss: 0.0866 Train_dice: 0.9134\n",
            "184/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "185/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "186/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "187/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "188/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "189/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "190/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "191/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "192/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "193/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "194/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "195/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "196/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "197/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "198/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "199/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "200/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "201/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "202/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "203/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "204/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "205/326, Train_loss: 0.2095 Train_dice: 0.7905\n",
            "206/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "207/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "208/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "209/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "210/326, Train_loss: 0.1320 Train_dice: 0.8680\n",
            "211/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "212/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "213/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "214/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "215/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "216/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "217/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "218/326, Train_loss: 0.0606 Train_dice: 0.9394\n",
            "219/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "220/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "221/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "222/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "223/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "224/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "225/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "226/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "227/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "228/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "229/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "230/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "231/326, Train_loss: 0.0789 Train_dice: 0.9211\n",
            "232/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "233/326, Train_loss: 0.1704 Train_dice: 0.8296\n",
            "234/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "235/326, Train_loss: 0.1384 Train_dice: 0.8616\n",
            "236/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "237/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "238/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "239/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "240/326, Train_loss: 0.1103 Train_dice: 0.8897\n",
            "241/326, Train_loss: 0.1063 Train_dice: 0.8937\n",
            "242/326, Train_loss: 0.1069 Train_dice: 0.8931\n",
            "243/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "244/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "245/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "246/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "247/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "248/326, Train_loss: 0.0764 Train_dice: 0.9236\n",
            "249/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "250/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "251/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "252/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "253/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "254/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "255/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "256/326, Train_loss: 0.1121 Train_dice: 0.8879\n",
            "257/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "258/326, Train_loss: 0.2099 Train_dice: 0.7901\n",
            "259/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "260/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "261/326, Train_loss: 0.1354 Train_dice: 0.8646\n",
            "262/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "263/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "264/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "265/326, Train_loss: 0.0709 Train_dice: 0.9291\n",
            "266/326, Train_loss: 0.0471 Train_dice: 0.9529\n",
            "267/326, Train_loss: 0.0670 Train_dice: 0.9330\n",
            "268/326, Train_loss: 0.0607 Train_dice: 0.9393\n",
            "269/326, Train_loss: 0.0740 Train_dice: 0.9260\n",
            "270/326, Train_loss: 0.0768 Train_dice: 0.9232\n",
            "271/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "272/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "273/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "274/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "275/326, Train_loss: 0.1383 Train_dice: 0.8617\n",
            "276/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "277/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "278/326, Train_loss: 0.0909 Train_dice: 0.9091\n",
            "279/326, Train_loss: 0.1485 Train_dice: 0.8515\n",
            "280/326, Train_loss: 0.0729 Train_dice: 0.9271\n",
            "281/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "282/326, Train_loss: 0.0790 Train_dice: 0.9210\n",
            "283/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "284/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "285/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "286/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "287/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "288/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "289/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "290/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "291/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "292/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "293/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "294/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "295/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "296/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "297/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "298/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "299/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "300/326, Train_loss: 0.0877 Train_dice: 0.9123\n",
            "301/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "302/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "303/326, Train_loss: 0.1010 Train_dice: 0.8990\n",
            "304/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "305/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "306/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "307/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "308/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "309/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "310/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "311/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "312/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "313/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "314/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "315/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "316/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "317/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "318/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "319/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "320/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "321/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "322/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "323/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "324/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "325/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "326/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "--------------------\n",
            "Epoch_loss: 0.0596\n",
            "Epoch_metric: 0.9404\n",
            "test_loss_epoch: 0.5133\n",
            "test_dice_epoch: 0.4867\n",
            "current epoch: 140 current mean dice: 0.4867\n",
            "best mean dice: 0.6180 \n",
            "mean jaccard index: 0.0000 at epoch: -2\n",
            "Time Taken:  6728.61523270607\n",
            "Maximum GPU Memory taken for training:  0\n",
            "Maximum CPU Memory taken for training:  229\n",
            "----------\n",
            "epoch 141/250\n",
            "1/326, Train_loss: 0.1058 Train_dice: 0.8942\n",
            "2/326, Train_loss: 0.1500 Train_dice: 0.8500\n",
            "3/326, Train_loss: 0.1799 Train_dice: 0.8201\n",
            "4/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "5/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "6/326, Train_loss: 0.1193 Train_dice: 0.8807\n",
            "7/326, Train_loss: 0.0579 Train_dice: 0.9421\n",
            "8/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "9/326, Train_loss: 0.0634 Train_dice: 0.9366\n",
            "10/326, Train_loss: 0.0442 Train_dice: 0.9558\n",
            "11/326, Train_loss: 0.1394 Train_dice: 0.8606\n",
            "12/326, Train_loss: 0.1520 Train_dice: 0.8480\n",
            "13/326, Train_loss: 0.0821 Train_dice: 0.9179\n",
            "14/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "15/326, Train_loss: 0.2020 Train_dice: 0.7980\n",
            "16/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "17/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "18/326, Train_loss: 0.1534 Train_dice: 0.8466\n",
            "19/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "20/326, Train_loss: 0.1106 Train_dice: 0.8894\n",
            "21/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "22/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "23/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "24/326, Train_loss: 0.1288 Train_dice: 0.8712\n",
            "25/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "26/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "27/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "28/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "29/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "30/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "31/326, Train_loss: 0.1775 Train_dice: 0.8225\n",
            "32/326, Train_loss: 0.1090 Train_dice: 0.8910\n",
            "33/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "34/326, Train_loss: 0.0516 Train_dice: 0.9484\n",
            "35/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "36/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "37/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "38/326, Train_loss: 0.1227 Train_dice: 0.8773\n",
            "39/326, Train_loss: 0.0876 Train_dice: 0.9124\n",
            "40/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "41/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "42/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "43/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "44/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "45/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "46/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "47/326, Train_loss: 0.1687 Train_dice: 0.8313\n",
            "48/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "49/326, Train_loss: 0.0821 Train_dice: 0.9179\n",
            "50/326, Train_loss: 0.0975 Train_dice: 0.9025\n",
            "51/326, Train_loss: 0.0224 Train_dice: 0.9776\n",
            "52/326, Train_loss: 0.1098 Train_dice: 0.8902\n",
            "53/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "54/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "55/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "56/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "57/326, Train_loss: 0.0392 Train_dice: 0.9608\n",
            "58/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "59/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "60/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "61/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "62/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "63/326, Train_loss: 0.1063 Train_dice: 0.8937\n",
            "64/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "65/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "66/326, Train_loss: 0.0930 Train_dice: 0.9070\n",
            "67/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "68/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "69/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "70/326, Train_loss: 0.1947 Train_dice: 0.8053\n",
            "71/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "72/326, Train_loss: 0.1376 Train_dice: 0.8624\n",
            "73/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "74/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "75/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "76/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "77/326, Train_loss: 0.1284 Train_dice: 0.8716\n",
            "78/326, Train_loss: 0.0953 Train_dice: 0.9047\n",
            "79/326, Train_loss: 0.1351 Train_dice: 0.8649\n",
            "80/326, Train_loss: 0.0425 Train_dice: 0.9575\n",
            "81/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "82/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "83/326, Train_loss: 0.0939 Train_dice: 0.9061\n",
            "84/326, Train_loss: 0.1943 Train_dice: 0.8057\n",
            "85/326, Train_loss: 0.0759 Train_dice: 0.9241\n",
            "86/326, Train_loss: 0.0363 Train_dice: 0.9637\n",
            "87/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "88/326, Train_loss: 0.0937 Train_dice: 0.9063\n",
            "89/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "90/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "91/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "92/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "93/326, Train_loss: 0.1447 Train_dice: 0.8553\n",
            "94/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "95/326, Train_loss: 0.2039 Train_dice: 0.7961\n",
            "96/326, Train_loss: 0.0647 Train_dice: 0.9353\n",
            "97/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "98/326, Train_loss: 0.1313 Train_dice: 0.8687\n",
            "99/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "100/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "101/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "102/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "103/326, Train_loss: 0.0498 Train_dice: 0.9502\n",
            "104/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "105/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "106/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "107/326, Train_loss: 0.0710 Train_dice: 0.9290\n",
            "108/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "109/326, Train_loss: 0.0673 Train_dice: 0.9327\n",
            "110/326, Train_loss: 0.1370 Train_dice: 0.8630\n",
            "111/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "112/326, Train_loss: 0.1546 Train_dice: 0.8454\n",
            "113/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "114/326, Train_loss: 0.0727 Train_dice: 0.9273\n",
            "115/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "116/326, Train_loss: 0.1988 Train_dice: 0.8012\n",
            "117/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "118/326, Train_loss: 0.1663 Train_dice: 0.8337\n",
            "119/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "120/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "121/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "122/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "123/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "124/326, Train_loss: 0.0982 Train_dice: 0.9018\n",
            "125/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "126/326, Train_loss: 0.1374 Train_dice: 0.8626\n",
            "127/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "128/326, Train_loss: 0.1077 Train_dice: 0.8923\n",
            "129/326, Train_loss: 0.2413 Train_dice: 0.7587\n",
            "130/326, Train_loss: 0.1317 Train_dice: 0.8683\n",
            "131/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "132/326, Train_loss: 0.1294 Train_dice: 0.8706\n",
            "133/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "134/326, Train_loss: 0.2385 Train_dice: 0.7615\n",
            "135/326, Train_loss: 0.0964 Train_dice: 0.9036\n",
            "136/326, Train_loss: 0.1369 Train_dice: 0.8631\n",
            "137/326, Train_loss: 0.0922 Train_dice: 0.9078\n",
            "138/326, Train_loss: 0.0558 Train_dice: 0.9442\n",
            "139/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "140/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "141/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "142/326, Train_loss: 0.1361 Train_dice: 0.8639\n",
            "143/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "144/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "145/326, Train_loss: 0.1853 Train_dice: 0.8147\n",
            "146/326, Train_loss: 0.0819 Train_dice: 0.9181\n",
            "147/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "148/326, Train_loss: 0.1207 Train_dice: 0.8793\n",
            "149/326, Train_loss: 0.0701 Train_dice: 0.9299\n",
            "150/326, Train_loss: 0.1350 Train_dice: 0.8650\n",
            "151/326, Train_loss: 0.0914 Train_dice: 0.9086\n",
            "152/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "153/326, Train_loss: 0.1605 Train_dice: 0.8395\n",
            "154/326, Train_loss: 0.0732 Train_dice: 0.9268\n",
            "155/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "156/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "157/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "158/326, Train_loss: 0.1950 Train_dice: 0.8050\n",
            "159/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "160/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "161/326, Train_loss: 0.0927 Train_dice: 0.9073\n",
            "162/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "163/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "164/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "165/326, Train_loss: 0.1338 Train_dice: 0.8662\n",
            "166/326, Train_loss: 0.1369 Train_dice: 0.8631\n",
            "167/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "168/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "169/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "170/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "171/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "172/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "173/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "174/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "175/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "176/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "177/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "178/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "179/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "180/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "181/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "182/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "183/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "184/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "185/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "186/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "187/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "188/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "189/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "190/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "191/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "192/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "193/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "194/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "195/326, Train_loss: 0.0865 Train_dice: 0.9135\n",
            "196/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "197/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "198/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "199/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "200/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "201/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "202/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "203/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "204/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "205/326, Train_loss: 0.1652 Train_dice: 0.8348\n",
            "206/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "207/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "208/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "209/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "210/326, Train_loss: 0.1238 Train_dice: 0.8762\n",
            "211/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "212/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "213/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "214/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "215/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "216/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "217/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "218/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "219/326, Train_loss: 0.0607 Train_dice: 0.9393\n",
            "220/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "221/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "222/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "223/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "224/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "225/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "226/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "227/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "228/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "229/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "230/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "231/326, Train_loss: 0.0732 Train_dice: 0.9268\n",
            "232/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "233/326, Train_loss: 0.1597 Train_dice: 0.8403\n",
            "234/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "235/326, Train_loss: 0.1313 Train_dice: 0.8687\n",
            "236/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "237/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "238/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "239/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "240/326, Train_loss: 0.1048 Train_dice: 0.8952\n",
            "241/326, Train_loss: 0.1006 Train_dice: 0.8994\n",
            "242/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "243/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "244/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "245/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "246/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "247/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "248/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "249/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "250/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "251/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "252/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "253/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "254/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "255/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "256/326, Train_loss: 0.1062 Train_dice: 0.8938\n",
            "257/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "258/326, Train_loss: 0.1985 Train_dice: 0.8015\n",
            "259/326, Train_loss: 0.0530 Train_dice: 0.9470\n",
            "260/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "261/326, Train_loss: 0.1297 Train_dice: 0.8703\n",
            "262/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "263/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "264/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "265/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "266/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "267/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "268/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "269/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "270/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "271/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "272/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "273/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "274/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "275/326, Train_loss: 0.1328 Train_dice: 0.8672\n",
            "276/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "277/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "278/326, Train_loss: 0.0862 Train_dice: 0.9138\n",
            "279/326, Train_loss: 0.1422 Train_dice: 0.8578\n",
            "280/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "281/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "282/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "283/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "284/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "285/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "286/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "287/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "288/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "289/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "290/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "291/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "292/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "293/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "294/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "295/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "296/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "297/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "298/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "299/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "300/326, Train_loss: 0.0827 Train_dice: 0.9173\n",
            "301/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "302/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "303/326, Train_loss: 0.0986 Train_dice: 0.9014\n",
            "304/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "305/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "306/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "307/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "308/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "309/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "310/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "311/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "312/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "313/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "314/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "315/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "316/326, Train_loss: 0.0220 Train_dice: 0.9780\n",
            "317/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "318/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "319/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "320/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "321/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "322/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "323/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "324/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "325/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "326/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "--------------------\n",
            "Epoch_loss: 0.0564\n",
            "Epoch_metric: 0.9436\n",
            "----------\n",
            "epoch 142/250\n",
            "1/326, Train_loss: 0.1005 Train_dice: 0.8995\n",
            "2/326, Train_loss: 0.1432 Train_dice: 0.8568\n",
            "3/326, Train_loss: 0.1724 Train_dice: 0.8276\n",
            "4/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "5/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "6/326, Train_loss: 0.1141 Train_dice: 0.8859\n",
            "7/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "8/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "9/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "10/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "11/326, Train_loss: 0.1321 Train_dice: 0.8679\n",
            "12/326, Train_loss: 0.1455 Train_dice: 0.8545\n",
            "13/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "14/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "15/326, Train_loss: 0.1929 Train_dice: 0.8071\n",
            "16/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "17/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "18/326, Train_loss: 0.1464 Train_dice: 0.8536\n",
            "19/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "20/326, Train_loss: 0.1058 Train_dice: 0.8942\n",
            "21/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "22/326, Train_loss: 0.0580 Train_dice: 0.9420\n",
            "23/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "24/326, Train_loss: 0.1229 Train_dice: 0.8771\n",
            "25/326, Train_loss: 0.0751 Train_dice: 0.9249\n",
            "26/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "27/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "28/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "29/326, Train_loss: 0.0724 Train_dice: 0.9276\n",
            "30/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "31/326, Train_loss: 0.1697 Train_dice: 0.8303\n",
            "32/326, Train_loss: 0.1038 Train_dice: 0.8962\n",
            "33/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "34/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "35/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "36/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "37/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "38/326, Train_loss: 0.1173 Train_dice: 0.8827\n",
            "39/326, Train_loss: 0.0842 Train_dice: 0.9158\n",
            "40/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "41/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "42/326, Train_loss: 0.0488 Train_dice: 0.9512\n",
            "43/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "44/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "45/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "46/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "47/326, Train_loss: 0.1617 Train_dice: 0.8383\n",
            "48/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "49/326, Train_loss: 0.0779 Train_dice: 0.9221\n",
            "50/326, Train_loss: 0.0927 Train_dice: 0.9073\n",
            "51/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "52/326, Train_loss: 0.1046 Train_dice: 0.8954\n",
            "53/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "54/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "55/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "56/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "57/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "58/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "59/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "60/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "61/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "62/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "63/326, Train_loss: 0.1009 Train_dice: 0.8991\n",
            "64/326, Train_loss: 0.0425 Train_dice: 0.9575\n",
            "65/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "66/326, Train_loss: 0.0882 Train_dice: 0.9118\n",
            "67/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "68/326, Train_loss: 0.0840 Train_dice: 0.9160\n",
            "69/326, Train_loss: 0.0392 Train_dice: 0.9608\n",
            "70/326, Train_loss: 0.1868 Train_dice: 0.8132\n",
            "71/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "72/326, Train_loss: 0.1326 Train_dice: 0.8674\n",
            "73/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "74/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "75/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "76/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "77/326, Train_loss: 0.1223 Train_dice: 0.8777\n",
            "78/326, Train_loss: 0.0905 Train_dice: 0.9095\n",
            "79/326, Train_loss: 0.1286 Train_dice: 0.8714\n",
            "80/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "81/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "82/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "83/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "84/326, Train_loss: 0.1862 Train_dice: 0.8138\n",
            "85/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "86/326, Train_loss: 0.0348 Train_dice: 0.9652\n",
            "87/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "88/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "89/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "90/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "91/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "92/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "93/326, Train_loss: 0.1386 Train_dice: 0.8614\n",
            "94/326, Train_loss: 0.0908 Train_dice: 0.9092\n",
            "95/326, Train_loss: 0.1951 Train_dice: 0.8049\n",
            "96/326, Train_loss: 0.0616 Train_dice: 0.9384\n",
            "97/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "98/326, Train_loss: 0.1259 Train_dice: 0.8741\n",
            "99/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "100/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "101/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "102/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "103/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "104/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "105/326, Train_loss: 0.0479 Train_dice: 0.9521\n",
            "106/326, Train_loss: 0.0653 Train_dice: 0.9347\n",
            "107/326, Train_loss: 0.0677 Train_dice: 0.9323\n",
            "108/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "109/326, Train_loss: 0.0644 Train_dice: 0.9356\n",
            "110/326, Train_loss: 0.1308 Train_dice: 0.8692\n",
            "111/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "112/326, Train_loss: 0.1487 Train_dice: 0.8513\n",
            "113/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "114/326, Train_loss: 0.0690 Train_dice: 0.9310\n",
            "115/326, Train_loss: 0.0988 Train_dice: 0.9012\n",
            "116/326, Train_loss: 0.1931 Train_dice: 0.8069\n",
            "117/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "118/326, Train_loss: 0.1596 Train_dice: 0.8404\n",
            "119/326, Train_loss: 0.0831 Train_dice: 0.9169\n",
            "120/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "121/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "122/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "123/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "124/326, Train_loss: 0.0938 Train_dice: 0.9062\n",
            "125/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "126/326, Train_loss: 0.1316 Train_dice: 0.8684\n",
            "127/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "128/326, Train_loss: 0.1017 Train_dice: 0.8983\n",
            "129/326, Train_loss: 0.2324 Train_dice: 0.7676\n",
            "130/326, Train_loss: 0.1260 Train_dice: 0.8740\n",
            "131/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "132/326, Train_loss: 0.1241 Train_dice: 0.8759\n",
            "133/326, Train_loss: 0.0905 Train_dice: 0.9095\n",
            "134/326, Train_loss: 0.2306 Train_dice: 0.7694\n",
            "135/326, Train_loss: 0.0925 Train_dice: 0.9075\n",
            "136/326, Train_loss: 0.1314 Train_dice: 0.8686\n",
            "137/326, Train_loss: 0.0882 Train_dice: 0.9118\n",
            "138/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "139/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "140/326, Train_loss: 0.0929 Train_dice: 0.9071\n",
            "141/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "142/326, Train_loss: 0.1311 Train_dice: 0.8689\n",
            "143/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "144/326, Train_loss: 0.0751 Train_dice: 0.9249\n",
            "145/326, Train_loss: 0.1775 Train_dice: 0.8225\n",
            "146/326, Train_loss: 0.0782 Train_dice: 0.9218\n",
            "147/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "148/326, Train_loss: 0.1161 Train_dice: 0.8839\n",
            "149/326, Train_loss: 0.0668 Train_dice: 0.9332\n",
            "150/326, Train_loss: 0.1282 Train_dice: 0.8718\n",
            "151/326, Train_loss: 0.0876 Train_dice: 0.9124\n",
            "152/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "153/326, Train_loss: 0.1532 Train_dice: 0.8468\n",
            "154/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "155/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "156/326, Train_loss: 0.0735 Train_dice: 0.9265\n",
            "157/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "158/326, Train_loss: 0.1885 Train_dice: 0.8115\n",
            "159/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "160/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "161/326, Train_loss: 0.0888 Train_dice: 0.9112\n",
            "162/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "163/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "164/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "165/326, Train_loss: 0.1279 Train_dice: 0.8721\n",
            "166/326, Train_loss: 0.1310 Train_dice: 0.8690\n",
            "167/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "168/326, Train_loss: 0.0257 Train_dice: 0.9743\n",
            "169/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "170/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "171/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "172/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "173/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "174/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "175/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "176/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "177/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "178/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "179/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "180/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "181/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "182/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "183/326, Train_loss: 0.0775 Train_dice: 0.9225\n",
            "184/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "185/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "186/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "187/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "188/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "189/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "190/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "191/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "192/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "193/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "194/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "195/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "196/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "197/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "198/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "199/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "200/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "201/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "202/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "203/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "204/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "205/326, Train_loss: 0.1354 Train_dice: 0.8646\n",
            "206/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "207/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "208/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "209/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "210/326, Train_loss: 0.1164 Train_dice: 0.8836\n",
            "211/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "212/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "213/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "214/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "215/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "216/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "217/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "218/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "219/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "220/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "221/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "222/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "223/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "224/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "225/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "226/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "227/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "228/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "229/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "230/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "231/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "232/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "233/326, Train_loss: 0.1524 Train_dice: 0.8476\n",
            "234/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "235/326, Train_loss: 0.1255 Train_dice: 0.8745\n",
            "236/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "237/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "238/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "239/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "240/326, Train_loss: 0.0993 Train_dice: 0.9007\n",
            "241/326, Train_loss: 0.0946 Train_dice: 0.9054\n",
            "242/326, Train_loss: 0.0962 Train_dice: 0.9038\n",
            "243/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "244/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "245/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "246/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "247/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "248/326, Train_loss: 0.0688 Train_dice: 0.9312\n",
            "249/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "250/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "251/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "252/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "253/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "254/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "255/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "256/326, Train_loss: 0.1026 Train_dice: 0.8974\n",
            "257/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "258/326, Train_loss: 0.1867 Train_dice: 0.8133\n",
            "259/326, Train_loss: 0.0516 Train_dice: 0.9484\n",
            "260/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "261/326, Train_loss: 0.1240 Train_dice: 0.8760\n",
            "262/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "263/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "264/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "265/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "266/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "267/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "268/326, Train_loss: 0.0522 Train_dice: 0.9478\n",
            "269/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "270/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "271/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "272/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "273/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "274/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "275/326, Train_loss: 0.1255 Train_dice: 0.8745\n",
            "276/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "277/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "278/326, Train_loss: 0.0824 Train_dice: 0.9176\n",
            "279/326, Train_loss: 0.1352 Train_dice: 0.8648\n",
            "280/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "281/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "282/326, Train_loss: 0.0739 Train_dice: 0.9261\n",
            "283/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "284/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "285/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "286/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "287/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "288/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "289/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "290/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "291/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "292/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "293/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "294/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "295/326, Train_loss: 0.0930 Train_dice: 0.9070\n",
            "296/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "297/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "298/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "299/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "300/326, Train_loss: 0.0823 Train_dice: 0.9177\n",
            "301/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "302/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "303/326, Train_loss: 0.0980 Train_dice: 0.9020\n",
            "304/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "305/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "306/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "307/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "308/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "309/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "310/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "311/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "312/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "313/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "314/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "315/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "316/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "317/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "318/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "319/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "320/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "321/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "322/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "323/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "324/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "325/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "326/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "--------------------\n",
            "Epoch_loss: 0.0537\n",
            "Epoch_metric: 0.9463\n",
            "----------\n",
            "epoch 143/250\n",
            "1/326, Train_loss: 0.0957 Train_dice: 0.9043\n",
            "2/326, Train_loss: 0.1389 Train_dice: 0.8611\n",
            "3/326, Train_loss: 0.1659 Train_dice: 0.8341\n",
            "4/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "5/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "6/326, Train_loss: 0.1093 Train_dice: 0.8907\n",
            "7/326, Train_loss: 0.0522 Train_dice: 0.9478\n",
            "8/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "9/326, Train_loss: 0.0567 Train_dice: 0.9433\n",
            "10/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "11/326, Train_loss: 0.1271 Train_dice: 0.8729\n",
            "12/326, Train_loss: 0.1386 Train_dice: 0.8614\n",
            "13/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "14/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "15/326, Train_loss: 0.1841 Train_dice: 0.8159\n",
            "16/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "17/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "18/326, Train_loss: 0.1390 Train_dice: 0.8610\n",
            "19/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "20/326, Train_loss: 0.1010 Train_dice: 0.8990\n",
            "21/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "22/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "23/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "24/326, Train_loss: 0.1165 Train_dice: 0.8835\n",
            "25/326, Train_loss: 0.0712 Train_dice: 0.9288\n",
            "26/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "27/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "28/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "29/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "30/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "31/326, Train_loss: 0.1628 Train_dice: 0.8372\n",
            "32/326, Train_loss: 0.0991 Train_dice: 0.9009\n",
            "33/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "34/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "35/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "36/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "37/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "38/326, Train_loss: 0.1117 Train_dice: 0.8883\n",
            "39/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "40/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "41/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "42/326, Train_loss: 0.0463 Train_dice: 0.9537\n",
            "43/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "44/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "45/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "46/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "47/326, Train_loss: 0.1554 Train_dice: 0.8446\n",
            "48/326, Train_loss: 0.0343 Train_dice: 0.9657\n",
            "49/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "50/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "51/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "52/326, Train_loss: 0.1000 Train_dice: 0.9000\n",
            "53/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "54/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "55/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "56/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "57/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "58/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "59/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "60/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "61/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "62/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "63/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "64/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "65/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "66/326, Train_loss: 0.0839 Train_dice: 0.9161\n",
            "67/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "68/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "69/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "70/326, Train_loss: 0.1798 Train_dice: 0.8202\n",
            "71/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "72/326, Train_loss: 0.1260 Train_dice: 0.8740\n",
            "73/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "74/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "75/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "76/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "77/326, Train_loss: 0.1174 Train_dice: 0.8826\n",
            "78/326, Train_loss: 0.0861 Train_dice: 0.9139\n",
            "79/326, Train_loss: 0.1230 Train_dice: 0.8770\n",
            "80/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "81/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "82/326, Train_loss: 0.0343 Train_dice: 0.9657\n",
            "83/326, Train_loss: 0.0852 Train_dice: 0.9148\n",
            "84/326, Train_loss: 0.1793 Train_dice: 0.8207\n",
            "85/326, Train_loss: 0.0684 Train_dice: 0.9316\n",
            "86/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "87/326, Train_loss: 0.0404 Train_dice: 0.9596\n",
            "88/326, Train_loss: 0.0852 Train_dice: 0.9148\n",
            "89/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "90/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "91/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "92/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "93/326, Train_loss: 0.1333 Train_dice: 0.8667\n",
            "94/326, Train_loss: 0.0870 Train_dice: 0.9130\n",
            "95/326, Train_loss: 0.1873 Train_dice: 0.8127\n",
            "96/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "97/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "98/326, Train_loss: 0.1208 Train_dice: 0.8792\n",
            "99/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "100/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "101/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "102/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "103/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "104/326, Train_loss: 0.0662 Train_dice: 0.9338\n",
            "105/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "106/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "107/326, Train_loss: 0.0648 Train_dice: 0.9352\n",
            "108/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "109/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "110/326, Train_loss: 0.1250 Train_dice: 0.8750\n",
            "111/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "112/326, Train_loss: 0.1428 Train_dice: 0.8572\n",
            "113/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "114/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "115/326, Train_loss: 0.0937 Train_dice: 0.9063\n",
            "116/326, Train_loss: 0.1851 Train_dice: 0.8149\n",
            "117/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "118/326, Train_loss: 0.1549 Train_dice: 0.8451\n",
            "119/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "120/326, Train_loss: 0.0439 Train_dice: 0.9561\n",
            "121/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "122/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "123/326, Train_loss: 0.0546 Train_dice: 0.9454\n",
            "124/326, Train_loss: 0.0897 Train_dice: 0.9103\n",
            "125/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "126/326, Train_loss: 0.1262 Train_dice: 0.8738\n",
            "127/326, Train_loss: 0.0558 Train_dice: 0.9442\n",
            "128/326, Train_loss: 0.0973 Train_dice: 0.9027\n",
            "129/326, Train_loss: 0.2242 Train_dice: 0.7758\n",
            "130/326, Train_loss: 0.1209 Train_dice: 0.8791\n",
            "131/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "132/326, Train_loss: 0.1185 Train_dice: 0.8815\n",
            "133/326, Train_loss: 0.0867 Train_dice: 0.9133\n",
            "134/326, Train_loss: 0.2225 Train_dice: 0.7775\n",
            "135/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "136/326, Train_loss: 0.1260 Train_dice: 0.8740\n",
            "137/326, Train_loss: 0.0848 Train_dice: 0.9152\n",
            "138/326, Train_loss: 0.0515 Train_dice: 0.9485\n",
            "139/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "140/326, Train_loss: 0.0890 Train_dice: 0.9110\n",
            "141/326, Train_loss: 0.0442 Train_dice: 0.9558\n",
            "142/326, Train_loss: 0.1254 Train_dice: 0.8746\n",
            "143/326, Train_loss: 0.0300 Train_dice: 0.9700\n",
            "144/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "145/326, Train_loss: 0.1706 Train_dice: 0.8294\n",
            "146/326, Train_loss: 0.0746 Train_dice: 0.9254\n",
            "147/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "148/326, Train_loss: 0.1109 Train_dice: 0.8891\n",
            "149/326, Train_loss: 0.0637 Train_dice: 0.9363\n",
            "150/326, Train_loss: 0.1224 Train_dice: 0.8776\n",
            "151/326, Train_loss: 0.0836 Train_dice: 0.9164\n",
            "152/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "153/326, Train_loss: 0.1465 Train_dice: 0.8535\n",
            "154/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "155/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "156/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "157/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "158/326, Train_loss: 0.1782 Train_dice: 0.8218\n",
            "159/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "160/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "161/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "162/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "163/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "164/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "165/326, Train_loss: 0.1231 Train_dice: 0.8769\n",
            "166/326, Train_loss: 0.1262 Train_dice: 0.8738\n",
            "167/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "168/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "169/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "170/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "171/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "172/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "173/326, Train_loss: 0.0080 Train_dice: 0.9920\n",
            "174/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "175/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "176/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "177/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "178/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "179/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "180/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "181/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "182/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "183/326, Train_loss: 0.0748 Train_dice: 0.9252\n",
            "184/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "185/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "186/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "187/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "188/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "189/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "190/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "191/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "192/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "193/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "194/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "195/326, Train_loss: 0.0791 Train_dice: 0.9209\n",
            "196/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "197/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "198/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "199/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "200/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "201/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "202/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "203/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "204/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "205/326, Train_loss: 0.1096 Train_dice: 0.8904\n",
            "206/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "207/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "208/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "209/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "210/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "211/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "212/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "213/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "214/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "215/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "216/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "217/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "218/326, Train_loss: 0.0439 Train_dice: 0.9561\n",
            "219/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "220/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "221/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "222/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "223/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "224/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "225/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "226/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "227/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "228/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "229/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "230/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "231/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "232/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "233/326, Train_loss: 0.1438 Train_dice: 0.8562\n",
            "234/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "235/326, Train_loss: 0.1199 Train_dice: 0.8801\n",
            "236/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "237/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "238/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "239/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "240/326, Train_loss: 0.0946 Train_dice: 0.9054\n",
            "241/326, Train_loss: 0.0904 Train_dice: 0.9096\n",
            "242/326, Train_loss: 0.0907 Train_dice: 0.9093\n",
            "243/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "244/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "245/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "246/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "247/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "248/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "249/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "250/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "251/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "252/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "253/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "254/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "255/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "256/326, Train_loss: 0.0998 Train_dice: 0.9002\n",
            "257/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "258/326, Train_loss: 0.1756 Train_dice: 0.8244\n",
            "259/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "260/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "261/326, Train_loss: 0.1215 Train_dice: 0.8785\n",
            "262/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "263/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "264/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "265/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "266/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "267/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "268/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "269/326, Train_loss: 0.0606 Train_dice: 0.9394\n",
            "270/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "271/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "272/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "273/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "274/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "275/326, Train_loss: 0.1214 Train_dice: 0.8786\n",
            "276/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "277/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "278/326, Train_loss: 0.0784 Train_dice: 0.9216\n",
            "279/326, Train_loss: 0.1328 Train_dice: 0.8672\n",
            "280/326, Train_loss: 0.0659 Train_dice: 0.9341\n",
            "281/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "282/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "283/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "284/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "285/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "286/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "287/326, Train_loss: 0.0647 Train_dice: 0.9353\n",
            "288/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "289/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "290/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "291/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "292/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "293/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "294/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "295/326, Train_loss: 0.0865 Train_dice: 0.9135\n",
            "296/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "297/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "298/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "299/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "300/326, Train_loss: 0.0730 Train_dice: 0.9270\n",
            "301/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "302/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "303/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "304/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "305/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "306/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "307/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "308/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "309/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "310/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "311/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "312/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "313/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "314/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "315/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "316/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "317/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "318/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "319/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "320/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "321/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "322/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "323/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "324/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "325/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "326/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "--------------------\n",
            "Epoch_loss: 0.0512\n",
            "Epoch_metric: 0.9488\n",
            "----------\n",
            "epoch 144/250\n",
            "1/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "2/326, Train_loss: 0.1362 Train_dice: 0.8638\n",
            "3/326, Train_loss: 0.1609 Train_dice: 0.8391\n",
            "4/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "5/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "6/326, Train_loss: 0.1050 Train_dice: 0.8950\n",
            "7/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "8/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "9/326, Train_loss: 0.0544 Train_dice: 0.9456\n",
            "10/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "11/326, Train_loss: 0.1219 Train_dice: 0.8781\n",
            "12/326, Train_loss: 0.1340 Train_dice: 0.8660\n",
            "13/326, Train_loss: 0.0733 Train_dice: 0.9267\n",
            "14/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "15/326, Train_loss: 0.1778 Train_dice: 0.8222\n",
            "16/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "17/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "18/326, Train_loss: 0.1342 Train_dice: 0.8658\n",
            "19/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "20/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "21/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "22/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "23/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "24/326, Train_loss: 0.1110 Train_dice: 0.8890\n",
            "25/326, Train_loss: 0.0685 Train_dice: 0.9315\n",
            "26/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "27/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "28/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "29/326, Train_loss: 0.0664 Train_dice: 0.9336\n",
            "30/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "31/326, Train_loss: 0.1573 Train_dice: 0.8427\n",
            "32/326, Train_loss: 0.0944 Train_dice: 0.9056\n",
            "33/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "34/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "35/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "36/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "37/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "38/326, Train_loss: 0.1068 Train_dice: 0.8932\n",
            "39/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "40/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "41/326, Train_loss: 0.0544 Train_dice: 0.9456\n",
            "42/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "43/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "44/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "45/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "46/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "47/326, Train_loss: 0.1492 Train_dice: 0.8508\n",
            "48/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "49/326, Train_loss: 0.0705 Train_dice: 0.9295\n",
            "50/326, Train_loss: 0.0841 Train_dice: 0.9159\n",
            "51/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "52/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "53/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "54/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "55/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "56/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "57/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "58/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "59/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "60/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "61/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "62/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "63/326, Train_loss: 0.0913 Train_dice: 0.9087\n",
            "64/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "65/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "66/326, Train_loss: 0.0801 Train_dice: 0.9199\n",
            "67/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "68/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "69/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "70/326, Train_loss: 0.1727 Train_dice: 0.8273\n",
            "71/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "72/326, Train_loss: 0.1207 Train_dice: 0.8793\n",
            "73/326, Train_loss: 0.0491 Train_dice: 0.9509\n",
            "74/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "75/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "76/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "77/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "78/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "79/326, Train_loss: 0.1174 Train_dice: 0.8826\n",
            "80/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "81/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "82/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "83/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "84/326, Train_loss: 0.1719 Train_dice: 0.8281\n",
            "85/326, Train_loss: 0.0654 Train_dice: 0.9346\n",
            "86/326, Train_loss: 0.0314 Train_dice: 0.9686\n",
            "87/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "88/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "89/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "90/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "91/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "92/326, Train_loss: 0.0595 Train_dice: 0.9405\n",
            "93/326, Train_loss: 0.1277 Train_dice: 0.8723\n",
            "94/326, Train_loss: 0.0832 Train_dice: 0.9168\n",
            "95/326, Train_loss: 0.1789 Train_dice: 0.8211\n",
            "96/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "97/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "98/326, Train_loss: 0.1161 Train_dice: 0.8839\n",
            "99/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "100/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "101/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "102/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "103/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "104/326, Train_loss: 0.0631 Train_dice: 0.9369\n",
            "105/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "106/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "107/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "108/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "109/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "110/326, Train_loss: 0.1196 Train_dice: 0.8804\n",
            "111/326, Train_loss: 0.0392 Train_dice: 0.9608\n",
            "112/326, Train_loss: 0.1366 Train_dice: 0.8634\n",
            "113/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "114/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "115/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "116/326, Train_loss: 0.1801 Train_dice: 0.8199\n",
            "117/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "118/326, Train_loss: 0.1480 Train_dice: 0.8520\n",
            "119/326, Train_loss: 0.0770 Train_dice: 0.9230\n",
            "120/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "121/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "122/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "123/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "124/326, Train_loss: 0.0870 Train_dice: 0.9130\n",
            "125/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "126/326, Train_loss: 0.1215 Train_dice: 0.8785\n",
            "127/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "128/326, Train_loss: 0.0940 Train_dice: 0.9060\n",
            "129/326, Train_loss: 0.2166 Train_dice: 0.7834\n",
            "130/326, Train_loss: 0.1163 Train_dice: 0.8837\n",
            "131/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "132/326, Train_loss: 0.1131 Train_dice: 0.8869\n",
            "133/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "134/326, Train_loss: 0.2160 Train_dice: 0.7840\n",
            "135/326, Train_loss: 0.0845 Train_dice: 0.9155\n",
            "136/326, Train_loss: 0.1207 Train_dice: 0.8793\n",
            "137/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "138/326, Train_loss: 0.0491 Train_dice: 0.9509\n",
            "139/326, Train_loss: 0.0220 Train_dice: 0.9780\n",
            "140/326, Train_loss: 0.0853 Train_dice: 0.9147\n",
            "141/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "142/326, Train_loss: 0.1213 Train_dice: 0.8787\n",
            "143/326, Train_loss: 0.0286 Train_dice: 0.9714\n",
            "144/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "145/326, Train_loss: 0.1650 Train_dice: 0.8350\n",
            "146/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "147/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "148/326, Train_loss: 0.1069 Train_dice: 0.8931\n",
            "149/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "150/326, Train_loss: 0.1175 Train_dice: 0.8825\n",
            "151/326, Train_loss: 0.0803 Train_dice: 0.9197\n",
            "152/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "153/326, Train_loss: 0.1407 Train_dice: 0.8593\n",
            "154/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "155/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "156/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "157/326, Train_loss: 0.0257 Train_dice: 0.9743\n",
            "158/326, Train_loss: 0.1695 Train_dice: 0.8305\n",
            "159/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "160/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "161/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "162/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "163/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "164/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "165/326, Train_loss: 0.1202 Train_dice: 0.8798\n",
            "166/326, Train_loss: 0.1213 Train_dice: 0.8787\n",
            "167/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "168/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "169/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "170/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "171/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "172/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "173/326, Train_loss: 0.0076 Train_dice: 0.9924\n",
            "174/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "175/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "176/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "177/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "178/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "179/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "180/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "181/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "182/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "183/326, Train_loss: 0.0722 Train_dice: 0.9278\n",
            "184/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "185/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "186/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "187/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "188/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "189/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "190/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "191/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "192/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "193/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "194/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "195/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "196/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "197/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "198/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "199/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "200/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "201/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "202/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "203/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "204/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "205/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "206/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "207/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "208/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "209/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "210/326, Train_loss: 0.1054 Train_dice: 0.8946\n",
            "211/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "212/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "213/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "214/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "215/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "216/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "217/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "218/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "219/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "220/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "221/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "222/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "223/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "224/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "225/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "226/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "227/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "228/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "229/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "230/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "231/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "232/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "233/326, Train_loss: 0.1385 Train_dice: 0.8615\n",
            "234/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "235/326, Train_loss: 0.1146 Train_dice: 0.8854\n",
            "236/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "237/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "238/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "239/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "240/326, Train_loss: 0.0900 Train_dice: 0.9100\n",
            "241/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "242/326, Train_loss: 0.0857 Train_dice: 0.9143\n",
            "243/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "244/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "245/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "246/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "247/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "248/326, Train_loss: 0.0626 Train_dice: 0.9374\n",
            "249/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "250/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "251/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "252/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "253/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "254/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "255/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "256/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "257/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "258/326, Train_loss: 0.1694 Train_dice: 0.8306\n",
            "259/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "260/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "261/326, Train_loss: 0.1139 Train_dice: 0.8861\n",
            "262/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "263/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "264/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "265/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "266/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "267/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "268/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "269/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "270/326, Train_loss: 0.0638 Train_dice: 0.9362\n",
            "271/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "272/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "273/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "274/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "275/326, Train_loss: 0.1117 Train_dice: 0.8883\n",
            "276/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "277/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "278/326, Train_loss: 0.0735 Train_dice: 0.9265\n",
            "279/326, Train_loss: 0.1243 Train_dice: 0.8757\n",
            "280/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "281/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "282/326, Train_loss: 0.0681 Train_dice: 0.9319\n",
            "283/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "284/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "285/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "286/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "287/326, Train_loss: 0.0623 Train_dice: 0.9377\n",
            "288/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "289/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "290/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "291/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "292/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "293/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "294/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "295/326, Train_loss: 0.0825 Train_dice: 0.9175\n",
            "296/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "297/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "298/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "299/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "300/326, Train_loss: 0.0714 Train_dice: 0.9286\n",
            "301/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "302/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "303/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "304/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "305/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "306/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "307/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "308/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "309/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "310/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "311/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "312/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "313/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "314/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "315/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "316/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "317/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "318/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "319/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "320/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "321/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "322/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "323/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "324/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "325/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "326/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "--------------------\n",
            "Epoch_loss: 0.0490\n",
            "Epoch_metric: 0.9510\n",
            "----------\n",
            "epoch 145/250\n",
            "1/326, Train_loss: 0.0879 Train_dice: 0.9121\n",
            "2/326, Train_loss: 0.1269 Train_dice: 0.8731\n",
            "3/326, Train_loss: 0.1505 Train_dice: 0.8495\n",
            "4/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "5/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "6/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "7/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "8/326, Train_loss: 0.0332 Train_dice: 0.9668\n",
            "9/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "10/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "11/326, Train_loss: 0.1171 Train_dice: 0.8829\n",
            "12/326, Train_loss: 0.1283 Train_dice: 0.8717\n",
            "13/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "14/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "15/326, Train_loss: 0.1707 Train_dice: 0.8293\n",
            "16/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "17/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "18/326, Train_loss: 0.1282 Train_dice: 0.8718\n",
            "19/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "20/326, Train_loss: 0.0931 Train_dice: 0.9069\n",
            "21/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "22/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "23/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "24/326, Train_loss: 0.1073 Train_dice: 0.8927\n",
            "25/326, Train_loss: 0.0659 Train_dice: 0.9341\n",
            "26/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "27/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "28/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "29/326, Train_loss: 0.0637 Train_dice: 0.9363\n",
            "30/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "31/326, Train_loss: 0.1515 Train_dice: 0.8485\n",
            "32/326, Train_loss: 0.0915 Train_dice: 0.9085\n",
            "33/326, Train_loss: 0.0313 Train_dice: 0.9687\n",
            "34/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "35/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "36/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "37/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "38/326, Train_loss: 0.1027 Train_dice: 0.8973\n",
            "39/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "40/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "41/326, Train_loss: 0.0522 Train_dice: 0.9478\n",
            "42/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "43/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "44/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "45/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "46/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "47/326, Train_loss: 0.1438 Train_dice: 0.8562\n",
            "48/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "49/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "50/326, Train_loss: 0.0806 Train_dice: 0.9194\n",
            "51/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "52/326, Train_loss: 0.0921 Train_dice: 0.9079\n",
            "53/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "54/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "55/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "56/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "57/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "58/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "59/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "60/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "61/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "62/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "63/326, Train_loss: 0.0873 Train_dice: 0.9127\n",
            "64/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "65/326, Train_loss: 0.0193 Train_dice: 0.9807\n",
            "66/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "67/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "68/326, Train_loss: 0.0729 Train_dice: 0.9271\n",
            "69/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "70/326, Train_loss: 0.1665 Train_dice: 0.8335\n",
            "71/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "72/326, Train_loss: 0.1155 Train_dice: 0.8845\n",
            "73/326, Train_loss: 0.0471 Train_dice: 0.9529\n",
            "74/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "75/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "76/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "77/326, Train_loss: 0.1079 Train_dice: 0.8921\n",
            "78/326, Train_loss: 0.0782 Train_dice: 0.9218\n",
            "79/326, Train_loss: 0.1125 Train_dice: 0.8875\n",
            "80/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "81/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "82/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "83/326, Train_loss: 0.0777 Train_dice: 0.9223\n",
            "84/326, Train_loss: 0.1647 Train_dice: 0.8353\n",
            "85/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "86/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "87/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "88/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "89/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "90/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "91/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "92/326, Train_loss: 0.0568 Train_dice: 0.9432\n",
            "93/326, Train_loss: 0.1227 Train_dice: 0.8773\n",
            "94/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "95/326, Train_loss: 0.1715 Train_dice: 0.8285\n",
            "96/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "97/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "98/326, Train_loss: 0.1117 Train_dice: 0.8883\n",
            "99/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "100/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "101/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "102/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "103/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "104/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "105/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "106/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "107/326, Train_loss: 0.0598 Train_dice: 0.9402\n",
            "108/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "109/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "110/326, Train_loss: 0.1155 Train_dice: 0.8845\n",
            "111/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "112/326, Train_loss: 0.1315 Train_dice: 0.8685\n",
            "113/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "114/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "115/326, Train_loss: 0.0853 Train_dice: 0.9147\n",
            "116/326, Train_loss: 0.1734 Train_dice: 0.8266\n",
            "117/326, Train_loss: 0.0523 Train_dice: 0.9477\n",
            "118/326, Train_loss: 0.1424 Train_dice: 0.8576\n",
            "119/326, Train_loss: 0.0745 Train_dice: 0.9255\n",
            "120/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "121/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "122/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "123/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "124/326, Train_loss: 0.0843 Train_dice: 0.9157\n",
            "125/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "126/326, Train_loss: 0.1163 Train_dice: 0.8837\n",
            "127/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "128/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "129/326, Train_loss: 0.2093 Train_dice: 0.7907\n",
            "130/326, Train_loss: 0.1132 Train_dice: 0.8868\n",
            "131/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "132/326, Train_loss: 0.1086 Train_dice: 0.8914\n",
            "133/326, Train_loss: 0.0800 Train_dice: 0.9200\n",
            "134/326, Train_loss: 0.2082 Train_dice: 0.7918\n",
            "135/326, Train_loss: 0.0810 Train_dice: 0.9190\n",
            "136/326, Train_loss: 0.1159 Train_dice: 0.8841\n",
            "137/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "138/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "139/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "140/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "141/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "142/326, Train_loss: 0.1163 Train_dice: 0.8837\n",
            "143/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "144/326, Train_loss: 0.0670 Train_dice: 0.9330\n",
            "145/326, Train_loss: 0.1594 Train_dice: 0.8406\n",
            "146/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "147/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "148/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "149/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "150/326, Train_loss: 0.1149 Train_dice: 0.8851\n",
            "151/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "152/326, Train_loss: 0.0302 Train_dice: 0.9698\n",
            "153/326, Train_loss: 0.1361 Train_dice: 0.8639\n",
            "154/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "155/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "156/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "157/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "158/326, Train_loss: 0.1642 Train_dice: 0.8358\n",
            "159/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "160/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "161/326, Train_loss: 0.0786 Train_dice: 0.9214\n",
            "162/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "163/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "164/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "165/326, Train_loss: 0.1145 Train_dice: 0.8855\n",
            "166/326, Train_loss: 0.1164 Train_dice: 0.8836\n",
            "167/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "168/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "169/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "170/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "171/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "172/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "173/326, Train_loss: 0.0075 Train_dice: 0.9925\n",
            "174/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "175/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "176/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "177/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "178/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "179/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "180/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "181/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "182/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "183/326, Train_loss: 0.0683 Train_dice: 0.9317\n",
            "184/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "185/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "186/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "187/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "188/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "189/326, Train_loss: 0.0085 Train_dice: 0.9915\n",
            "190/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "191/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "192/326, Train_loss: 0.0483 Train_dice: 0.9517\n",
            "193/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "194/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "195/326, Train_loss: 0.0731 Train_dice: 0.9269\n",
            "196/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "197/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "198/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "199/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "200/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "201/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "202/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "203/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "204/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "205/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "206/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "207/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "208/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "209/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "210/326, Train_loss: 0.1031 Train_dice: 0.8969\n",
            "211/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "212/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "213/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "214/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "215/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "216/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "217/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "218/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "219/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "220/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "221/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "222/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "223/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "224/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "225/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "226/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "227/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "228/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "229/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "230/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "231/326, Train_loss: 0.0588 Train_dice: 0.9412\n",
            "232/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "233/326, Train_loss: 0.1314 Train_dice: 0.8686\n",
            "234/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "235/326, Train_loss: 0.1104 Train_dice: 0.8896\n",
            "236/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "237/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "238/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "239/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "240/326, Train_loss: 0.0865 Train_dice: 0.9135\n",
            "241/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "242/326, Train_loss: 0.0829 Train_dice: 0.9171\n",
            "243/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "244/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "245/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "246/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "247/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "248/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "249/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "250/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "251/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "252/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "253/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "254/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "255/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "256/326, Train_loss: 0.0859 Train_dice: 0.9141\n",
            "257/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "258/326, Train_loss: 0.1610 Train_dice: 0.8390\n",
            "259/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "260/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "261/326, Train_loss: 0.1110 Train_dice: 0.8890\n",
            "262/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "263/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "264/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "265/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "266/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "267/326, Train_loss: 0.0515 Train_dice: 0.9485\n",
            "268/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "269/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "270/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "271/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "272/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "273/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "274/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "275/326, Train_loss: 0.1140 Train_dice: 0.8860\n",
            "276/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "277/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "278/326, Train_loss: 0.0715 Train_dice: 0.9285\n",
            "279/326, Train_loss: 0.1197 Train_dice: 0.8803\n",
            "280/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "281/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "282/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "283/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "284/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "285/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "286/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "287/326, Train_loss: 0.0585 Train_dice: 0.9415\n",
            "288/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "289/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "290/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "291/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "292/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "293/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "294/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "295/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "296/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "297/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "298/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "299/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "300/326, Train_loss: 0.0664 Train_dice: 0.9336\n",
            "301/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "302/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "303/326, Train_loss: 0.0825 Train_dice: 0.9175\n",
            "304/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "305/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "306/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "307/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "308/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "309/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "310/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "311/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "312/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "313/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "314/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "315/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "316/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "317/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "318/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "319/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "320/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "321/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "322/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "323/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "324/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "325/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "326/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "--------------------\n",
            "Epoch_loss: 0.0469\n",
            "Epoch_metric: 0.9531\n",
            "----------\n",
            "epoch 146/250\n",
            "1/326, Train_loss: 0.0866 Train_dice: 0.9134\n",
            "2/326, Train_loss: 0.1254 Train_dice: 0.8746\n",
            "3/326, Train_loss: 0.1458 Train_dice: 0.8542\n",
            "4/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "5/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "6/326, Train_loss: 0.0963 Train_dice: 0.9037\n",
            "7/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "8/326, Train_loss: 0.0332 Train_dice: 0.9668\n",
            "9/326, Train_loss: 0.0510 Train_dice: 0.9490\n",
            "10/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "11/326, Train_loss: 0.1164 Train_dice: 0.8836\n",
            "12/326, Train_loss: 0.1240 Train_dice: 0.8760\n",
            "13/326, Train_loss: 0.0671 Train_dice: 0.9329\n",
            "14/326, Train_loss: 0.0286 Train_dice: 0.9714\n",
            "15/326, Train_loss: 0.1649 Train_dice: 0.8351\n",
            "16/326, Train_loss: 0.0513 Train_dice: 0.9487\n",
            "17/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "18/326, Train_loss: 0.1250 Train_dice: 0.8750\n",
            "19/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "20/326, Train_loss: 0.0910 Train_dice: 0.9090\n",
            "21/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "22/326, Train_loss: 0.0495 Train_dice: 0.9505\n",
            "23/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "24/326, Train_loss: 0.1038 Train_dice: 0.8962\n",
            "25/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "26/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "27/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "28/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "29/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "30/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "31/326, Train_loss: 0.1467 Train_dice: 0.8533\n",
            "32/326, Train_loss: 0.0878 Train_dice: 0.9122\n",
            "33/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "34/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "35/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "36/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "37/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "38/326, Train_loss: 0.0992 Train_dice: 0.9008\n",
            "39/326, Train_loss: 0.0701 Train_dice: 0.9299\n",
            "40/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "41/326, Train_loss: 0.0501 Train_dice: 0.9499\n",
            "42/326, Train_loss: 0.0409 Train_dice: 0.9591\n",
            "43/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "44/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "45/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "46/326, Train_loss: 0.0205 Train_dice: 0.9795\n",
            "47/326, Train_loss: 0.1385 Train_dice: 0.8615\n",
            "48/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "49/326, Train_loss: 0.0647 Train_dice: 0.9353\n",
            "50/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "51/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "52/326, Train_loss: 0.0884 Train_dice: 0.9116\n",
            "53/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "54/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "55/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "56/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "57/326, Train_loss: 0.0313 Train_dice: 0.9687\n",
            "58/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "59/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "60/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "61/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "62/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "63/326, Train_loss: 0.0840 Train_dice: 0.9160\n",
            "64/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "65/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "66/326, Train_loss: 0.0739 Train_dice: 0.9261\n",
            "67/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "68/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "69/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "70/326, Train_loss: 0.1606 Train_dice: 0.8394\n",
            "71/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "72/326, Train_loss: 0.1110 Train_dice: 0.8890\n",
            "73/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "74/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "75/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "76/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "77/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "78/326, Train_loss: 0.0753 Train_dice: 0.9247\n",
            "79/326, Train_loss: 0.1083 Train_dice: 0.8917\n",
            "80/326, Train_loss: 0.0332 Train_dice: 0.9668\n",
            "81/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "82/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "83/326, Train_loss: 0.0748 Train_dice: 0.9252\n",
            "84/326, Train_loss: 0.1568 Train_dice: 0.8432\n",
            "85/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "86/326, Train_loss: 0.0286 Train_dice: 0.9714\n",
            "87/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "88/326, Train_loss: 0.0747 Train_dice: 0.9253\n",
            "89/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "90/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "91/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "92/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "93/326, Train_loss: 0.1179 Train_dice: 0.8821\n",
            "94/326, Train_loss: 0.0755 Train_dice: 0.9245\n",
            "95/326, Train_loss: 0.1655 Train_dice: 0.8345\n",
            "96/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "97/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "98/326, Train_loss: 0.1070 Train_dice: 0.8930\n",
            "99/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "100/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "101/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "102/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "103/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "104/326, Train_loss: 0.0586 Train_dice: 0.9414\n",
            "105/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "106/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "107/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "108/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "109/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "110/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "111/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "112/326, Train_loss: 0.1269 Train_dice: 0.8731\n",
            "113/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "114/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "115/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "116/326, Train_loss: 0.1674 Train_dice: 0.8326\n",
            "117/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "118/326, Train_loss: 0.1370 Train_dice: 0.8630\n",
            "119/326, Train_loss: 0.0707 Train_dice: 0.9293\n",
            "120/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "121/326, Train_loss: 0.0257 Train_dice: 0.9743\n",
            "122/326, Train_loss: 0.0313 Train_dice: 0.9687\n",
            "123/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "124/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "125/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "126/326, Train_loss: 0.1124 Train_dice: 0.8876\n",
            "127/326, Train_loss: 0.0503 Train_dice: 0.9497\n",
            "128/326, Train_loss: 0.0879 Train_dice: 0.9121\n",
            "129/326, Train_loss: 0.2041 Train_dice: 0.7959\n",
            "130/326, Train_loss: 0.1078 Train_dice: 0.8922\n",
            "131/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "132/326, Train_loss: 0.1048 Train_dice: 0.8952\n",
            "133/326, Train_loss: 0.0771 Train_dice: 0.9229\n",
            "134/326, Train_loss: 0.2018 Train_dice: 0.7982\n",
            "135/326, Train_loss: 0.0779 Train_dice: 0.9221\n",
            "136/326, Train_loss: 0.1113 Train_dice: 0.8887\n",
            "137/326, Train_loss: 0.0753 Train_dice: 0.9247\n",
            "138/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "139/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "140/326, Train_loss: 0.0781 Train_dice: 0.9219\n",
            "141/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "142/326, Train_loss: 0.1110 Train_dice: 0.8890\n",
            "143/326, Train_loss: 0.0266 Train_dice: 0.9734\n",
            "144/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "145/326, Train_loss: 0.1530 Train_dice: 0.8470\n",
            "146/326, Train_loss: 0.0668 Train_dice: 0.9332\n",
            "147/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "148/326, Train_loss: 0.0998 Train_dice: 0.9002\n",
            "149/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "150/326, Train_loss: 0.1115 Train_dice: 0.8885\n",
            "151/326, Train_loss: 0.0757 Train_dice: 0.9243\n",
            "152/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "153/326, Train_loss: 0.1323 Train_dice: 0.8677\n",
            "154/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "155/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "156/326, Train_loss: 0.0630 Train_dice: 0.9370\n",
            "157/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "158/326, Train_loss: 0.1606 Train_dice: 0.8394\n",
            "159/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "160/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "161/326, Train_loss: 0.0755 Train_dice: 0.9245\n",
            "162/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "163/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "164/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "165/326, Train_loss: 0.1081 Train_dice: 0.8919\n",
            "166/326, Train_loss: 0.1115 Train_dice: 0.8885\n",
            "167/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "168/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "169/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "170/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "171/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "172/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "173/326, Train_loss: 0.0073 Train_dice: 0.9927\n",
            "174/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "175/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "176/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "177/326, Train_loss: 0.0087 Train_dice: 0.9913\n",
            "178/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "179/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "180/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "181/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "182/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "183/326, Train_loss: 0.0689 Train_dice: 0.9311\n",
            "184/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "185/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "186/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "187/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "188/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "189/326, Train_loss: 0.0087 Train_dice: 0.9913\n",
            "190/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "191/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "192/326, Train_loss: 0.0479 Train_dice: 0.9521\n",
            "193/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "194/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "195/326, Train_loss: 0.0701 Train_dice: 0.9299\n",
            "196/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "197/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "198/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "199/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "200/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "201/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "202/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "203/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "204/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "205/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "206/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "207/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "208/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "209/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "210/326, Train_loss: 0.1003 Train_dice: 0.8997\n",
            "211/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "212/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "213/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "214/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "215/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "216/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "217/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "218/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "219/326, Train_loss: 0.0444 Train_dice: 0.9556\n",
            "220/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "221/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "222/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "223/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "224/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "225/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "226/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "227/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "228/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "229/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "230/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "231/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "232/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "233/326, Train_loss: 0.1275 Train_dice: 0.8725\n",
            "234/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "235/326, Train_loss: 0.1064 Train_dice: 0.8936\n",
            "236/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "237/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "238/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "239/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "240/326, Train_loss: 0.0845 Train_dice: 0.9155\n",
            "241/326, Train_loss: 0.0817 Train_dice: 0.9183\n",
            "242/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "243/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "244/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "245/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "246/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "247/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "248/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "249/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "250/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "251/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "252/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "253/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "254/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "255/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "256/326, Train_loss: 0.0850 Train_dice: 0.9150\n",
            "257/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "258/326, Train_loss: 0.1540 Train_dice: 0.8460\n",
            "259/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "260/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "261/326, Train_loss: 0.1046 Train_dice: 0.8954\n",
            "262/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "263/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "264/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "265/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "266/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "267/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "268/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "269/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "270/326, Train_loss: 0.0592 Train_dice: 0.9408\n",
            "271/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "272/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "273/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "274/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "275/326, Train_loss: 0.1064 Train_dice: 0.8936\n",
            "276/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "277/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "278/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "279/326, Train_loss: 0.1152 Train_dice: 0.8848\n",
            "280/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "281/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "282/326, Train_loss: 0.0644 Train_dice: 0.9356\n",
            "283/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "284/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "285/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "286/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "287/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "288/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "289/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "290/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "291/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "292/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "293/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "294/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "295/326, Train_loss: 0.0777 Train_dice: 0.9223\n",
            "296/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "297/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "298/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "299/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "300/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "301/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "302/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "303/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "304/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "305/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "306/326, Train_loss: 0.0076 Train_dice: 0.9924\n",
            "307/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "308/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "309/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "310/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "311/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "312/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "313/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "314/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "315/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "316/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "317/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "318/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "319/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "320/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "321/326, Train_loss: 0.0171 Train_dice: 0.9829\n",
            "322/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "323/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "324/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "325/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "326/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "--------------------\n",
            "Epoch_loss: 0.0453\n",
            "Epoch_metric: 0.9547\n",
            "----------\n",
            "epoch 147/250\n",
            "1/326, Train_loss: 0.0849 Train_dice: 0.9151\n",
            "2/326, Train_loss: 0.1198 Train_dice: 0.8802\n",
            "3/326, Train_loss: 0.1408 Train_dice: 0.8592\n",
            "4/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "5/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "6/326, Train_loss: 0.0926 Train_dice: 0.9074\n",
            "7/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "8/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "9/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "10/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "11/326, Train_loss: 0.1078 Train_dice: 0.8922\n",
            "12/326, Train_loss: 0.1191 Train_dice: 0.8809\n",
            "13/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "14/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "15/326, Train_loss: 0.1597 Train_dice: 0.8403\n",
            "16/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "17/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "18/326, Train_loss: 0.1209 Train_dice: 0.8791\n",
            "19/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "20/326, Train_loss: 0.0874 Train_dice: 0.9126\n",
            "21/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "22/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "23/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "24/326, Train_loss: 0.0999 Train_dice: 0.9001\n",
            "25/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "26/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "27/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "28/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "29/326, Train_loss: 0.0594 Train_dice: 0.9406\n",
            "30/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "31/326, Train_loss: 0.1435 Train_dice: 0.8565\n",
            "32/326, Train_loss: 0.0852 Train_dice: 0.9148\n",
            "33/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "34/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "35/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "36/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "37/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "38/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "39/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "40/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "41/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "42/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "43/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "44/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "45/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "46/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "47/326, Train_loss: 0.1335 Train_dice: 0.8665\n",
            "48/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "49/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "50/326, Train_loss: 0.0745 Train_dice: 0.9255\n",
            "51/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "52/326, Train_loss: 0.0853 Train_dice: 0.9147\n",
            "53/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "54/326, Train_loss: 0.0442 Train_dice: 0.9558\n",
            "55/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "56/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "57/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "58/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "59/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "60/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "61/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "62/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "63/326, Train_loss: 0.0810 Train_dice: 0.9190\n",
            "64/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "65/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "66/326, Train_loss: 0.0714 Train_dice: 0.9286\n",
            "67/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "68/326, Train_loss: 0.0669 Train_dice: 0.9331\n",
            "69/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "70/326, Train_loss: 0.1542 Train_dice: 0.8458\n",
            "71/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "72/326, Train_loss: 0.1072 Train_dice: 0.8928\n",
            "73/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "74/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "75/326, Train_loss: 0.0439 Train_dice: 0.9561\n",
            "76/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "77/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "78/326, Train_loss: 0.0726 Train_dice: 0.9274\n",
            "79/326, Train_loss: 0.1050 Train_dice: 0.8950\n",
            "80/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "81/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "82/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "83/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "84/326, Train_loss: 0.1496 Train_dice: 0.8504\n",
            "85/326, Train_loss: 0.0580 Train_dice: 0.9420\n",
            "86/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "87/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "88/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "89/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "90/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "91/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "92/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "93/326, Train_loss: 0.1141 Train_dice: 0.8859\n",
            "94/326, Train_loss: 0.0722 Train_dice: 0.9278\n",
            "95/326, Train_loss: 0.1598 Train_dice: 0.8402\n",
            "96/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "97/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "98/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "99/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "100/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "101/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "102/326, Train_loss: 0.0425 Train_dice: 0.9575\n",
            "103/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "104/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "105/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "106/326, Train_loss: 0.0515 Train_dice: 0.9485\n",
            "107/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "108/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "109/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "110/326, Train_loss: 0.1071 Train_dice: 0.8929\n",
            "111/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "112/326, Train_loss: 0.1227 Train_dice: 0.8773\n",
            "113/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "114/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "115/326, Train_loss: 0.0791 Train_dice: 0.9209\n",
            "116/326, Train_loss: 0.1611 Train_dice: 0.8389\n",
            "117/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "118/326, Train_loss: 0.1331 Train_dice: 0.8669\n",
            "119/326, Train_loss: 0.0679 Train_dice: 0.9321\n",
            "120/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "121/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "122/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "123/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "124/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "125/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "126/326, Train_loss: 0.1072 Train_dice: 0.8928\n",
            "127/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "128/326, Train_loss: 0.0834 Train_dice: 0.9166\n",
            "129/326, Train_loss: 0.1960 Train_dice: 0.8040\n",
            "130/326, Train_loss: 0.1038 Train_dice: 0.8962\n",
            "131/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "132/326, Train_loss: 0.1014 Train_dice: 0.8986\n",
            "133/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "134/326, Train_loss: 0.1980 Train_dice: 0.8020\n",
            "135/326, Train_loss: 0.0751 Train_dice: 0.9249\n",
            "136/326, Train_loss: 0.1065 Train_dice: 0.8935\n",
            "137/326, Train_loss: 0.0725 Train_dice: 0.9275\n",
            "138/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "139/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "140/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "141/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "142/326, Train_loss: 0.1075 Train_dice: 0.8925\n",
            "143/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "144/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "145/326, Train_loss: 0.1463 Train_dice: 0.8537\n",
            "146/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "147/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "148/326, Train_loss: 0.0976 Train_dice: 0.9024\n",
            "149/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "150/326, Train_loss: 0.1088 Train_dice: 0.8912\n",
            "151/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "152/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "153/326, Train_loss: 0.1286 Train_dice: 0.8714\n",
            "154/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "155/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "156/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "157/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "158/326, Train_loss: 0.1581 Train_dice: 0.8419\n",
            "159/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "160/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "161/326, Train_loss: 0.0755 Train_dice: 0.9245\n",
            "162/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "163/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "164/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "165/326, Train_loss: 0.1055 Train_dice: 0.8945\n",
            "166/326, Train_loss: 0.1083 Train_dice: 0.8917\n",
            "167/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "168/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "169/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "170/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "171/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "172/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "173/326, Train_loss: 0.0073 Train_dice: 0.9927\n",
            "174/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "175/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "176/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "177/326, Train_loss: 0.0088 Train_dice: 0.9912\n",
            "178/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "179/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "180/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "181/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "182/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "183/326, Train_loss: 0.0655 Train_dice: 0.9345\n",
            "184/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "185/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "186/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "187/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "188/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "189/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "190/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "191/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "192/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "193/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "194/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "195/326, Train_loss: 0.0695 Train_dice: 0.9305\n",
            "196/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "197/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "198/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "199/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "200/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "201/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "202/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "203/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "204/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "205/326, Train_loss: 0.0444 Train_dice: 0.9556\n",
            "206/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "207/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "208/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "209/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "210/326, Train_loss: 0.0924 Train_dice: 0.9076\n",
            "211/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "212/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "213/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "214/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "215/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "216/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "217/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "218/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "219/326, Train_loss: 0.0402 Train_dice: 0.9598\n",
            "220/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "221/326, Train_loss: 0.0088 Train_dice: 0.9912\n",
            "222/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "223/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "224/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "225/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "226/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "227/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "228/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "229/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "230/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "231/326, Train_loss: 0.0536 Train_dice: 0.9464\n",
            "232/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "233/326, Train_loss: 0.1247 Train_dice: 0.8753\n",
            "234/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "235/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "236/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "237/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "238/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "239/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "240/326, Train_loss: 0.0805 Train_dice: 0.9195\n",
            "241/326, Train_loss: 0.0774 Train_dice: 0.9226\n",
            "242/326, Train_loss: 0.0757 Train_dice: 0.9243\n",
            "243/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "244/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "245/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "246/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "247/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "248/326, Train_loss: 0.0563 Train_dice: 0.9437\n",
            "249/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "250/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "251/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "252/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "253/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "254/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "255/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "256/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "257/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "258/326, Train_loss: 0.1460 Train_dice: 0.8540\n",
            "259/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "260/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "261/326, Train_loss: 0.1031 Train_dice: 0.8969\n",
            "262/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "263/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "264/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "265/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "266/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "267/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "268/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "269/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "270/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "271/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "272/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "273/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "274/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "275/326, Train_loss: 0.1038 Train_dice: 0.8962\n",
            "276/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "277/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "278/326, Train_loss: 0.0695 Train_dice: 0.9305\n",
            "279/326, Train_loss: 0.1115 Train_dice: 0.8885\n",
            "280/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "281/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "282/326, Train_loss: 0.0634 Train_dice: 0.9366\n",
            "283/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "284/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "285/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "286/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "287/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "288/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "289/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "290/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "291/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "292/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "293/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "294/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "295/326, Train_loss: 0.0789 Train_dice: 0.9211\n",
            "296/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "297/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "298/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "299/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "300/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "301/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "302/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "303/326, Train_loss: 0.0783 Train_dice: 0.9217\n",
            "304/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "305/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "306/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "307/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "308/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "309/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "310/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "311/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "312/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "313/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "314/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "315/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "316/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "317/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "318/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "319/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "320/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "321/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "322/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "323/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "324/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "325/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "326/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "--------------------\n",
            "Epoch_loss: 0.0437\n",
            "Epoch_metric: 0.9563\n",
            "----------\n",
            "epoch 148/250\n",
            "1/326, Train_loss: 0.0837 Train_dice: 0.9163\n",
            "2/326, Train_loss: 0.1153 Train_dice: 0.8847\n",
            "3/326, Train_loss: 0.1373 Train_dice: 0.8627\n",
            "4/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "5/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "6/326, Train_loss: 0.0888 Train_dice: 0.9112\n",
            "7/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "8/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "9/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "10/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "11/326, Train_loss: 0.1059 Train_dice: 0.8941\n",
            "12/326, Train_loss: 0.1143 Train_dice: 0.8857\n",
            "13/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "14/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "15/326, Train_loss: 0.1529 Train_dice: 0.8471\n",
            "16/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "17/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "18/326, Train_loss: 0.1157 Train_dice: 0.8843\n",
            "19/326, Train_loss: 0.0485 Train_dice: 0.9515\n",
            "20/326, Train_loss: 0.0859 Train_dice: 0.9141\n",
            "21/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "22/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "23/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "24/326, Train_loss: 0.0990 Train_dice: 0.9010\n",
            "25/326, Train_loss: 0.0609 Train_dice: 0.9391\n",
            "26/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "27/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "28/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "29/326, Train_loss: 0.0568 Train_dice: 0.9432\n",
            "30/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "31/326, Train_loss: 0.1368 Train_dice: 0.8632\n",
            "32/326, Train_loss: 0.0824 Train_dice: 0.9176\n",
            "33/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "34/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "35/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "36/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "37/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "38/326, Train_loss: 0.0929 Train_dice: 0.9071\n",
            "39/326, Train_loss: 0.0669 Train_dice: 0.9331\n",
            "40/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "41/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "42/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "43/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "44/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "45/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "46/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "47/326, Train_loss: 0.1287 Train_dice: 0.8713\n",
            "48/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "49/326, Train_loss: 0.0597 Train_dice: 0.9403\n",
            "50/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "51/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "52/326, Train_loss: 0.0821 Train_dice: 0.9179\n",
            "53/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "54/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "55/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "56/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "57/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "58/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "59/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "60/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "61/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "62/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "63/326, Train_loss: 0.0799 Train_dice: 0.9201\n",
            "64/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "65/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "66/326, Train_loss: 0.0696 Train_dice: 0.9304\n",
            "67/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "68/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "69/326, Train_loss: 0.0314 Train_dice: 0.9686\n",
            "70/326, Train_loss: 0.1494 Train_dice: 0.8506\n",
            "71/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "72/326, Train_loss: 0.1036 Train_dice: 0.8964\n",
            "73/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "74/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "75/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "76/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "77/326, Train_loss: 0.0963 Train_dice: 0.9037\n",
            "78/326, Train_loss: 0.0705 Train_dice: 0.9295\n",
            "79/326, Train_loss: 0.1006 Train_dice: 0.8994\n",
            "80/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "81/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "82/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "83/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "84/326, Train_loss: 0.1446 Train_dice: 0.8554\n",
            "85/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "86/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "87/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "88/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "89/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "90/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "91/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "92/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "93/326, Train_loss: 0.1097 Train_dice: 0.8903\n",
            "94/326, Train_loss: 0.0695 Train_dice: 0.9305\n",
            "95/326, Train_loss: 0.1542 Train_dice: 0.8458\n",
            "96/326, Train_loss: 0.0471 Train_dice: 0.9529\n",
            "97/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "98/326, Train_loss: 0.0990 Train_dice: 0.9010\n",
            "99/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "100/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "101/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "102/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "103/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "104/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "105/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "106/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "107/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "108/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "109/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "110/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "111/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "112/326, Train_loss: 0.1177 Train_dice: 0.8823\n",
            "113/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "114/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "115/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "116/326, Train_loss: 0.1567 Train_dice: 0.8433\n",
            "117/326, Train_loss: 0.0466 Train_dice: 0.9534\n",
            "118/326, Train_loss: 0.1283 Train_dice: 0.8717\n",
            "119/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "120/326, Train_loss: 0.0367 Train_dice: 0.9633\n",
            "121/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "122/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "123/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "124/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "125/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "126/326, Train_loss: 0.1055 Train_dice: 0.8945\n",
            "127/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "128/326, Train_loss: 0.0801 Train_dice: 0.9199\n",
            "129/326, Train_loss: 0.1914 Train_dice: 0.8086\n",
            "130/326, Train_loss: 0.0993 Train_dice: 0.9007\n",
            "131/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "132/326, Train_loss: 0.0981 Train_dice: 0.9019\n",
            "133/326, Train_loss: 0.0715 Train_dice: 0.9285\n",
            "134/326, Train_loss: 0.1893 Train_dice: 0.8107\n",
            "135/326, Train_loss: 0.0733 Train_dice: 0.9267\n",
            "136/326, Train_loss: 0.1030 Train_dice: 0.8970\n",
            "137/326, Train_loss: 0.0723 Train_dice: 0.9277\n",
            "138/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "139/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "140/326, Train_loss: 0.0727 Train_dice: 0.9273\n",
            "141/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "142/326, Train_loss: 0.1032 Train_dice: 0.8968\n",
            "143/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "144/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "145/326, Train_loss: 0.1411 Train_dice: 0.8589\n",
            "146/326, Train_loss: 0.0610 Train_dice: 0.9390\n",
            "147/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "148/326, Train_loss: 0.0939 Train_dice: 0.9061\n",
            "149/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "150/326, Train_loss: 0.1041 Train_dice: 0.8959\n",
            "151/326, Train_loss: 0.0705 Train_dice: 0.9295\n",
            "152/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "153/326, Train_loss: 0.1219 Train_dice: 0.8781\n",
            "154/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "155/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "156/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "157/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "158/326, Train_loss: 0.1519 Train_dice: 0.8481\n",
            "159/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "160/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "161/326, Train_loss: 0.0753 Train_dice: 0.9247\n",
            "162/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "163/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "164/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "165/326, Train_loss: 0.1074 Train_dice: 0.8926\n",
            "166/326, Train_loss: 0.1081 Train_dice: 0.8919\n",
            "167/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "168/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "169/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "170/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "171/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "172/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "173/326, Train_loss: 0.0077 Train_dice: 0.9923\n",
            "174/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "175/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "176/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "177/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "178/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "179/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "180/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "181/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "182/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "183/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "184/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "185/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "186/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "187/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "188/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "189/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "190/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "191/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "192/326, Train_loss: 0.0437 Train_dice: 0.9563\n",
            "193/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "194/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "195/326, Train_loss: 0.0651 Train_dice: 0.9349\n",
            "196/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "197/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "198/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "199/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "200/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "201/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "202/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "203/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "204/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "205/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "206/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "207/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "208/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "209/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "210/326, Train_loss: 0.0930 Train_dice: 0.9070\n",
            "211/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "212/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "213/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "214/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "215/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "216/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "217/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "218/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "219/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "220/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "221/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "222/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "223/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "224/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "225/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "226/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "227/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "228/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "229/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "230/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "231/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "232/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "233/326, Train_loss: 0.1183 Train_dice: 0.8817\n",
            "234/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "235/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "236/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "237/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "238/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "239/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "240/326, Train_loss: 0.0784 Train_dice: 0.9216\n",
            "241/326, Train_loss: 0.0751 Train_dice: 0.9249\n",
            "242/326, Train_loss: 0.0729 Train_dice: 0.9271\n",
            "243/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "244/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "245/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "246/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "247/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "248/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "249/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "250/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "251/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "252/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "253/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "254/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "255/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "256/326, Train_loss: 0.0791 Train_dice: 0.9209\n",
            "257/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "258/326, Train_loss: 0.1398 Train_dice: 0.8602\n",
            "259/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "260/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "261/326, Train_loss: 0.0985 Train_dice: 0.9015\n",
            "262/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "263/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "264/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "265/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "266/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "267/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "268/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "269/326, Train_loss: 0.0513 Train_dice: 0.9487\n",
            "270/326, Train_loss: 0.0546 Train_dice: 0.9454\n",
            "271/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "272/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "273/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "274/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "275/326, Train_loss: 0.1001 Train_dice: 0.8999\n",
            "276/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "277/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "278/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "279/326, Train_loss: 0.1089 Train_dice: 0.8911\n",
            "280/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "281/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "282/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "283/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "284/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "285/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "286/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "287/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "288/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "289/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "290/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "291/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "292/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "293/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "294/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "295/326, Train_loss: 0.0739 Train_dice: 0.9261\n",
            "296/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "297/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "298/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "299/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "300/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "301/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "302/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "303/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "304/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "305/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "306/326, Train_loss: 0.0077 Train_dice: 0.9923\n",
            "307/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "308/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "309/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "310/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "311/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "312/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "313/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "314/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "315/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "316/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "317/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "318/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "319/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "320/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "321/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "322/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "323/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "324/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "325/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "326/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "--------------------\n",
            "Epoch_loss: 0.0425\n",
            "Epoch_metric: 0.9575\n",
            "----------\n",
            "epoch 149/250\n",
            "1/326, Train_loss: 0.0752 Train_dice: 0.9248\n",
            "2/326, Train_loss: 0.1101 Train_dice: 0.8899\n",
            "3/326, Train_loss: 0.1312 Train_dice: 0.8688\n",
            "4/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "5/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "6/326, Train_loss: 0.0854 Train_dice: 0.9146\n",
            "7/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "8/326, Train_loss: 0.0289 Train_dice: 0.9711\n",
            "9/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "10/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "11/326, Train_loss: 0.1014 Train_dice: 0.8986\n",
            "12/326, Train_loss: 0.1102 Train_dice: 0.8898\n",
            "13/326, Train_loss: 0.0595 Train_dice: 0.9405\n",
            "14/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "15/326, Train_loss: 0.1488 Train_dice: 0.8512\n",
            "16/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "17/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "18/326, Train_loss: 0.1113 Train_dice: 0.8887\n",
            "19/326, Train_loss: 0.0435 Train_dice: 0.9565\n",
            "20/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "21/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "22/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "23/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "24/326, Train_loss: 0.0935 Train_dice: 0.9065\n",
            "25/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "26/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "27/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "28/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "29/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "30/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "31/326, Train_loss: 0.1341 Train_dice: 0.8659\n",
            "32/326, Train_loss: 0.0807 Train_dice: 0.9193\n",
            "33/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "34/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "35/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "36/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "37/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "38/326, Train_loss: 0.0895 Train_dice: 0.9105\n",
            "39/326, Train_loss: 0.0647 Train_dice: 0.9353\n",
            "40/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "41/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "42/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "43/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "44/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "45/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "46/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "47/326, Train_loss: 0.1251 Train_dice: 0.8749\n",
            "48/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "49/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "50/326, Train_loss: 0.0692 Train_dice: 0.9308\n",
            "51/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "52/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "53/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "54/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "55/326, Train_loss: 0.0323 Train_dice: 0.9677\n",
            "56/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "57/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "58/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "59/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "60/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "61/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "62/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "63/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "64/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "65/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "66/326, Train_loss: 0.0676 Train_dice: 0.9324\n",
            "67/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "68/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "69/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "70/326, Train_loss: 0.1475 Train_dice: 0.8525\n",
            "71/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "72/326, Train_loss: 0.1005 Train_dice: 0.8995\n",
            "73/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "74/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "75/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "76/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "77/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "78/326, Train_loss: 0.0677 Train_dice: 0.9323\n",
            "79/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "80/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "81/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "82/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "83/326, Train_loss: 0.0669 Train_dice: 0.9331\n",
            "84/326, Train_loss: 0.1395 Train_dice: 0.8605\n",
            "85/326, Train_loss: 0.0546 Train_dice: 0.9454\n",
            "86/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "87/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "88/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "89/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "90/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "91/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "92/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "93/326, Train_loss: 0.1068 Train_dice: 0.8932\n",
            "94/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "95/326, Train_loss: 0.1501 Train_dice: 0.8499\n",
            "96/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "97/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "98/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "99/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "100/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "101/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "102/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "103/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "104/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "105/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "106/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "107/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "108/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "109/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "110/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "111/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "112/326, Train_loss: 0.1151 Train_dice: 0.8849\n",
            "113/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "114/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "115/326, Train_loss: 0.0744 Train_dice: 0.9256\n",
            "116/326, Train_loss: 0.1518 Train_dice: 0.8482\n",
            "117/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "118/326, Train_loss: 0.1240 Train_dice: 0.8760\n",
            "119/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "120/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "121/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "122/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "123/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "124/326, Train_loss: 0.0737 Train_dice: 0.9263\n",
            "125/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "126/326, Train_loss: 0.1013 Train_dice: 0.8987\n",
            "127/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "128/326, Train_loss: 0.0794 Train_dice: 0.9206\n",
            "129/326, Train_loss: 0.1861 Train_dice: 0.8139\n",
            "130/326, Train_loss: 0.0974 Train_dice: 0.9026\n",
            "131/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "132/326, Train_loss: 0.0941 Train_dice: 0.9059\n",
            "133/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "134/326, Train_loss: 0.1837 Train_dice: 0.8163\n",
            "135/326, Train_loss: 0.0702 Train_dice: 0.9298\n",
            "136/326, Train_loss: 0.0992 Train_dice: 0.9008\n",
            "137/326, Train_loss: 0.0709 Train_dice: 0.9291\n",
            "138/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "139/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "140/326, Train_loss: 0.0707 Train_dice: 0.9293\n",
            "141/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "142/326, Train_loss: 0.1028 Train_dice: 0.8972\n",
            "143/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "144/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "145/326, Train_loss: 0.1389 Train_dice: 0.8611\n",
            "146/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "147/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "148/326, Train_loss: 0.0898 Train_dice: 0.9102\n",
            "149/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "150/326, Train_loss: 0.1003 Train_dice: 0.8997\n",
            "151/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "152/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "153/326, Train_loss: 0.1186 Train_dice: 0.8814\n",
            "154/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "155/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "156/326, Train_loss: 0.0579 Train_dice: 0.9421\n",
            "157/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "158/326, Train_loss: 0.1450 Train_dice: 0.8550\n",
            "159/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "160/326, Train_loss: 0.0456 Train_dice: 0.9544\n",
            "161/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "162/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "163/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "164/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "165/326, Train_loss: 0.1015 Train_dice: 0.8985\n",
            "166/326, Train_loss: 0.1029 Train_dice: 0.8971\n",
            "167/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "168/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "169/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "170/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "171/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "172/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "173/326, Train_loss: 0.0073 Train_dice: 0.9927\n",
            "174/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "175/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "176/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "177/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "178/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "179/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "180/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "181/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "182/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "183/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "184/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "185/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "186/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "187/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "188/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "189/326, Train_loss: 0.0079 Train_dice: 0.9921\n",
            "190/326, Train_loss: 0.0513 Train_dice: 0.9487\n",
            "191/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "192/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "193/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "194/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "195/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "196/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "197/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "198/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "199/326, Train_loss: 0.0313 Train_dice: 0.9687\n",
            "200/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "201/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "202/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "203/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "204/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "205/326, Train_loss: 0.0388 Train_dice: 0.9612\n",
            "206/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "207/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "208/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "209/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "210/326, Train_loss: 0.0898 Train_dice: 0.9102\n",
            "211/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "212/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "213/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "214/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "215/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "216/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "217/326, Train_loss: 0.0439 Train_dice: 0.9561\n",
            "218/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "219/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "220/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "221/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "222/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "223/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "224/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "225/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "226/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "227/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "228/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "229/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "230/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "231/326, Train_loss: 0.0509 Train_dice: 0.9491\n",
            "232/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "233/326, Train_loss: 0.1170 Train_dice: 0.8830\n",
            "234/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "235/326, Train_loss: 0.0959 Train_dice: 0.9041\n",
            "236/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "237/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "238/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "239/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "240/326, Train_loss: 0.0749 Train_dice: 0.9251\n",
            "241/326, Train_loss: 0.0741 Train_dice: 0.9259\n",
            "242/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "243/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "244/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "245/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "246/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "247/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "248/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "249/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "250/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "251/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "252/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "253/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "254/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "255/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "256/326, Train_loss: 0.0742 Train_dice: 0.9258\n",
            "257/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "258/326, Train_loss: 0.1350 Train_dice: 0.8650\n",
            "259/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "260/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "261/326, Train_loss: 0.0939 Train_dice: 0.9061\n",
            "262/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "263/326, Train_loss: 0.0266 Train_dice: 0.9734\n",
            "264/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "265/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "266/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "267/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "268/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "269/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "270/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "271/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "272/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "273/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "274/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "275/326, Train_loss: 0.0974 Train_dice: 0.9026\n",
            "276/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "277/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "278/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "279/326, Train_loss: 0.1062 Train_dice: 0.8938\n",
            "280/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "281/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "282/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "283/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "284/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "285/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "286/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "287/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "288/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "289/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "290/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "291/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "292/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "293/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "294/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "295/326, Train_loss: 0.0700 Train_dice: 0.9300\n",
            "296/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "297/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "298/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "299/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "300/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "301/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "302/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "303/326, Train_loss: 0.0701 Train_dice: 0.9299\n",
            "304/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "305/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "306/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "307/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "308/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "309/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "310/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "311/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "312/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "313/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "314/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "315/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "316/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "317/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "318/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "319/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "320/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "321/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "322/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "323/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "324/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "325/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "326/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "--------------------\n",
            "Epoch_loss: 0.0411\n",
            "Epoch_metric: 0.9589\n",
            "----------\n",
            "epoch 150/250\n",
            "1/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "2/326, Train_loss: 0.1088 Train_dice: 0.8912\n",
            "3/326, Train_loss: 0.1290 Train_dice: 0.8710\n",
            "4/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "5/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "6/326, Train_loss: 0.0816 Train_dice: 0.9184\n",
            "7/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "8/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "9/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "10/326, Train_loss: 0.0298 Train_dice: 0.9702\n",
            "11/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "12/326, Train_loss: 0.1089 Train_dice: 0.8911\n",
            "13/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "14/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "15/326, Train_loss: 0.1431 Train_dice: 0.8569\n",
            "16/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "17/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "18/326, Train_loss: 0.1062 Train_dice: 0.8938\n",
            "19/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "20/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "21/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "22/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "23/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "24/326, Train_loss: 0.0887 Train_dice: 0.9113\n",
            "25/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "26/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "27/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "28/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "29/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "30/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "31/326, Train_loss: 0.1281 Train_dice: 0.8719\n",
            "32/326, Train_loss: 0.0759 Train_dice: 0.9241\n",
            "33/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "34/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "35/326, Train_loss: 0.0374 Train_dice: 0.9626\n",
            "36/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "37/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "38/326, Train_loss: 0.0862 Train_dice: 0.9138\n",
            "39/326, Train_loss: 0.0613 Train_dice: 0.9387\n",
            "40/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "41/326, Train_loss: 0.0446 Train_dice: 0.9554\n",
            "42/326, Train_loss: 0.0365 Train_dice: 0.9635\n",
            "43/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "44/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "45/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "46/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "47/326, Train_loss: 0.1208 Train_dice: 0.8792\n",
            "48/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "49/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "50/326, Train_loss: 0.0683 Train_dice: 0.9317\n",
            "51/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "52/326, Train_loss: 0.0778 Train_dice: 0.9222\n",
            "53/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "54/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "55/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "56/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "57/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "58/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "59/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "60/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "61/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "62/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "63/326, Train_loss: 0.0750 Train_dice: 0.9250\n",
            "64/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "65/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "66/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "67/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "68/326, Train_loss: 0.0616 Train_dice: 0.9384\n",
            "69/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "70/326, Train_loss: 0.1422 Train_dice: 0.8578\n",
            "71/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "72/326, Train_loss: 0.0980 Train_dice: 0.9020\n",
            "73/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "74/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "75/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "76/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "77/326, Train_loss: 0.0906 Train_dice: 0.9094\n",
            "78/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "79/326, Train_loss: 0.0938 Train_dice: 0.9062\n",
            "80/326, Train_loss: 0.0289 Train_dice: 0.9711\n",
            "81/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "82/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "83/326, Train_loss: 0.0649 Train_dice: 0.9351\n",
            "84/326, Train_loss: 0.1365 Train_dice: 0.8635\n",
            "85/326, Train_loss: 0.0528 Train_dice: 0.9472\n",
            "86/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "87/326, Train_loss: 0.0325 Train_dice: 0.9675\n",
            "88/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "89/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "90/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "91/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "92/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "93/326, Train_loss: 0.1057 Train_dice: 0.8943\n",
            "94/326, Train_loss: 0.0653 Train_dice: 0.9347\n",
            "95/326, Train_loss: 0.1454 Train_dice: 0.8546\n",
            "96/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "97/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "98/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "99/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "100/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "101/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "102/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "103/326, Train_loss: 0.0348 Train_dice: 0.9652\n",
            "104/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "105/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "106/326, Train_loss: 0.0463 Train_dice: 0.9537\n",
            "107/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "108/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "109/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "110/326, Train_loss: 0.0958 Train_dice: 0.9042\n",
            "111/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "112/326, Train_loss: 0.1107 Train_dice: 0.8893\n",
            "113/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "114/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "115/326, Train_loss: 0.0714 Train_dice: 0.9286\n",
            "116/326, Train_loss: 0.1492 Train_dice: 0.8508\n",
            "117/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "118/326, Train_loss: 0.1212 Train_dice: 0.8788\n",
            "119/326, Train_loss: 0.0641 Train_dice: 0.9359\n",
            "120/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "121/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "122/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "123/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "124/326, Train_loss: 0.0722 Train_dice: 0.9278\n",
            "125/326, Train_loss: 0.0173 Train_dice: 0.9827\n",
            "126/326, Train_loss: 0.0968 Train_dice: 0.9032\n",
            "127/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "128/326, Train_loss: 0.0776 Train_dice: 0.9224\n",
            "129/326, Train_loss: 0.1807 Train_dice: 0.8193\n",
            "130/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "131/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "132/326, Train_loss: 0.0925 Train_dice: 0.9075\n",
            "133/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "134/326, Train_loss: 0.1825 Train_dice: 0.8175\n",
            "135/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "136/326, Train_loss: 0.0978 Train_dice: 0.9022\n",
            "137/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "138/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "139/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "140/326, Train_loss: 0.0680 Train_dice: 0.9320\n",
            "141/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "142/326, Train_loss: 0.0981 Train_dice: 0.9019\n",
            "143/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "144/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "145/326, Train_loss: 0.1358 Train_dice: 0.8642\n",
            "146/326, Train_loss: 0.0593 Train_dice: 0.9407\n",
            "147/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "148/326, Train_loss: 0.0878 Train_dice: 0.9122\n",
            "149/326, Train_loss: 0.0533 Train_dice: 0.9467\n",
            "150/326, Train_loss: 0.1012 Train_dice: 0.8988\n",
            "151/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "152/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "153/326, Train_loss: 0.1160 Train_dice: 0.8840\n",
            "154/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "155/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "156/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "157/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "158/326, Train_loss: 0.1410 Train_dice: 0.8590\n",
            "159/326, Train_loss: 0.0427 Train_dice: 0.9573\n",
            "160/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "161/326, Train_loss: 0.0666 Train_dice: 0.9334\n",
            "162/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "163/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "164/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "165/326, Train_loss: 0.1041 Train_dice: 0.8959\n",
            "166/326, Train_loss: 0.1010 Train_dice: 0.8990\n",
            "167/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "168/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "169/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "170/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "171/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "172/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "173/326, Train_loss: 0.0075 Train_dice: 0.9925\n",
            "174/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "175/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "176/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "177/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "178/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "179/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "180/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "181/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "182/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "183/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "184/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "185/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "186/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "187/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "188/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "189/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "190/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "191/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "192/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "193/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "194/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "195/326, Train_loss: 0.0616 Train_dice: 0.9384\n",
            "196/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "197/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "198/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "199/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "200/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "201/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "202/326, Train_loss: 0.0147 Train_dice: 0.9853\n",
            "203/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "204/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "205/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "206/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "207/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "208/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "209/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "210/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "211/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "212/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "213/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "214/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "215/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "216/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "217/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "218/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "219/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "220/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "221/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "222/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "223/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "224/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "225/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "226/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "227/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "228/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "229/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "230/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "231/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "232/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "233/326, Train_loss: 0.1112 Train_dice: 0.8888\n",
            "234/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "235/326, Train_loss: 0.0928 Train_dice: 0.9072\n",
            "236/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "237/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "238/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "239/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "240/326, Train_loss: 0.0728 Train_dice: 0.9272\n",
            "241/326, Train_loss: 0.0702 Train_dice: 0.9298\n",
            "242/326, Train_loss: 0.0695 Train_dice: 0.9305\n",
            "243/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "244/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "245/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "246/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "247/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "248/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "249/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "250/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "251/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "252/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "253/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "254/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "255/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "256/326, Train_loss: 0.0721 Train_dice: 0.9279\n",
            "257/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "258/326, Train_loss: 0.1346 Train_dice: 0.8654\n",
            "259/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "260/326, Train_loss: 0.0087 Train_dice: 0.9913\n",
            "261/326, Train_loss: 0.0929 Train_dice: 0.9071\n",
            "262/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "263/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "264/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "265/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "266/326, Train_loss: 0.0286 Train_dice: 0.9714\n",
            "267/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "268/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "269/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "270/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "271/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "272/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "273/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "274/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "275/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "276/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "277/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "278/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "279/326, Train_loss: 0.0992 Train_dice: 0.9008\n",
            "280/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "281/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "282/326, Train_loss: 0.0510 Train_dice: 0.9490\n",
            "283/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "284/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "285/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "286/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "287/326, Train_loss: 0.0497 Train_dice: 0.9503\n",
            "288/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "289/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "290/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "291/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "292/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "293/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "294/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "295/326, Train_loss: 0.0697 Train_dice: 0.9303\n",
            "296/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "297/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "298/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "299/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "300/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "301/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "302/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "303/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "304/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "305/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "306/326, Train_loss: 0.0073 Train_dice: 0.9927\n",
            "307/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "308/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "309/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "310/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "311/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "312/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "313/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "314/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "315/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "316/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "317/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "318/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "319/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "320/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "321/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "322/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "323/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "324/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "325/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "326/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "--------------------\n",
            "Epoch_loss: 0.0400\n",
            "Epoch_metric: 0.9600\n",
            "test_loss_epoch: 0.5319\n",
            "test_dice_epoch: 0.4681\n",
            "current epoch: 150 current mean dice: 0.4681\n",
            "best mean dice: 0.6180 \n",
            "mean jaccard index: 0.0000 at epoch: -2\n",
            "Time Taken:  11668.373413801193\n",
            "Maximum GPU Memory taken for training:  0\n",
            "Maximum CPU Memory taken for training:  229\n",
            "----------\n",
            "epoch 151/250\n",
            "1/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "2/326, Train_loss: 0.1039 Train_dice: 0.8961\n",
            "3/326, Train_loss: 0.1220 Train_dice: 0.8780\n",
            "4/326, Train_loss: 0.0190 Train_dice: 0.9810\n",
            "5/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "6/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "7/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "8/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "9/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "10/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "11/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "12/326, Train_loss: 0.1035 Train_dice: 0.8965\n",
            "13/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "14/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "15/326, Train_loss: 0.1380 Train_dice: 0.8620\n",
            "16/326, Train_loss: 0.0429 Train_dice: 0.9571\n",
            "17/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "18/326, Train_loss: 0.1048 Train_dice: 0.8952\n",
            "19/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "20/326, Train_loss: 0.0756 Train_dice: 0.9244\n",
            "21/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "22/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "23/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "24/326, Train_loss: 0.0860 Train_dice: 0.9140\n",
            "25/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "26/326, Train_loss: 0.0209 Train_dice: 0.9791\n",
            "27/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "28/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "29/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "30/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "31/326, Train_loss: 0.1213 Train_dice: 0.8787\n",
            "32/326, Train_loss: 0.0737 Train_dice: 0.9263\n",
            "33/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "34/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "35/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "36/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "37/326, Train_loss: 0.0289 Train_dice: 0.9711\n",
            "38/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "39/326, Train_loss: 0.0604 Train_dice: 0.9396\n",
            "40/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "41/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "42/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "43/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "44/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "45/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "46/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "47/326, Train_loss: 0.1141 Train_dice: 0.8859\n",
            "48/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "49/326, Train_loss: 0.0537 Train_dice: 0.9463\n",
            "50/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "51/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "52/326, Train_loss: 0.0749 Train_dice: 0.9251\n",
            "53/326, Train_loss: 0.0161 Train_dice: 0.9839\n",
            "54/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "55/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "56/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "57/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "58/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "59/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "60/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "61/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "62/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "63/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "64/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "65/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "66/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "67/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "68/326, Train_loss: 0.0598 Train_dice: 0.9402\n",
            "69/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "70/326, Train_loss: 0.1369 Train_dice: 0.8631\n",
            "71/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "72/326, Train_loss: 0.0962 Train_dice: 0.9038\n",
            "73/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "74/326, Train_loss: 0.0305 Train_dice: 0.9695\n",
            "75/326, Train_loss: 0.0389 Train_dice: 0.9611\n",
            "76/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "77/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "78/326, Train_loss: 0.0640 Train_dice: 0.9360\n",
            "79/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "80/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "81/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "82/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "83/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "84/326, Train_loss: 0.1317 Train_dice: 0.8683\n",
            "85/326, Train_loss: 0.0503 Train_dice: 0.9497\n",
            "86/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "87/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "88/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "89/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "90/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "91/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "92/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "93/326, Train_loss: 0.1050 Train_dice: 0.8950\n",
            "94/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "95/326, Train_loss: 0.1446 Train_dice: 0.8554\n",
            "96/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "97/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "98/326, Train_loss: 0.0941 Train_dice: 0.9059\n",
            "99/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "100/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "101/326, Train_loss: 0.0475 Train_dice: 0.9525\n",
            "102/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "103/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "104/326, Train_loss: 0.0508 Train_dice: 0.9492\n",
            "105/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "106/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "107/326, Train_loss: 0.0479 Train_dice: 0.9521\n",
            "108/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "109/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "110/326, Train_loss: 0.0924 Train_dice: 0.9076\n",
            "111/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "112/326, Train_loss: 0.1078 Train_dice: 0.8922\n",
            "113/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "114/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "115/326, Train_loss: 0.0681 Train_dice: 0.9319\n",
            "116/326, Train_loss: 0.1451 Train_dice: 0.8549\n",
            "117/326, Train_loss: 0.0434 Train_dice: 0.9566\n",
            "118/326, Train_loss: 0.1168 Train_dice: 0.8832\n",
            "119/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "120/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "121/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "122/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "123/326, Train_loss: 0.0413 Train_dice: 0.9587\n",
            "124/326, Train_loss: 0.0707 Train_dice: 0.9293\n",
            "125/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "126/326, Train_loss: 0.0954 Train_dice: 0.9046\n",
            "127/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "128/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "129/326, Train_loss: 0.1759 Train_dice: 0.8241\n",
            "130/326, Train_loss: 0.0933 Train_dice: 0.9067\n",
            "131/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "132/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "133/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "134/326, Train_loss: 0.1740 Train_dice: 0.8260\n",
            "135/326, Train_loss: 0.0675 Train_dice: 0.9325\n",
            "136/326, Train_loss: 0.0945 Train_dice: 0.9055\n",
            "137/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "138/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "139/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "140/326, Train_loss: 0.0673 Train_dice: 0.9327\n",
            "141/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "142/326, Train_loss: 0.0982 Train_dice: 0.9018\n",
            "143/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "144/326, Train_loss: 0.0545 Train_dice: 0.9455\n",
            "145/326, Train_loss: 0.1321 Train_dice: 0.8679\n",
            "146/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "147/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "148/326, Train_loss: 0.0840 Train_dice: 0.9160\n",
            "149/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "150/326, Train_loss: 0.0949 Train_dice: 0.9051\n",
            "151/326, Train_loss: 0.0657 Train_dice: 0.9343\n",
            "152/326, Train_loss: 0.0266 Train_dice: 0.9734\n",
            "153/326, Train_loss: 0.1143 Train_dice: 0.8857\n",
            "154/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "155/326, Train_loss: 0.0323 Train_dice: 0.9677\n",
            "156/326, Train_loss: 0.0563 Train_dice: 0.9437\n",
            "157/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "158/326, Train_loss: 0.1453 Train_dice: 0.8547\n",
            "159/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "160/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "161/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "162/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "163/326, Train_loss: 0.0228 Train_dice: 0.9772\n",
            "164/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "165/326, Train_loss: 0.0959 Train_dice: 0.9041\n",
            "166/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "167/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "168/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "169/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "170/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "171/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "172/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "173/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "174/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "175/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "176/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "177/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "178/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "179/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "180/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "181/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "182/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "183/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "184/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "185/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "186/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "187/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "188/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "189/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "190/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "191/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "192/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "193/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "194/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "195/326, Train_loss: 0.0596 Train_dice: 0.9404\n",
            "196/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "197/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "198/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "199/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "200/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "201/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "202/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "203/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "204/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "205/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "206/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "207/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "208/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "209/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "210/326, Train_loss: 0.0844 Train_dice: 0.9156\n",
            "211/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "212/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "213/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "214/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "215/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "216/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "217/326, Train_loss: 0.0425 Train_dice: 0.9575\n",
            "218/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "219/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "220/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "221/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "222/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "223/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "224/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "225/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "226/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "227/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "228/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "229/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "230/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "231/326, Train_loss: 0.0492 Train_dice: 0.9508\n",
            "232/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "233/326, Train_loss: 0.1092 Train_dice: 0.8908\n",
            "234/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "235/326, Train_loss: 0.0923 Train_dice: 0.9077\n",
            "236/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "237/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "238/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "239/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "240/326, Train_loss: 0.0713 Train_dice: 0.9287\n",
            "241/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "242/326, Train_loss: 0.0677 Train_dice: 0.9323\n",
            "243/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "244/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "245/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "246/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "247/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "248/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "249/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "250/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "251/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "252/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "253/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "254/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "255/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "256/326, Train_loss: 0.0784 Train_dice: 0.9216\n",
            "257/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "258/326, Train_loss: 0.1410 Train_dice: 0.8590\n",
            "259/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "260/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "261/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "262/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "263/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "264/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "265/326, Train_loss: 0.0414 Train_dice: 0.9586\n",
            "266/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "267/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "268/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "269/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "270/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "271/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "272/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "273/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "274/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "275/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "276/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "277/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "278/326, Train_loss: 0.0572 Train_dice: 0.9428\n",
            "279/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "280/326, Train_loss: 0.0500 Train_dice: 0.9500\n",
            "281/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "282/326, Train_loss: 0.0506 Train_dice: 0.9494\n",
            "283/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "284/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "285/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "286/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "287/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "288/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "289/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "290/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "291/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "292/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "293/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "294/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "295/326, Train_loss: 0.0625 Train_dice: 0.9375\n",
            "296/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "297/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "298/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "299/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "300/326, Train_loss: 0.0555 Train_dice: 0.9445\n",
            "301/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "302/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "303/326, Train_loss: 0.0650 Train_dice: 0.9350\n",
            "304/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "305/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "306/326, Train_loss: 0.0078 Train_dice: 0.9922\n",
            "307/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "308/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "309/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "310/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "311/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "312/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "313/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "314/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "315/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "316/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "317/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "318/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "319/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "320/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "321/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "322/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "323/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "324/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "325/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "326/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "--------------------\n",
            "Epoch_loss: 0.0392\n",
            "Epoch_metric: 0.9608\n",
            "----------\n",
            "epoch 152/250\n",
            "1/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "2/326, Train_loss: 0.1043 Train_dice: 0.8957\n",
            "3/326, Train_loss: 0.1237 Train_dice: 0.8763\n",
            "4/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "5/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "6/326, Train_loss: 0.0818 Train_dice: 0.9182\n",
            "7/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "8/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "9/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "10/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "11/326, Train_loss: 0.0920 Train_dice: 0.9080\n",
            "12/326, Train_loss: 0.1002 Train_dice: 0.8998\n",
            "13/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "14/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "15/326, Train_loss: 0.1345 Train_dice: 0.8655\n",
            "16/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "17/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "18/326, Train_loss: 0.1016 Train_dice: 0.8984\n",
            "19/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "20/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "21/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "22/326, Train_loss: 0.0395 Train_dice: 0.9605\n",
            "23/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "24/326, Train_loss: 0.0849 Train_dice: 0.9151\n",
            "25/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "26/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "27/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "28/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "29/326, Train_loss: 0.0495 Train_dice: 0.9505\n",
            "30/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "31/326, Train_loss: 0.1146 Train_dice: 0.8854\n",
            "32/326, Train_loss: 0.0703 Train_dice: 0.9297\n",
            "33/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "34/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "35/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "36/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "37/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "38/326, Train_loss: 0.0792 Train_dice: 0.9208\n",
            "39/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "40/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "41/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "42/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "43/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "44/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "45/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "46/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "47/326, Train_loss: 0.1109 Train_dice: 0.8891\n",
            "48/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "49/326, Train_loss: 0.0516 Train_dice: 0.9484\n",
            "50/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "51/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "52/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "53/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "54/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "55/326, Train_loss: 0.0298 Train_dice: 0.9702\n",
            "56/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "57/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "58/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "59/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "60/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "61/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "62/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "63/326, Train_loss: 0.0682 Train_dice: 0.9318\n",
            "64/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "65/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "66/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "67/326, Train_loss: 0.0210 Train_dice: 0.9790\n",
            "68/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "69/326, Train_loss: 0.0290 Train_dice: 0.9710\n",
            "70/326, Train_loss: 0.1318 Train_dice: 0.8682\n",
            "71/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "72/326, Train_loss: 0.0909 Train_dice: 0.9091\n",
            "73/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "74/326, Train_loss: 0.0290 Train_dice: 0.9710\n",
            "75/326, Train_loss: 0.0378 Train_dice: 0.9622\n",
            "76/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "77/326, Train_loss: 0.0869 Train_dice: 0.9131\n",
            "78/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "79/326, Train_loss: 0.0888 Train_dice: 0.9112\n",
            "80/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "81/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "82/326, Train_loss: 0.0277 Train_dice: 0.9723\n",
            "83/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "84/326, Train_loss: 0.1376 Train_dice: 0.8624\n",
            "85/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "86/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "87/326, Train_loss: 0.0310 Train_dice: 0.9690\n",
            "88/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "89/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "90/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "91/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "92/326, Train_loss: 0.0449 Train_dice: 0.9551\n",
            "93/326, Train_loss: 0.0977 Train_dice: 0.9023\n",
            "94/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "95/326, Train_loss: 0.1375 Train_dice: 0.8625\n",
            "96/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "97/326, Train_loss: 0.0357 Train_dice: 0.9643\n",
            "98/326, Train_loss: 0.0919 Train_dice: 0.9081\n",
            "99/326, Train_loss: 0.0288 Train_dice: 0.9712\n",
            "100/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "101/326, Train_loss: 0.0487 Train_dice: 0.9513\n",
            "102/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "103/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "104/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "105/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "106/326, Train_loss: 0.0464 Train_dice: 0.9536\n",
            "107/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "108/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "109/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "110/326, Train_loss: 0.0909 Train_dice: 0.9091\n",
            "111/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "112/326, Train_loss: 0.1047 Train_dice: 0.8953\n",
            "113/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "114/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "115/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "116/326, Train_loss: 0.1414 Train_dice: 0.8586\n",
            "117/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "118/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "119/326, Train_loss: 0.0614 Train_dice: 0.9386\n",
            "120/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "121/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "122/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "123/326, Train_loss: 0.0416 Train_dice: 0.9584\n",
            "124/326, Train_loss: 0.0698 Train_dice: 0.9302\n",
            "125/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "126/326, Train_loss: 0.0946 Train_dice: 0.9054\n",
            "127/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "128/326, Train_loss: 0.0753 Train_dice: 0.9247\n",
            "129/326, Train_loss: 0.1716 Train_dice: 0.8284\n",
            "130/326, Train_loss: 0.0919 Train_dice: 0.9081\n",
            "131/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "132/326, Train_loss: 0.0868 Train_dice: 0.9132\n",
            "133/326, Train_loss: 0.0634 Train_dice: 0.9366\n",
            "134/326, Train_loss: 0.1697 Train_dice: 0.8303\n",
            "135/326, Train_loss: 0.0648 Train_dice: 0.9352\n",
            "136/326, Train_loss: 0.0918 Train_dice: 0.9082\n",
            "137/326, Train_loss: 0.0636 Train_dice: 0.9364\n",
            "138/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "139/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "140/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "141/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "142/326, Train_loss: 0.0986 Train_dice: 0.9014\n",
            "143/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "144/326, Train_loss: 0.0536 Train_dice: 0.9464\n",
            "145/326, Train_loss: 0.1296 Train_dice: 0.8704\n",
            "146/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "147/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "148/326, Train_loss: 0.0808 Train_dice: 0.9192\n",
            "149/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "150/326, Train_loss: 0.0914 Train_dice: 0.9086\n",
            "151/326, Train_loss: 0.0621 Train_dice: 0.9379\n",
            "152/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "153/326, Train_loss: 0.1080 Train_dice: 0.8920\n",
            "154/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "155/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "156/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "157/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "158/326, Train_loss: 0.1342 Train_dice: 0.8658\n",
            "159/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "160/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "161/326, Train_loss: 0.0667 Train_dice: 0.9333\n",
            "162/326, Train_loss: 0.0174 Train_dice: 0.9826\n",
            "163/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "164/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "165/326, Train_loss: 0.0934 Train_dice: 0.9066\n",
            "166/326, Train_loss: 0.0955 Train_dice: 0.9045\n",
            "167/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "168/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "169/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "170/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "171/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "172/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "173/326, Train_loss: 0.0085 Train_dice: 0.9915\n",
            "174/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "175/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "176/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "177/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "178/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "179/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "180/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "181/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "182/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "183/326, Train_loss: 0.0602 Train_dice: 0.9398\n",
            "184/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "185/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "186/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "187/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "188/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "189/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "190/326, Train_loss: 0.0408 Train_dice: 0.9592\n",
            "191/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "192/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "193/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "194/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "195/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "196/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "197/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "198/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "199/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "200/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "201/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "202/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "203/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "204/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "205/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "206/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "207/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "208/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "209/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "210/326, Train_loss: 0.0825 Train_dice: 0.9175\n",
            "211/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "212/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "213/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "214/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "215/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "216/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "217/326, Train_loss: 0.0420 Train_dice: 0.9580\n",
            "218/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "219/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "220/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "221/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "222/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "223/326, Train_loss: 0.0170 Train_dice: 0.9830\n",
            "224/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "225/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "226/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "227/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "228/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "229/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "230/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "231/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "232/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "233/326, Train_loss: 0.1074 Train_dice: 0.8926\n",
            "234/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "235/326, Train_loss: 0.0880 Train_dice: 0.9120\n",
            "236/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "237/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "238/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "239/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "240/326, Train_loss: 0.0711 Train_dice: 0.9289\n",
            "241/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "242/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "243/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "244/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "245/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "246/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "247/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "248/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "249/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "250/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "251/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "252/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "253/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "254/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "255/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "256/326, Train_loss: 0.0774 Train_dice: 0.9226\n",
            "257/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "258/326, Train_loss: 0.1265 Train_dice: 0.8735\n",
            "259/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "260/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "261/326, Train_loss: 0.0913 Train_dice: 0.9087\n",
            "262/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "263/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "264/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "265/326, Train_loss: 0.0411 Train_dice: 0.9589\n",
            "266/326, Train_loss: 0.0302 Train_dice: 0.9698\n",
            "267/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "268/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "269/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "270/326, Train_loss: 0.0477 Train_dice: 0.9523\n",
            "271/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "272/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "273/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "274/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "275/326, Train_loss: 0.0873 Train_dice: 0.9127\n",
            "276/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "277/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "278/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "279/326, Train_loss: 0.0948 Train_dice: 0.9052\n",
            "280/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "281/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "282/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "283/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "284/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "285/326, Train_loss: 0.0355 Train_dice: 0.9645\n",
            "286/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "287/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "288/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "289/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "290/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "291/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "292/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "293/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "294/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "295/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "296/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "297/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "298/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "299/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "300/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "301/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "302/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "303/326, Train_loss: 0.0636 Train_dice: 0.9364\n",
            "304/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "305/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "306/326, Train_loss: 0.0077 Train_dice: 0.9923\n",
            "307/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "308/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "309/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "310/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "311/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "312/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "313/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "314/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "315/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "316/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "317/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "318/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "319/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "320/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "321/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "322/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "323/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "324/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "325/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "326/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "--------------------\n",
            "Epoch_loss: 0.0384\n",
            "Epoch_metric: 0.9616\n",
            "----------\n",
            "epoch 153/250\n",
            "1/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "2/326, Train_loss: 0.0987 Train_dice: 0.9013\n",
            "3/326, Train_loss: 0.1178 Train_dice: 0.8822\n",
            "4/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "5/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "6/326, Train_loss: 0.0750 Train_dice: 0.9250\n",
            "7/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "8/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "9/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "10/326, Train_loss: 0.0279 Train_dice: 0.9721\n",
            "11/326, Train_loss: 0.0914 Train_dice: 0.9086\n",
            "12/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "13/326, Train_loss: 0.0523 Train_dice: 0.9477\n",
            "14/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "15/326, Train_loss: 0.1331 Train_dice: 0.8669\n",
            "16/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "17/326, Train_loss: 0.0200 Train_dice: 0.9800\n",
            "18/326, Train_loss: 0.0989 Train_dice: 0.9011\n",
            "19/326, Train_loss: 0.0392 Train_dice: 0.9608\n",
            "20/326, Train_loss: 0.0710 Train_dice: 0.9290\n",
            "21/326, Train_loss: 0.0351 Train_dice: 0.9649\n",
            "22/326, Train_loss: 0.0385 Train_dice: 0.9615\n",
            "23/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "24/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "25/326, Train_loss: 0.0524 Train_dice: 0.9476\n",
            "26/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "27/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "28/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "29/326, Train_loss: 0.0486 Train_dice: 0.9514\n",
            "30/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "31/326, Train_loss: 0.1124 Train_dice: 0.8876\n",
            "32/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "33/326, Train_loss: 0.0252 Train_dice: 0.9748\n",
            "34/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "35/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "36/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "37/326, Train_loss: 0.0275 Train_dice: 0.9725\n",
            "38/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "39/326, Train_loss: 0.0549 Train_dice: 0.9451\n",
            "40/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "41/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "42/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "43/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "44/326, Train_loss: 0.0197 Train_dice: 0.9803\n",
            "45/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "46/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "47/326, Train_loss: 0.1067 Train_dice: 0.8933\n",
            "48/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "49/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "50/326, Train_loss: 0.0606 Train_dice: 0.9394\n",
            "51/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "52/326, Train_loss: 0.0706 Train_dice: 0.9294\n",
            "53/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "54/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "55/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "56/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "57/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "58/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "59/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "60/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "61/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "62/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "63/326, Train_loss: 0.0654 Train_dice: 0.9346\n",
            "64/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "65/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "66/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "67/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "68/326, Train_loss: 0.0550 Train_dice: 0.9450\n",
            "69/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "70/326, Train_loss: 0.1283 Train_dice: 0.8717\n",
            "71/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "72/326, Train_loss: 0.0879 Train_dice: 0.9121\n",
            "73/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "74/326, Train_loss: 0.0266 Train_dice: 0.9734\n",
            "75/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "76/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "77/326, Train_loss: 0.0822 Train_dice: 0.9178\n",
            "78/326, Train_loss: 0.0584 Train_dice: 0.9416\n",
            "79/326, Train_loss: 0.0844 Train_dice: 0.9156\n",
            "80/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "81/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "82/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "83/326, Train_loss: 0.0600 Train_dice: 0.9400\n",
            "84/326, Train_loss: 0.1312 Train_dice: 0.8688\n",
            "85/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "86/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "87/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "88/326, Train_loss: 0.0599 Train_dice: 0.9401\n",
            "89/326, Train_loss: 0.0212 Train_dice: 0.9788\n",
            "90/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "91/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "92/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "93/326, Train_loss: 0.0968 Train_dice: 0.9032\n",
            "94/326, Train_loss: 0.0588 Train_dice: 0.9412\n",
            "95/326, Train_loss: 0.1341 Train_dice: 0.8659\n",
            "96/326, Train_loss: 0.0405 Train_dice: 0.9595\n",
            "97/326, Train_loss: 0.0330 Train_dice: 0.9670\n",
            "98/326, Train_loss: 0.0850 Train_dice: 0.9150\n",
            "99/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "100/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "101/326, Train_loss: 0.0441 Train_dice: 0.9559\n",
            "102/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "103/326, Train_loss: 0.0350 Train_dice: 0.9650\n",
            "104/326, Train_loss: 0.0502 Train_dice: 0.9498\n",
            "105/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "106/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "107/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "108/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "109/326, Train_loss: 0.0505 Train_dice: 0.9495\n",
            "110/326, Train_loss: 0.0908 Train_dice: 0.9092\n",
            "111/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "112/326, Train_loss: 0.1043 Train_dice: 0.8957\n",
            "113/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "114/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "115/326, Train_loss: 0.0665 Train_dice: 0.9335\n",
            "116/326, Train_loss: 0.1378 Train_dice: 0.8622\n",
            "117/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "118/326, Train_loss: 0.1099 Train_dice: 0.8901\n",
            "119/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "120/326, Train_loss: 0.0322 Train_dice: 0.9678\n",
            "121/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "122/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "123/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "124/326, Train_loss: 0.0664 Train_dice: 0.9336\n",
            "125/326, Train_loss: 0.0177 Train_dice: 0.9823\n",
            "126/326, Train_loss: 0.0914 Train_dice: 0.9086\n",
            "127/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "128/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "129/326, Train_loss: 0.1693 Train_dice: 0.8307\n",
            "130/326, Train_loss: 0.0938 Train_dice: 0.9062\n",
            "131/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "132/326, Train_loss: 0.0873 Train_dice: 0.9127\n",
            "133/326, Train_loss: 0.0644 Train_dice: 0.9356\n",
            "134/326, Train_loss: 0.1666 Train_dice: 0.8334\n",
            "135/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "136/326, Train_loss: 0.0880 Train_dice: 0.9120\n",
            "137/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "138/326, Train_loss: 0.0386 Train_dice: 0.9614\n",
            "139/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "140/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "141/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "142/326, Train_loss: 0.0886 Train_dice: 0.9114\n",
            "143/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "144/326, Train_loss: 0.0542 Train_dice: 0.9458\n",
            "145/326, Train_loss: 0.1257 Train_dice: 0.8743\n",
            "146/326, Train_loss: 0.0583 Train_dice: 0.9417\n",
            "147/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "148/326, Train_loss: 0.0809 Train_dice: 0.9191\n",
            "149/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "150/326, Train_loss: 0.0949 Train_dice: 0.9051\n",
            "151/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "152/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "153/326, Train_loss: 0.1078 Train_dice: 0.8922\n",
            "154/326, Train_loss: 0.0472 Train_dice: 0.9528\n",
            "155/326, Train_loss: 0.0269 Train_dice: 0.9731\n",
            "156/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "157/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "158/326, Train_loss: 0.1304 Train_dice: 0.8696\n",
            "159/326, Train_loss: 0.0418 Train_dice: 0.9582\n",
            "160/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "161/326, Train_loss: 0.0617 Train_dice: 0.9383\n",
            "162/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "163/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "164/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "165/326, Train_loss: 0.0913 Train_dice: 0.9087\n",
            "166/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "167/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "168/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "169/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "170/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "171/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "172/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "173/326, Train_loss: 0.0077 Train_dice: 0.9923\n",
            "174/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "175/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "176/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "177/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "178/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "179/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "180/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "181/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "182/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "183/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "184/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "185/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "186/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "187/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "188/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "189/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "190/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "191/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "192/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "193/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "194/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "195/326, Train_loss: 0.0527 Train_dice: 0.9473\n",
            "196/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "197/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "198/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "199/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "200/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "201/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "202/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "203/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "204/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "205/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "206/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "207/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "208/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "209/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "210/326, Train_loss: 0.0769 Train_dice: 0.9231\n",
            "211/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "212/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "213/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "214/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "215/326, Train_loss: 0.0085 Train_dice: 0.9915\n",
            "216/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "217/326, Train_loss: 0.0398 Train_dice: 0.9602\n",
            "218/326, Train_loss: 0.0311 Train_dice: 0.9689\n",
            "219/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "220/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "221/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "222/326, Train_loss: 0.0231 Train_dice: 0.9769\n",
            "223/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "224/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "225/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "226/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "227/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "228/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "229/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "230/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "231/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "232/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "233/326, Train_loss: 0.1000 Train_dice: 0.9000\n",
            "234/326, Train_loss: 0.0130 Train_dice: 0.9870\n",
            "235/326, Train_loss: 0.0855 Train_dice: 0.9145\n",
            "236/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "237/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "238/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "239/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "240/326, Train_loss: 0.0674 Train_dice: 0.9326\n",
            "241/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "242/326, Train_loss: 0.0627 Train_dice: 0.9373\n",
            "243/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "244/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "245/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "246/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "247/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "248/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "249/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "250/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "251/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "252/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "253/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "254/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "255/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "256/326, Train_loss: 0.0704 Train_dice: 0.9296\n",
            "257/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "258/326, Train_loss: 0.1291 Train_dice: 0.8709\n",
            "259/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "260/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "261/326, Train_loss: 0.0860 Train_dice: 0.9140\n",
            "262/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "263/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "264/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "265/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "266/326, Train_loss: 0.0264 Train_dice: 0.9736\n",
            "267/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "268/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "269/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "270/326, Train_loss: 0.0479 Train_dice: 0.9521\n",
            "271/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "272/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "273/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "274/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "275/326, Train_loss: 0.0869 Train_dice: 0.9131\n",
            "276/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "277/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "278/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "279/326, Train_loss: 0.0961 Train_dice: 0.9039\n",
            "280/326, Train_loss: 0.0489 Train_dice: 0.9511\n",
            "281/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "282/326, Train_loss: 0.0498 Train_dice: 0.9502\n",
            "283/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "284/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "285/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "286/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "287/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "288/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "289/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "290/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "291/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "292/326, Train_loss: 0.0152 Train_dice: 0.9848\n",
            "293/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "294/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "295/326, Train_loss: 0.0687 Train_dice: 0.9313\n",
            "296/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "297/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "298/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "299/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "300/326, Train_loss: 0.0620 Train_dice: 0.9380\n",
            "301/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "302/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "303/326, Train_loss: 0.0672 Train_dice: 0.9328\n",
            "304/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "305/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "306/326, Train_loss: 0.0080 Train_dice: 0.9920\n",
            "307/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "308/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "309/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "310/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "311/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "312/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "313/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "314/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "315/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "316/326, Train_loss: 0.0140 Train_dice: 0.9860\n",
            "317/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "318/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "319/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "320/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "321/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "322/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "323/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "324/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "325/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "326/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "--------------------\n",
            "Epoch_loss: 0.0374\n",
            "Epoch_metric: 0.9626\n",
            "----------\n",
            "epoch 154/250\n",
            "1/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "2/326, Train_loss: 0.0976 Train_dice: 0.9024\n",
            "3/326, Train_loss: 0.1146 Train_dice: 0.8854\n",
            "4/326, Train_loss: 0.0189 Train_dice: 0.9811\n",
            "5/326, Train_loss: 0.0215 Train_dice: 0.9785\n",
            "6/326, Train_loss: 0.0736 Train_dice: 0.9264\n",
            "7/326, Train_loss: 0.0363 Train_dice: 0.9637\n",
            "8/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "9/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "10/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "11/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "12/326, Train_loss: 0.0942 Train_dice: 0.9058\n",
            "13/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "14/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "15/326, Train_loss: 0.1274 Train_dice: 0.8726\n",
            "16/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "17/326, Train_loss: 0.0193 Train_dice: 0.9807\n",
            "18/326, Train_loss: 0.0965 Train_dice: 0.9035\n",
            "19/326, Train_loss: 0.0396 Train_dice: 0.9604\n",
            "20/326, Train_loss: 0.0693 Train_dice: 0.9307\n",
            "21/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "22/326, Train_loss: 0.0370 Train_dice: 0.9630\n",
            "23/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "24/326, Train_loss: 0.0792 Train_dice: 0.9208\n",
            "25/326, Train_loss: 0.0499 Train_dice: 0.9501\n",
            "26/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "27/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "28/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "29/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "30/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "31/326, Train_loss: 0.1082 Train_dice: 0.8918\n",
            "32/326, Train_loss: 0.0699 Train_dice: 0.9301\n",
            "33/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "34/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "35/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "36/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "37/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "38/326, Train_loss: 0.0749 Train_dice: 0.9251\n",
            "39/326, Train_loss: 0.0536 Train_dice: 0.9464\n",
            "40/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "41/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "42/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "43/326, Train_loss: 0.0155 Train_dice: 0.9845\n",
            "44/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "45/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "46/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "47/326, Train_loss: 0.1034 Train_dice: 0.8966\n",
            "48/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "49/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "50/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "51/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "52/326, Train_loss: 0.0686 Train_dice: 0.9314\n",
            "53/326, Train_loss: 0.0144 Train_dice: 0.9856\n",
            "54/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "55/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "56/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "57/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "58/326, Train_loss: 0.0248 Train_dice: 0.9752\n",
            "59/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "60/326, Train_loss: 0.0299 Train_dice: 0.9701\n",
            "61/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "62/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "63/326, Train_loss: 0.0636 Train_dice: 0.9364\n",
            "64/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "65/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "66/326, Train_loss: 0.0565 Train_dice: 0.9435\n",
            "67/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "68/326, Train_loss: 0.0531 Train_dice: 0.9469\n",
            "69/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "70/326, Train_loss: 0.1240 Train_dice: 0.8760\n",
            "71/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "72/326, Train_loss: 0.0852 Train_dice: 0.9148\n",
            "73/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "74/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "75/326, Train_loss: 0.0337 Train_dice: 0.9663\n",
            "76/326, Train_loss: 0.0088 Train_dice: 0.9912\n",
            "77/326, Train_loss: 0.0790 Train_dice: 0.9210\n",
            "78/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "79/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "80/326, Train_loss: 0.0257 Train_dice: 0.9743\n",
            "81/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "82/326, Train_loss: 0.0246 Train_dice: 0.9754\n",
            "83/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "84/326, Train_loss: 0.1250 Train_dice: 0.8750\n",
            "85/326, Train_loss: 0.0468 Train_dice: 0.9532\n",
            "86/326, Train_loss: 0.0234 Train_dice: 0.9766\n",
            "87/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "88/326, Train_loss: 0.0562 Train_dice: 0.9438\n",
            "89/326, Train_loss: 0.0198 Train_dice: 0.9802\n",
            "90/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "91/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "92/326, Train_loss: 0.0424 Train_dice: 0.9576\n",
            "93/326, Train_loss: 0.0951 Train_dice: 0.9049\n",
            "94/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "95/326, Train_loss: 0.1298 Train_dice: 0.8702\n",
            "96/326, Train_loss: 0.0404 Train_dice: 0.9596\n",
            "97/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "98/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "99/326, Train_loss: 0.0251 Train_dice: 0.9749\n",
            "100/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "101/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "102/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "103/326, Train_loss: 0.0309 Train_dice: 0.9691\n",
            "104/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "105/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "106/326, Train_loss: 0.0433 Train_dice: 0.9567\n",
            "107/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "108/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "109/326, Train_loss: 0.0478 Train_dice: 0.9522\n",
            "110/326, Train_loss: 0.0876 Train_dice: 0.9124\n",
            "111/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "112/326, Train_loss: 0.0992 Train_dice: 0.9008\n",
            "113/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "114/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "115/326, Train_loss: 0.0678 Train_dice: 0.9322\n",
            "116/326, Train_loss: 0.1320 Train_dice: 0.8680\n",
            "117/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "118/326, Train_loss: 0.1095 Train_dice: 0.8905\n",
            "119/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "120/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "121/326, Train_loss: 0.0213 Train_dice: 0.9787\n",
            "122/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "123/326, Train_loss: 0.0377 Train_dice: 0.9623\n",
            "124/326, Train_loss: 0.0634 Train_dice: 0.9366\n",
            "125/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "126/326, Train_loss: 0.0875 Train_dice: 0.9125\n",
            "127/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "128/326, Train_loss: 0.0708 Train_dice: 0.9292\n",
            "129/326, Train_loss: 0.1638 Train_dice: 0.8362\n",
            "130/326, Train_loss: 0.0870 Train_dice: 0.9130\n",
            "131/326, Train_loss: 0.0224 Train_dice: 0.9776\n",
            "132/326, Train_loss: 0.0856 Train_dice: 0.9144\n",
            "133/326, Train_loss: 0.0642 Train_dice: 0.9358\n",
            "134/326, Train_loss: 0.1624 Train_dice: 0.8376\n",
            "135/326, Train_loss: 0.0646 Train_dice: 0.9354\n",
            "136/326, Train_loss: 0.0862 Train_dice: 0.9138\n",
            "137/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "138/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "139/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "140/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "141/326, Train_loss: 0.0340 Train_dice: 0.9660\n",
            "142/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "143/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "144/326, Train_loss: 0.0510 Train_dice: 0.9490\n",
            "145/326, Train_loss: 0.1212 Train_dice: 0.8788\n",
            "146/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "147/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "148/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "149/326, Train_loss: 0.0490 Train_dice: 0.9510\n",
            "150/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "151/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "152/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "153/326, Train_loss: 0.1063 Train_dice: 0.8937\n",
            "154/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "155/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "156/326, Train_loss: 0.0525 Train_dice: 0.9475\n",
            "157/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "158/326, Train_loss: 0.1314 Train_dice: 0.8686\n",
            "159/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "160/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "161/326, Train_loss: 0.0628 Train_dice: 0.9372\n",
            "162/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "163/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "164/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "165/326, Train_loss: 0.0863 Train_dice: 0.9137\n",
            "166/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "167/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "168/326, Train_loss: 0.0211 Train_dice: 0.9789\n",
            "169/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "170/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "171/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "172/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "173/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "174/326, Train_loss: 0.0154 Train_dice: 0.9846\n",
            "175/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "176/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "177/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "178/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "179/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "180/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "181/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "182/326, Train_loss: 0.0083 Train_dice: 0.9917\n",
            "183/326, Train_loss: 0.0553 Train_dice: 0.9447\n",
            "184/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "185/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "186/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "187/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "188/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "189/326, Train_loss: 0.0088 Train_dice: 0.9912\n",
            "190/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "191/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "192/326, Train_loss: 0.0360 Train_dice: 0.9640\n",
            "193/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "194/326, Train_loss: 0.0078 Train_dice: 0.9922\n",
            "195/326, Train_loss: 0.0520 Train_dice: 0.9480\n",
            "196/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "197/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "198/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "199/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "200/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "201/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "202/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "203/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "204/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "205/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "206/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "207/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "208/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "209/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "210/326, Train_loss: 0.0724 Train_dice: 0.9276\n",
            "211/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "212/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "213/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "214/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "215/326, Train_loss: 0.0083 Train_dice: 0.9917\n",
            "216/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "217/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "218/326, Train_loss: 0.0276 Train_dice: 0.9724\n",
            "219/326, Train_loss: 0.0341 Train_dice: 0.9659\n",
            "220/326, Train_loss: 0.0083 Train_dice: 0.9917\n",
            "221/326, Train_loss: 0.0076 Train_dice: 0.9924\n",
            "222/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "223/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "224/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "225/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "226/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "227/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "228/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "229/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "230/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "231/326, Train_loss: 0.0448 Train_dice: 0.9552\n",
            "232/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "233/326, Train_loss: 0.0973 Train_dice: 0.9027\n",
            "234/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "235/326, Train_loss: 0.0826 Train_dice: 0.9174\n",
            "236/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "237/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "238/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "239/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "240/326, Train_loss: 0.0639 Train_dice: 0.9361\n",
            "241/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "242/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "243/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "244/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "245/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "246/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "247/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "248/326, Train_loss: 0.0451 Train_dice: 0.9549\n",
            "249/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "250/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "251/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "252/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "253/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "254/326, Train_loss: 0.0139 Train_dice: 0.9861\n",
            "255/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "256/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "257/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "258/326, Train_loss: 0.1143 Train_dice: 0.8857\n",
            "259/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "260/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "261/326, Train_loss: 0.0811 Train_dice: 0.9189\n",
            "262/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "263/326, Train_loss: 0.0219 Train_dice: 0.9781\n",
            "264/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "265/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "266/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "267/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "268/326, Train_loss: 0.0354 Train_dice: 0.9646\n",
            "269/326, Train_loss: 0.0417 Train_dice: 0.9583\n",
            "270/326, Train_loss: 0.0445 Train_dice: 0.9555\n",
            "271/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "272/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "273/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "274/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "275/326, Train_loss: 0.0802 Train_dice: 0.9198\n",
            "276/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "277/326, Train_loss: 0.0120 Train_dice: 0.9880\n",
            "278/326, Train_loss: 0.0501 Train_dice: 0.9499\n",
            "279/326, Train_loss: 0.0868 Train_dice: 0.9132\n",
            "280/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "281/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "282/326, Train_loss: 0.0480 Train_dice: 0.9520\n",
            "283/326, Train_loss: 0.0259 Train_dice: 0.9741\n",
            "284/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "285/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "286/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "287/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "288/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "289/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "290/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "291/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "292/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "293/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "294/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "295/326, Train_loss: 0.0632 Train_dice: 0.9368\n",
            "296/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "297/326, Train_loss: 0.0134 Train_dice: 0.9866\n",
            "298/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "299/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "300/326, Train_loss: 0.0512 Train_dice: 0.9488\n",
            "301/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "302/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "303/326, Train_loss: 0.0606 Train_dice: 0.9394\n",
            "304/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "305/326, Train_loss: 0.0206 Train_dice: 0.9794\n",
            "306/326, Train_loss: 0.0075 Train_dice: 0.9925\n",
            "307/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "308/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "309/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "310/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "311/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "312/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "313/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "314/326, Train_loss: 0.0133 Train_dice: 0.9867\n",
            "315/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "316/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "317/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "318/326, Train_loss: 0.0132 Train_dice: 0.9868\n",
            "319/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "320/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "321/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "322/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "323/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "324/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "325/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "326/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "--------------------\n",
            "Epoch_loss: 0.0360\n",
            "Epoch_metric: 0.9640\n",
            "----------\n",
            "epoch 155/250\n",
            "1/326, Train_loss: 0.0637 Train_dice: 0.9363\n",
            "2/326, Train_loss: 0.0913 Train_dice: 0.9087\n",
            "3/326, Train_loss: 0.1114 Train_dice: 0.8886\n",
            "4/326, Train_loss: 0.0183 Train_dice: 0.9817\n",
            "5/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "6/326, Train_loss: 0.0716 Train_dice: 0.9284\n",
            "7/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "8/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "9/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "10/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "11/326, Train_loss: 0.0833 Train_dice: 0.9167\n",
            "12/326, Train_loss: 0.0905 Train_dice: 0.9095\n",
            "13/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "14/326, Train_loss: 0.0217 Train_dice: 0.9783\n",
            "15/326, Train_loss: 0.1248 Train_dice: 0.8752\n",
            "16/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "17/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "18/326, Train_loss: 0.0956 Train_dice: 0.9044\n",
            "19/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "20/326, Train_loss: 0.0671 Train_dice: 0.9329\n",
            "21/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "22/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "23/326, Train_loss: 0.0301 Train_dice: 0.9699\n",
            "24/326, Train_loss: 0.0768 Train_dice: 0.9232\n",
            "25/326, Train_loss: 0.0481 Train_dice: 0.9519\n",
            "26/326, Train_loss: 0.0194 Train_dice: 0.9806\n",
            "27/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "28/326, Train_loss: 0.0175 Train_dice: 0.9825\n",
            "29/326, Train_loss: 0.0460 Train_dice: 0.9540\n",
            "30/326, Train_loss: 0.0283 Train_dice: 0.9717\n",
            "31/326, Train_loss: 0.1049 Train_dice: 0.8951\n",
            "32/326, Train_loss: 0.0663 Train_dice: 0.9337\n",
            "33/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "34/326, Train_loss: 0.0302 Train_dice: 0.9698\n",
            "35/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "36/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "37/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "38/326, Train_loss: 0.0738 Train_dice: 0.9262\n",
            "39/326, Train_loss: 0.0538 Train_dice: 0.9462\n",
            "40/326, Train_loss: 0.0179 Train_dice: 0.9821\n",
            "41/326, Train_loss: 0.0379 Train_dice: 0.9621\n",
            "42/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "43/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "44/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "45/326, Train_loss: 0.0220 Train_dice: 0.9780\n",
            "46/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "47/326, Train_loss: 0.0999 Train_dice: 0.9001\n",
            "48/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "49/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "50/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "51/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "52/326, Train_loss: 0.0654 Train_dice: 0.9346\n",
            "53/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "54/326, Train_loss: 0.0346 Train_dice: 0.9654\n",
            "55/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "56/326, Train_loss: 0.0332 Train_dice: 0.9668\n",
            "57/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "58/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "59/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "60/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "61/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "62/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "63/326, Train_loss: 0.0618 Train_dice: 0.9382\n",
            "64/326, Train_loss: 0.0274 Train_dice: 0.9726\n",
            "65/326, Train_loss: 0.0158 Train_dice: 0.9842\n",
            "66/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "67/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "68/326, Train_loss: 0.0514 Train_dice: 0.9486\n",
            "69/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "70/326, Train_loss: 0.1212 Train_dice: 0.8788\n",
            "71/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "72/326, Train_loss: 0.0828 Train_dice: 0.9172\n",
            "73/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "74/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "75/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "76/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "77/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "78/326, Train_loss: 0.0554 Train_dice: 0.9446\n",
            "79/326, Train_loss: 0.0788 Train_dice: 0.9212\n",
            "80/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "81/326, Train_loss: 0.0150 Train_dice: 0.9850\n",
            "82/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "83/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "84/326, Train_loss: 0.1168 Train_dice: 0.8832\n",
            "85/326, Train_loss: 0.0452 Train_dice: 0.9548\n",
            "86/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "87/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "88/326, Train_loss: 0.0544 Train_dice: 0.9456\n",
            "89/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "90/326, Train_loss: 0.0207 Train_dice: 0.9793\n",
            "91/326, Train_loss: 0.0383 Train_dice: 0.9617\n",
            "92/326, Train_loss: 0.0394 Train_dice: 0.9606\n",
            "93/326, Train_loss: 0.0894 Train_dice: 0.9106\n",
            "94/326, Train_loss: 0.0543 Train_dice: 0.9457\n",
            "95/326, Train_loss: 0.1253 Train_dice: 0.8747\n",
            "96/326, Train_loss: 0.0391 Train_dice: 0.9609\n",
            "97/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "98/326, Train_loss: 0.0814 Train_dice: 0.9186\n",
            "99/326, Train_loss: 0.0254 Train_dice: 0.9746\n",
            "100/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "101/326, Train_loss: 0.0426 Train_dice: 0.9574\n",
            "102/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "103/326, Train_loss: 0.0308 Train_dice: 0.9692\n",
            "104/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "105/326, Train_loss: 0.0303 Train_dice: 0.9697\n",
            "106/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "107/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "108/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "109/326, Train_loss: 0.0428 Train_dice: 0.9572\n",
            "110/326, Train_loss: 0.0830 Train_dice: 0.9170\n",
            "111/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "112/326, Train_loss: 0.0943 Train_dice: 0.9057\n",
            "113/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "114/326, Train_loss: 0.0455 Train_dice: 0.9545\n",
            "115/326, Train_loss: 0.0643 Train_dice: 0.9357\n",
            "116/326, Train_loss: 0.1260 Train_dice: 0.8740\n",
            "117/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "118/326, Train_loss: 0.1043 Train_dice: 0.8957\n",
            "119/326, Train_loss: 0.0576 Train_dice: 0.9424\n",
            "120/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "121/326, Train_loss: 0.0232 Train_dice: 0.9768\n",
            "122/326, Train_loss: 0.0271 Train_dice: 0.9729\n",
            "123/326, Train_loss: 0.0399 Train_dice: 0.9601\n",
            "124/326, Train_loss: 0.0652 Train_dice: 0.9348\n",
            "125/326, Train_loss: 0.0168 Train_dice: 0.9832\n",
            "126/326, Train_loss: 0.0887 Train_dice: 0.9113\n",
            "127/326, Train_loss: 0.0393 Train_dice: 0.9607\n",
            "128/326, Train_loss: 0.0661 Train_dice: 0.9339\n",
            "129/326, Train_loss: 0.1587 Train_dice: 0.8413\n",
            "130/326, Train_loss: 0.0820 Train_dice: 0.9180\n",
            "131/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "132/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "133/326, Train_loss: 0.0590 Train_dice: 0.9410\n",
            "134/326, Train_loss: 0.1520 Train_dice: 0.8480\n",
            "135/326, Train_loss: 0.0605 Train_dice: 0.9395\n",
            "136/326, Train_loss: 0.0844 Train_dice: 0.9156\n",
            "137/326, Train_loss: 0.0652 Train_dice: 0.9348\n",
            "138/326, Train_loss: 0.0401 Train_dice: 0.9599\n",
            "139/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "140/326, Train_loss: 0.0624 Train_dice: 0.9376\n",
            "141/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "142/326, Train_loss: 0.0899 Train_dice: 0.9101\n",
            "143/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "144/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "145/326, Train_loss: 0.1219 Train_dice: 0.8781\n",
            "146/326, Train_loss: 0.0500 Train_dice: 0.9500\n",
            "147/326, Train_loss: 0.0186 Train_dice: 0.9814\n",
            "148/326, Train_loss: 0.0777 Train_dice: 0.9223\n",
            "149/326, Train_loss: 0.0447 Train_dice: 0.9553\n",
            "150/326, Train_loss: 0.0864 Train_dice: 0.9136\n",
            "151/326, Train_loss: 0.0591 Train_dice: 0.9409\n",
            "152/326, Train_loss: 0.0249 Train_dice: 0.9751\n",
            "153/326, Train_loss: 0.0985 Train_dice: 0.9015\n",
            "154/326, Train_loss: 0.0453 Train_dice: 0.9547\n",
            "155/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "156/326, Train_loss: 0.0500 Train_dice: 0.9500\n",
            "157/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "158/326, Train_loss: 0.1230 Train_dice: 0.8770\n",
            "159/326, Train_loss: 0.0436 Train_dice: 0.9564\n",
            "160/326, Train_loss: 0.0438 Train_dice: 0.9562\n",
            "161/326, Train_loss: 0.0653 Train_dice: 0.9347\n",
            "162/326, Train_loss: 0.0164 Train_dice: 0.9836\n",
            "163/326, Train_loss: 0.0284 Train_dice: 0.9716\n",
            "164/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "165/326, Train_loss: 0.0885 Train_dice: 0.9115\n",
            "166/326, Train_loss: 0.0863 Train_dice: 0.9137\n",
            "167/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "168/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "169/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "170/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "171/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "172/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "173/326, Train_loss: 0.0079 Train_dice: 0.9921\n",
            "174/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "175/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "176/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "177/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "178/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "179/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "180/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "181/326, Train_loss: 0.0122 Train_dice: 0.9878\n",
            "182/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "183/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "184/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "185/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "186/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "187/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "188/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "189/326, Train_loss: 0.0079 Train_dice: 0.9921\n",
            "190/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "191/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "192/326, Train_loss: 0.0343 Train_dice: 0.9657\n",
            "193/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "194/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "195/326, Train_loss: 0.0482 Train_dice: 0.9518\n",
            "196/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "197/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "198/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "199/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "200/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "201/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "202/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "203/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "204/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "205/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "206/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "207/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "208/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "209/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "210/326, Train_loss: 0.0724 Train_dice: 0.9276\n",
            "211/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "212/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "213/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "214/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "215/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "216/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "217/326, Train_loss: 0.0368 Train_dice: 0.9632\n",
            "218/326, Train_loss: 0.0268 Train_dice: 0.9732\n",
            "219/326, Train_loss: 0.0318 Train_dice: 0.9682\n",
            "220/326, Train_loss: 0.0079 Train_dice: 0.9921\n",
            "221/326, Train_loss: 0.0076 Train_dice: 0.9924\n",
            "222/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "223/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "224/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "225/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "226/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "227/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "228/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "229/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "230/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "231/326, Train_loss: 0.0419 Train_dice: 0.9581\n",
            "232/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "233/326, Train_loss: 0.0933 Train_dice: 0.9067\n",
            "234/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "235/326, Train_loss: 0.0777 Train_dice: 0.9223\n",
            "236/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "237/326, Train_loss: 0.0088 Train_dice: 0.9912\n",
            "238/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "239/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "240/326, Train_loss: 0.0615 Train_dice: 0.9385\n",
            "241/326, Train_loss: 0.0612 Train_dice: 0.9388\n",
            "242/326, Train_loss: 0.0561 Train_dice: 0.9439\n",
            "243/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "244/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "245/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "246/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "247/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "248/326, Train_loss: 0.0440 Train_dice: 0.9560\n",
            "249/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "250/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "251/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "252/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "253/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "254/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "255/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "256/326, Train_loss: 0.0633 Train_dice: 0.9367\n",
            "257/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "258/326, Train_loss: 0.1177 Train_dice: 0.8823\n",
            "259/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "260/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "261/326, Train_loss: 0.0798 Train_dice: 0.9202\n",
            "262/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "263/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "264/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "265/326, Train_loss: 0.0362 Train_dice: 0.9638\n",
            "266/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "267/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "268/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "269/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "270/326, Train_loss: 0.0412 Train_dice: 0.9588\n",
            "271/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "272/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "273/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "274/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "275/326, Train_loss: 0.0780 Train_dice: 0.9220\n",
            "276/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "277/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "278/326, Train_loss: 0.0515 Train_dice: 0.9485\n",
            "279/326, Train_loss: 0.0866 Train_dice: 0.9134\n",
            "280/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "281/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "282/326, Train_loss: 0.0504 Train_dice: 0.9496\n",
            "283/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "284/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "285/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "286/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "287/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "288/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "289/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "290/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "291/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "292/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "293/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "294/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "295/326, Train_loss: 0.0556 Train_dice: 0.9444\n",
            "296/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "297/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "298/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "299/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "300/326, Train_loss: 0.0463 Train_dice: 0.9537\n",
            "301/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "302/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "303/326, Train_loss: 0.0573 Train_dice: 0.9427\n",
            "304/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "305/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "306/326, Train_loss: 0.0068 Train_dice: 0.9932\n",
            "307/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "308/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "309/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "310/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "311/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "312/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "313/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "314/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "315/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "316/326, Train_loss: 0.0124 Train_dice: 0.9876\n",
            "317/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "318/326, Train_loss: 0.0126 Train_dice: 0.9874\n",
            "319/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "320/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "321/326, Train_loss: 0.0142 Train_dice: 0.9858\n",
            "322/326, Train_loss: 0.0125 Train_dice: 0.9875\n",
            "323/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "324/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "325/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "326/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "--------------------\n",
            "Epoch_loss: 0.0348\n",
            "Epoch_metric: 0.9652\n",
            "----------\n",
            "epoch 156/250\n",
            "1/326, Train_loss: 0.0611 Train_dice: 0.9389\n",
            "2/326, Train_loss: 0.0893 Train_dice: 0.9107\n",
            "3/326, Train_loss: 0.1069 Train_dice: 0.8931\n",
            "4/326, Train_loss: 0.0165 Train_dice: 0.9835\n",
            "5/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "6/326, Train_loss: 0.0691 Train_dice: 0.9309\n",
            "7/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "8/326, Train_loss: 0.0238 Train_dice: 0.9762\n",
            "9/326, Train_loss: 0.0353 Train_dice: 0.9647\n",
            "10/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "11/326, Train_loss: 0.0808 Train_dice: 0.9192\n",
            "12/326, Train_loss: 0.0881 Train_dice: 0.9119\n",
            "13/326, Train_loss: 0.0465 Train_dice: 0.9535\n",
            "14/326, Train_loss: 0.0204 Train_dice: 0.9796\n",
            "15/326, Train_loss: 0.1197 Train_dice: 0.8803\n",
            "16/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "17/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "18/326, Train_loss: 0.0898 Train_dice: 0.9102\n",
            "19/326, Train_loss: 0.0364 Train_dice: 0.9636\n",
            "20/326, Train_loss: 0.0645 Train_dice: 0.9355\n",
            "21/326, Train_loss: 0.0327 Train_dice: 0.9673\n",
            "22/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "23/326, Train_loss: 0.0293 Train_dice: 0.9707\n",
            "24/326, Train_loss: 0.0763 Train_dice: 0.9237\n",
            "25/326, Train_loss: 0.0484 Train_dice: 0.9516\n",
            "26/326, Train_loss: 0.0193 Train_dice: 0.9807\n",
            "27/326, Train_loss: 0.0313 Train_dice: 0.9687\n",
            "28/326, Train_loss: 0.0172 Train_dice: 0.9828\n",
            "29/326, Train_loss: 0.0443 Train_dice: 0.9557\n",
            "30/326, Train_loss: 0.0278 Train_dice: 0.9722\n",
            "31/326, Train_loss: 0.1033 Train_dice: 0.8967\n",
            "32/326, Train_loss: 0.0670 Train_dice: 0.9330\n",
            "33/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "34/326, Train_loss: 0.0292 Train_dice: 0.9708\n",
            "35/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "36/326, Train_loss: 0.0255 Train_dice: 0.9745\n",
            "37/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "38/326, Train_loss: 0.0717 Train_dice: 0.9283\n",
            "39/326, Train_loss: 0.0522 Train_dice: 0.9478\n",
            "40/326, Train_loss: 0.0180 Train_dice: 0.9820\n",
            "41/326, Train_loss: 0.0366 Train_dice: 0.9634\n",
            "42/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "43/326, Train_loss: 0.0151 Train_dice: 0.9849\n",
            "44/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "45/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "46/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "47/326, Train_loss: 0.0969 Train_dice: 0.9031\n",
            "48/326, Train_loss: 0.0241 Train_dice: 0.9759\n",
            "49/326, Train_loss: 0.0469 Train_dice: 0.9531\n",
            "50/326, Train_loss: 0.0548 Train_dice: 0.9452\n",
            "51/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "52/326, Train_loss: 0.0652 Train_dice: 0.9348\n",
            "53/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "54/326, Train_loss: 0.0345 Train_dice: 0.9655\n",
            "55/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "56/326, Train_loss: 0.0329 Train_dice: 0.9671\n",
            "57/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "58/326, Train_loss: 0.0239 Train_dice: 0.9761\n",
            "59/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "60/326, Train_loss: 0.0287 Train_dice: 0.9713\n",
            "61/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "62/326, Train_loss: 0.0227 Train_dice: 0.9773\n",
            "63/326, Train_loss: 0.0608 Train_dice: 0.9392\n",
            "64/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "65/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "66/326, Train_loss: 0.0539 Train_dice: 0.9461\n",
            "67/326, Train_loss: 0.0192 Train_dice: 0.9808\n",
            "68/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "69/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "70/326, Train_loss: 0.1173 Train_dice: 0.8827\n",
            "71/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "72/326, Train_loss: 0.0797 Train_dice: 0.9203\n",
            "73/326, Train_loss: 0.0338 Train_dice: 0.9662\n",
            "74/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "75/326, Train_loss: 0.0321 Train_dice: 0.9679\n",
            "76/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "77/326, Train_loss: 0.0737 Train_dice: 0.9263\n",
            "78/326, Train_loss: 0.0534 Train_dice: 0.9466\n",
            "79/326, Train_loss: 0.0763 Train_dice: 0.9237\n",
            "80/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "81/326, Train_loss: 0.0148 Train_dice: 0.9852\n",
            "82/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "83/326, Train_loss: 0.0530 Train_dice: 0.9470\n",
            "84/326, Train_loss: 0.1145 Train_dice: 0.8855\n",
            "85/326, Train_loss: 0.0437 Train_dice: 0.9563\n",
            "86/326, Train_loss: 0.0216 Train_dice: 0.9784\n",
            "87/326, Train_loss: 0.0260 Train_dice: 0.9740\n",
            "88/326, Train_loss: 0.0532 Train_dice: 0.9468\n",
            "89/326, Train_loss: 0.0182 Train_dice: 0.9818\n",
            "90/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "91/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "92/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "93/326, Train_loss: 0.0870 Train_dice: 0.9130\n",
            "94/326, Train_loss: 0.0526 Train_dice: 0.9474\n",
            "95/326, Train_loss: 0.1213 Train_dice: 0.8787\n",
            "96/326, Train_loss: 0.0361 Train_dice: 0.9639\n",
            "97/326, Train_loss: 0.0296 Train_dice: 0.9704\n",
            "98/326, Train_loss: 0.0774 Train_dice: 0.9226\n",
            "99/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "100/326, Train_loss: 0.0226 Train_dice: 0.9774\n",
            "101/326, Train_loss: 0.0400 Train_dice: 0.9600\n",
            "102/326, Train_loss: 0.0328 Train_dice: 0.9672\n",
            "103/326, Train_loss: 0.0298 Train_dice: 0.9702\n",
            "104/326, Train_loss: 0.0435 Train_dice: 0.9565\n",
            "105/326, Train_loss: 0.0294 Train_dice: 0.9706\n",
            "106/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "107/326, Train_loss: 0.0410 Train_dice: 0.9590\n",
            "108/326, Train_loss: 0.0163 Train_dice: 0.9837\n",
            "109/326, Train_loss: 0.0397 Train_dice: 0.9603\n",
            "110/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "111/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "112/326, Train_loss: 0.0911 Train_dice: 0.9089\n",
            "113/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "114/326, Train_loss: 0.0423 Train_dice: 0.9577\n",
            "115/326, Train_loss: 0.0601 Train_dice: 0.9399\n",
            "116/326, Train_loss: 0.1227 Train_dice: 0.8773\n",
            "117/326, Train_loss: 0.0371 Train_dice: 0.9629\n",
            "118/326, Train_loss: 0.0990 Train_dice: 0.9010\n",
            "119/326, Train_loss: 0.0540 Train_dice: 0.9460\n",
            "120/326, Train_loss: 0.0307 Train_dice: 0.9693\n",
            "121/326, Train_loss: 0.0214 Train_dice: 0.9786\n",
            "122/326, Train_loss: 0.0256 Train_dice: 0.9744\n",
            "123/326, Train_loss: 0.0373 Train_dice: 0.9627\n",
            "124/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "125/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "126/326, Train_loss: 0.0847 Train_dice: 0.9153\n",
            "127/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "128/326, Train_loss: 0.0656 Train_dice: 0.9344\n",
            "129/326, Train_loss: 0.1548 Train_dice: 0.8452\n",
            "130/326, Train_loss: 0.0824 Train_dice: 0.9176\n",
            "131/326, Train_loss: 0.0203 Train_dice: 0.9797\n",
            "132/326, Train_loss: 0.0758 Train_dice: 0.9242\n",
            "133/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "134/326, Train_loss: 0.1454 Train_dice: 0.8546\n",
            "135/326, Train_loss: 0.0564 Train_dice: 0.9436\n",
            "136/326, Train_loss: 0.0785 Train_dice: 0.9215\n",
            "137/326, Train_loss: 0.0560 Train_dice: 0.9440\n",
            "138/326, Train_loss: 0.0347 Train_dice: 0.9653\n",
            "139/326, Train_loss: 0.0160 Train_dice: 0.9840\n",
            "140/326, Train_loss: 0.0581 Train_dice: 0.9419\n",
            "141/326, Train_loss: 0.0317 Train_dice: 0.9683\n",
            "142/326, Train_loss: 0.0868 Train_dice: 0.9132\n",
            "143/326, Train_loss: 0.0225 Train_dice: 0.9775\n",
            "144/326, Train_loss: 0.0507 Train_dice: 0.9493\n",
            "145/326, Train_loss: 0.1220 Train_dice: 0.8780\n",
            "146/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "147/326, Train_loss: 0.0187 Train_dice: 0.9813\n",
            "148/326, Train_loss: 0.0766 Train_dice: 0.9234\n",
            "149/326, Train_loss: 0.0470 Train_dice: 0.9530\n",
            "150/326, Train_loss: 0.0910 Train_dice: 0.9090\n",
            "151/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "152/326, Train_loss: 0.0244 Train_dice: 0.9756\n",
            "153/326, Train_loss: 0.0967 Train_dice: 0.9033\n",
            "154/326, Train_loss: 0.0432 Train_dice: 0.9568\n",
            "155/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "156/326, Train_loss: 0.0476 Train_dice: 0.9524\n",
            "157/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "158/326, Train_loss: 0.1195 Train_dice: 0.8805\n",
            "159/326, Train_loss: 0.0387 Train_dice: 0.9613\n",
            "160/326, Train_loss: 0.0381 Train_dice: 0.9619\n",
            "161/326, Train_loss: 0.0578 Train_dice: 0.9422\n",
            "162/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "163/326, Train_loss: 0.0237 Train_dice: 0.9763\n",
            "164/326, Train_loss: 0.0159 Train_dice: 0.9841\n",
            "165/326, Train_loss: 0.0803 Train_dice: 0.9197\n",
            "166/326, Train_loss: 0.0831 Train_dice: 0.9169\n",
            "167/326, Train_loss: 0.0117 Train_dice: 0.9883\n",
            "168/326, Train_loss: 0.0201 Train_dice: 0.9799\n",
            "169/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "170/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "171/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "172/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "173/326, Train_loss: 0.0068 Train_dice: 0.9932\n",
            "174/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "175/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "176/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "177/326, Train_loss: 0.0075 Train_dice: 0.9925\n",
            "178/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "179/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "180/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "181/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "182/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "183/326, Train_loss: 0.0473 Train_dice: 0.9527\n",
            "184/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "185/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "186/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "187/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "188/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "189/326, Train_loss: 0.0080 Train_dice: 0.9920\n",
            "190/326, Train_loss: 0.0339 Train_dice: 0.9661\n",
            "191/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "192/326, Train_loss: 0.0333 Train_dice: 0.9667\n",
            "193/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "194/326, Train_loss: 0.0087 Train_dice: 0.9913\n",
            "195/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "196/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "197/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "198/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "199/326, Train_loss: 0.0235 Train_dice: 0.9765\n",
            "200/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "201/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "202/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "203/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "204/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "205/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "206/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "207/326, Train_loss: 0.0105 Train_dice: 0.9895\n",
            "208/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "209/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "210/326, Train_loss: 0.0666 Train_dice: 0.9334\n",
            "211/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "212/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "213/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "214/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "215/326, Train_loss: 0.0082 Train_dice: 0.9918\n",
            "216/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "217/326, Train_loss: 0.0342 Train_dice: 0.9658\n",
            "218/326, Train_loss: 0.0263 Train_dice: 0.9737\n",
            "219/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "220/326, Train_loss: 0.0080 Train_dice: 0.9920\n",
            "221/326, Train_loss: 0.0071 Train_dice: 0.9929\n",
            "222/326, Train_loss: 0.0166 Train_dice: 0.9834\n",
            "223/326, Train_loss: 0.0123 Train_dice: 0.9877\n",
            "224/326, Train_loss: 0.0090 Train_dice: 0.9910\n",
            "225/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "226/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "227/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "228/326, Train_loss: 0.0098 Train_dice: 0.9902\n",
            "229/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "230/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "231/326, Train_loss: 0.0406 Train_dice: 0.9594\n",
            "232/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "233/326, Train_loss: 0.0903 Train_dice: 0.9097\n",
            "234/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "235/326, Train_loss: 0.0762 Train_dice: 0.9238\n",
            "236/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "237/326, Train_loss: 0.0084 Train_dice: 0.9916\n",
            "238/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "239/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "240/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "241/326, Train_loss: 0.0577 Train_dice: 0.9423\n",
            "242/326, Train_loss: 0.0552 Train_dice: 0.9448\n",
            "243/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "244/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "245/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "246/326, Train_loss: 0.0094 Train_dice: 0.9906\n",
            "247/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "248/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "249/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "250/326, Train_loss: 0.0087 Train_dice: 0.9913\n",
            "251/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "252/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "253/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "254/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "255/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "256/326, Train_loss: 0.0574 Train_dice: 0.9426\n",
            "257/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "258/326, Train_loss: 0.1120 Train_dice: 0.8880\n",
            "259/326, Train_loss: 0.0267 Train_dice: 0.9733\n",
            "260/326, Train_loss: 0.0100 Train_dice: 0.9900\n",
            "261/326, Train_loss: 0.0795 Train_dice: 0.9205\n",
            "262/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "263/326, Train_loss: 0.0223 Train_dice: 0.9777\n",
            "264/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "265/326, Train_loss: 0.0335 Train_dice: 0.9665\n",
            "266/326, Train_loss: 0.0247 Train_dice: 0.9753\n",
            "267/326, Train_loss: 0.0372 Train_dice: 0.9628\n",
            "268/326, Train_loss: 0.0319 Train_dice: 0.9681\n",
            "269/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "270/326, Train_loss: 0.0430 Train_dice: 0.9570\n",
            "271/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "272/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "273/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "274/326, Train_loss: 0.0265 Train_dice: 0.9735\n",
            "275/326, Train_loss: 0.0729 Train_dice: 0.9271\n",
            "276/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "277/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "278/326, Train_loss: 0.0479 Train_dice: 0.9521\n",
            "279/326, Train_loss: 0.0813 Train_dice: 0.9187\n",
            "280/326, Train_loss: 0.0403 Train_dice: 0.9597\n",
            "281/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "282/326, Train_loss: 0.0454 Train_dice: 0.9546\n",
            "283/326, Train_loss: 0.0253 Train_dice: 0.9747\n",
            "284/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "285/326, Train_loss: 0.0273 Train_dice: 0.9727\n",
            "286/326, Train_loss: 0.0108 Train_dice: 0.9892\n",
            "287/326, Train_loss: 0.0421 Train_dice: 0.9579\n",
            "288/326, Train_loss: 0.0083 Train_dice: 0.9917\n",
            "289/326, Train_loss: 0.0101 Train_dice: 0.9899\n",
            "290/326, Train_loss: 0.0102 Train_dice: 0.9898\n",
            "291/326, Train_loss: 0.0113 Train_dice: 0.9887\n",
            "292/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "293/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "294/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "295/326, Train_loss: 0.0569 Train_dice: 0.9431\n",
            "296/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "297/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "298/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "299/326, Train_loss: 0.0110 Train_dice: 0.9890\n",
            "300/326, Train_loss: 0.0467 Train_dice: 0.9533\n",
            "301/326, Train_loss: 0.0112 Train_dice: 0.9888\n",
            "302/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "303/326, Train_loss: 0.0566 Train_dice: 0.9434\n",
            "304/326, Train_loss: 0.0092 Train_dice: 0.9908\n",
            "305/326, Train_loss: 0.0129 Train_dice: 0.9871\n",
            "306/326, Train_loss: 0.0073 Train_dice: 0.9927\n",
            "307/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "308/326, Train_loss: 0.0115 Train_dice: 0.9885\n",
            "309/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "310/326, Train_loss: 0.0086 Train_dice: 0.9914\n",
            "311/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "312/326, Train_loss: 0.0131 Train_dice: 0.9869\n",
            "313/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "314/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "315/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "316/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "317/326, Train_loss: 0.0135 Train_dice: 0.9865\n",
            "318/326, Train_loss: 0.0128 Train_dice: 0.9872\n",
            "319/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "320/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "321/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "322/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "323/326, Train_loss: 0.0109 Train_dice: 0.9891\n",
            "324/326, Train_loss: 0.0103 Train_dice: 0.9897\n",
            "325/326, Train_loss: 0.0095 Train_dice: 0.9905\n",
            "326/326, Train_loss: 0.0119 Train_dice: 0.9881\n",
            "--------------------\n",
            "Epoch_loss: 0.0336\n",
            "Epoch_metric: 0.9664\n",
            "----------\n",
            "epoch 157/250\n",
            "1/326, Train_loss: 0.0575 Train_dice: 0.9425\n",
            "2/326, Train_loss: 0.0858 Train_dice: 0.9142\n",
            "3/326, Train_loss: 0.1023 Train_dice: 0.8977\n",
            "4/326, Train_loss: 0.0162 Train_dice: 0.9838\n",
            "5/326, Train_loss: 0.0188 Train_dice: 0.9812\n",
            "6/326, Train_loss: 0.0660 Train_dice: 0.9340\n",
            "7/326, Train_loss: 0.0316 Train_dice: 0.9684\n",
            "8/326, Train_loss: 0.0236 Train_dice: 0.9764\n",
            "9/326, Train_loss: 0.0334 Train_dice: 0.9666\n",
            "10/326, Train_loss: 0.0240 Train_dice: 0.9760\n",
            "11/326, Train_loss: 0.0778 Train_dice: 0.9222\n",
            "12/326, Train_loss: 0.0845 Train_dice: 0.9155\n",
            "13/326, Train_loss: 0.0458 Train_dice: 0.9542\n",
            "14/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "15/326, Train_loss: 0.1154 Train_dice: 0.8846\n",
            "16/326, Train_loss: 0.0359 Train_dice: 0.9641\n",
            "17/326, Train_loss: 0.0184 Train_dice: 0.9816\n",
            "18/326, Train_loss: 0.0863 Train_dice: 0.9137\n",
            "19/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "20/326, Train_loss: 0.0622 Train_dice: 0.9378\n",
            "21/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "22/326, Train_loss: 0.0336 Train_dice: 0.9664\n",
            "23/326, Train_loss: 0.0280 Train_dice: 0.9720\n",
            "24/326, Train_loss: 0.0720 Train_dice: 0.9280\n",
            "25/326, Train_loss: 0.0463 Train_dice: 0.9537\n",
            "26/326, Train_loss: 0.0191 Train_dice: 0.9809\n",
            "27/326, Train_loss: 0.0295 Train_dice: 0.9705\n",
            "28/326, Train_loss: 0.0169 Train_dice: 0.9831\n",
            "29/326, Train_loss: 0.0431 Train_dice: 0.9569\n",
            "30/326, Train_loss: 0.0262 Train_dice: 0.9738\n",
            "31/326, Train_loss: 0.0999 Train_dice: 0.9001\n",
            "32/326, Train_loss: 0.0631 Train_dice: 0.9369\n",
            "33/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "34/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "35/326, Train_loss: 0.0297 Train_dice: 0.9703\n",
            "36/326, Train_loss: 0.0243 Train_dice: 0.9757\n",
            "37/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "38/326, Train_loss: 0.0694 Train_dice: 0.9306\n",
            "39/326, Train_loss: 0.0496 Train_dice: 0.9504\n",
            "40/326, Train_loss: 0.0167 Train_dice: 0.9833\n",
            "41/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "42/326, Train_loss: 0.0304 Train_dice: 0.9696\n",
            "43/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "44/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "45/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "46/326, Train_loss: 0.0153 Train_dice: 0.9847\n",
            "47/326, Train_loss: 0.0950 Train_dice: 0.9050\n",
            "48/326, Train_loss: 0.0229 Train_dice: 0.9771\n",
            "49/326, Train_loss: 0.0450 Train_dice: 0.9550\n",
            "50/326, Train_loss: 0.0529 Train_dice: 0.9471\n",
            "51/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "52/326, Train_loss: 0.0629 Train_dice: 0.9371\n",
            "53/326, Train_loss: 0.0137 Train_dice: 0.9863\n",
            "54/326, Train_loss: 0.0323 Train_dice: 0.9677\n",
            "55/326, Train_loss: 0.0261 Train_dice: 0.9739\n",
            "56/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "57/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "58/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "59/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "60/326, Train_loss: 0.0272 Train_dice: 0.9728\n",
            "61/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "62/326, Train_loss: 0.0221 Train_dice: 0.9779\n",
            "63/326, Train_loss: 0.0582 Train_dice: 0.9418\n",
            "64/326, Train_loss: 0.0266 Train_dice: 0.9734\n",
            "65/326, Train_loss: 0.0157 Train_dice: 0.9843\n",
            "66/326, Train_loss: 0.0521 Train_dice: 0.9479\n",
            "67/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "68/326, Train_loss: 0.0494 Train_dice: 0.9506\n",
            "69/326, Train_loss: 0.0258 Train_dice: 0.9742\n",
            "70/326, Train_loss: 0.1137 Train_dice: 0.8863\n",
            "71/326, Train_loss: 0.0141 Train_dice: 0.9859\n",
            "72/326, Train_loss: 0.0783 Train_dice: 0.9217\n",
            "73/326, Train_loss: 0.0331 Train_dice: 0.9669\n",
            "74/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "75/326, Train_loss: 0.0306 Train_dice: 0.9694\n",
            "76/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "77/326, Train_loss: 0.0719 Train_dice: 0.9281\n",
            "78/326, Train_loss: 0.0517 Train_dice: 0.9483\n",
            "79/326, Train_loss: 0.0734 Train_dice: 0.9266\n",
            "80/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "81/326, Train_loss: 0.0143 Train_dice: 0.9857\n",
            "82/326, Train_loss: 0.0222 Train_dice: 0.9778\n",
            "83/326, Train_loss: 0.0511 Train_dice: 0.9489\n",
            "84/326, Train_loss: 0.1096 Train_dice: 0.8904\n",
            "85/326, Train_loss: 0.0415 Train_dice: 0.9585\n",
            "86/326, Train_loss: 0.0208 Train_dice: 0.9792\n",
            "87/326, Train_loss: 0.0250 Train_dice: 0.9750\n",
            "88/326, Train_loss: 0.0519 Train_dice: 0.9481\n",
            "89/326, Train_loss: 0.0181 Train_dice: 0.9819\n",
            "90/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "91/326, Train_loss: 0.0375 Train_dice: 0.9625\n",
            "92/326, Train_loss: 0.0384 Train_dice: 0.9616\n",
            "93/326, Train_loss: 0.0854 Train_dice: 0.9146\n",
            "94/326, Train_loss: 0.0516 Train_dice: 0.9484\n",
            "95/326, Train_loss: 0.1195 Train_dice: 0.8805\n",
            "96/326, Train_loss: 0.0352 Train_dice: 0.9648\n",
            "97/326, Train_loss: 0.0291 Train_dice: 0.9709\n",
            "98/326, Train_loss: 0.0757 Train_dice: 0.9243\n",
            "99/326, Train_loss: 0.0230 Train_dice: 0.9770\n",
            "100/326, Train_loss: 0.0218 Train_dice: 0.9782\n",
            "101/326, Train_loss: 0.0382 Train_dice: 0.9618\n",
            "102/326, Train_loss: 0.0312 Train_dice: 0.9688\n",
            "103/326, Train_loss: 0.0282 Train_dice: 0.9718\n",
            "104/326, Train_loss: 0.0422 Train_dice: 0.9578\n",
            "105/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "106/326, Train_loss: 0.0369 Train_dice: 0.9631\n",
            "107/326, Train_loss: 0.0390 Train_dice: 0.9610\n",
            "108/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "109/326, Train_loss: 0.0380 Train_dice: 0.9620\n",
            "110/326, Train_loss: 0.0761 Train_dice: 0.9239\n",
            "111/326, Train_loss: 0.0245 Train_dice: 0.9755\n",
            "112/326, Train_loss: 0.0875 Train_dice: 0.9125\n",
            "113/326, Train_loss: 0.0290 Train_dice: 0.9710\n",
            "114/326, Train_loss: 0.0407 Train_dice: 0.9593\n",
            "115/326, Train_loss: 0.0571 Train_dice: 0.9429\n",
            "116/326, Train_loss: 0.1185 Train_dice: 0.8815\n",
            "117/326, Train_loss: 0.0356 Train_dice: 0.9644\n",
            "118/326, Train_loss: 0.0958 Train_dice: 0.9042\n",
            "119/326, Train_loss: 0.0503 Train_dice: 0.9497\n",
            "120/326, Train_loss: 0.0285 Train_dice: 0.9715\n",
            "121/326, Train_loss: 0.0196 Train_dice: 0.9804\n",
            "122/326, Train_loss: 0.0233 Train_dice: 0.9767\n",
            "123/326, Train_loss: 0.0344 Train_dice: 0.9656\n",
            "124/326, Train_loss: 0.0589 Train_dice: 0.9411\n",
            "125/326, Train_loss: 0.0156 Train_dice: 0.9844\n",
            "126/326, Train_loss: 0.0793 Train_dice: 0.9207\n",
            "127/326, Train_loss: 0.0376 Train_dice: 0.9624\n",
            "128/326, Train_loss: 0.0635 Train_dice: 0.9365\n",
            "129/326, Train_loss: 0.1480 Train_dice: 0.8520\n",
            "130/326, Train_loss: 0.0805 Train_dice: 0.9195\n",
            "131/326, Train_loss: 0.0202 Train_dice: 0.9798\n",
            "132/326, Train_loss: 0.0756 Train_dice: 0.9244\n",
            "133/326, Train_loss: 0.0557 Train_dice: 0.9443\n",
            "134/326, Train_loss: 0.1435 Train_dice: 0.8565\n",
            "135/326, Train_loss: 0.0559 Train_dice: 0.9441\n",
            "136/326, Train_loss: 0.0767 Train_dice: 0.9233\n",
            "137/326, Train_loss: 0.0518 Train_dice: 0.9482\n",
            "138/326, Train_loss: 0.0320 Train_dice: 0.9680\n",
            "139/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "140/326, Train_loss: 0.0535 Train_dice: 0.9465\n",
            "141/326, Train_loss: 0.0281 Train_dice: 0.9719\n",
            "142/326, Train_loss: 0.0782 Train_dice: 0.9218\n",
            "143/326, Train_loss: 0.0199 Train_dice: 0.9801\n",
            "144/326, Train_loss: 0.0457 Train_dice: 0.9543\n",
            "145/326, Train_loss: 0.1116 Train_dice: 0.8884\n",
            "146/326, Train_loss: 0.0491 Train_dice: 0.9509\n",
            "147/326, Train_loss: 0.0176 Train_dice: 0.9824\n",
            "148/326, Train_loss: 0.0728 Train_dice: 0.9272\n",
            "149/326, Train_loss: 0.0462 Train_dice: 0.9538\n",
            "150/326, Train_loss: 0.0845 Train_dice: 0.9155\n",
            "151/326, Train_loss: 0.0570 Train_dice: 0.9430\n",
            "152/326, Train_loss: 0.0242 Train_dice: 0.9758\n",
            "153/326, Train_loss: 0.0996 Train_dice: 0.9004\n",
            "154/326, Train_loss: 0.0461 Train_dice: 0.9539\n",
            "155/326, Train_loss: 0.0270 Train_dice: 0.9730\n",
            "156/326, Train_loss: 0.0493 Train_dice: 0.9507\n",
            "157/326, Train_loss: 0.0195 Train_dice: 0.9805\n",
            "158/326, Train_loss: 0.1154 Train_dice: 0.8846\n",
            "159/326, Train_loss: 0.0358 Train_dice: 0.9642\n",
            "160/326, Train_loss: 0.0349 Train_dice: 0.9651\n",
            "161/326, Train_loss: 0.0547 Train_dice: 0.9453\n",
            "162/326, Train_loss: 0.0136 Train_dice: 0.9864\n",
            "163/326, Train_loss: 0.0185 Train_dice: 0.9815\n",
            "164/326, Train_loss: 0.0118 Train_dice: 0.9882\n",
            "165/326, Train_loss: 0.0765 Train_dice: 0.9235\n",
            "166/326, Train_loss: 0.0772 Train_dice: 0.9228\n",
            "167/326, Train_loss: 0.0146 Train_dice: 0.9854\n",
            "168/326, Train_loss: 0.0178 Train_dice: 0.9822\n",
            "169/326, Train_loss: 0.0116 Train_dice: 0.9884\n",
            "170/326, Train_loss: 0.0138 Train_dice: 0.9862\n",
            "171/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "172/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "173/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "174/326, Train_loss: 0.0149 Train_dice: 0.9851\n",
            "175/326, Train_loss: 0.0145 Train_dice: 0.9855\n",
            "176/326, Train_loss: 0.0127 Train_dice: 0.9873\n",
            "177/326, Train_loss: 0.0080 Train_dice: 0.9920\n",
            "178/326, Train_loss: 0.0121 Train_dice: 0.9879\n",
            "179/326, Train_loss: 0.0114 Train_dice: 0.9886\n",
            "180/326, Train_loss: 0.0089 Train_dice: 0.9911\n",
            "181/326, Train_loss: 0.0104 Train_dice: 0.9896\n",
            "182/326, Train_loss: 0.0081 Train_dice: 0.9919\n",
            "183/326, Train_loss: 0.0474 Train_dice: 0.9526\n",
            "184/326, Train_loss: 0.0083 Train_dice: 0.9917\n",
            "185/326, Train_loss: 0.0093 Train_dice: 0.9907\n",
            "186/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "187/326, Train_loss: 0.0107 Train_dice: 0.9893\n",
            "188/326, Train_loss: 0.0097 Train_dice: 0.9903\n",
            "189/326, Train_loss: 0.0079 Train_dice: 0.9921\n",
            "190/326, Train_loss: 0.0324 Train_dice: 0.9676\n",
            "191/326, Train_loss: 0.0091 Train_dice: 0.9909\n",
            "192/326, Train_loss: 0.0315 Train_dice: 0.9685\n",
            "193/326, Train_loss: 0.0111 Train_dice: 0.9889\n",
            "194/326, Train_loss: 0.0106 Train_dice: 0.9894\n",
            "195/326, Train_loss: 0.0459 Train_dice: 0.9541\n",
            "196/326, Train_loss: 0.0099 Train_dice: 0.9901\n",
            "197/326, Train_loss: 0.0096 Train_dice: 0.9904\n",
            "198/326, Train_loss: 0.0106 Train_dice: 0.9894\n"
          ]
        }
      ],
      "source": [
        "train(unet, data_in, loss_function, optimizer, 250, model_dir, test_interval= 10,start_from=128, load_from=OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esD5sFOHOxBX"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first\n",
        "from monai.transforms import(\n",
        "    Activations,\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "from monai.inferers import sliding_window_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "WoUJI-4IOxBY",
        "outputId": "65739015-bbe4-41d0-a393-3de16acad040"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from utils.view import  plt_metrices\n",
        "\n",
        "path = OUT_DIR\n",
        "if (os.path.exists(path)):\n",
        "    plt_metrices(path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "packages",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
