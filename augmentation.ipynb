{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR =       \"./\"\n",
    "DATA_DIR =       \"./PROSTATEx_masks/Files/prostate/\"\n",
    "OUT_DIR =        \"./aug_results/prostate/\"\n",
    "SLICED_OUT_DIR = \"./data/sliced/prostate/\"\n",
    "AUG_OUT_DIR = \"./data/augmented_test/prostate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "import os\n",
    "\n",
    "from monai.utils import first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(path):\n",
    "  f = open( path + 'config.json')\n",
    "  jdata = json.load(f)\n",
    "  f.close()\n",
    "  return jdata[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_path(SLICED_OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "\n",
    "import elasticdeform \n",
    "from skimage.util import random_noise\n",
    "import scipy\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import nibabel as nib\n",
    "#import torchio as tio\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import shift\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hFlipRotate(image, label):\n",
    "    angle =  random.uniform(-5, 5)\n",
    "    imgvol = np.array( image.dataobj )\n",
    "    lblvol = np.array( label.dataobj )\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(imgvol)\n",
    "    lbl = np.fliplr(lblvol)\n",
    "    \n",
    "    #Rotate\n",
    "    img = ndimage.rotate(img, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
    "    \n",
    "    image = nib.Nifti1Image ( img, image.affine )\n",
    "    label = nib.Nifti1Image ( lbl, label.affine )\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hFlipRotateZoom(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(img)\n",
    "    lbl = np.fliplr(lbl)\n",
    "\n",
    "    # zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    zoomed_img = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    zoomed_lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(zoomed_img, image.affine)\n",
    "    label = nib.Nifti1Image(zoomed_lbl, label.affine)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def hFlipShear(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    shear = random.uniform(-0.2,0.2)\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(imgvol)\n",
    "    lbl = np.fliplr(lblvol)\n",
    "\n",
    "    # apply shear transformation\n",
    "    matrix = np.array([[1, shear, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    img = scipy.ndimage.affine_transform(img, matrix)\n",
    "    lbl = scipy.ndimage.affine_transform(lbl, matrix)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_rotate_noise(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes\n",
    "    flip_axes = tuple(np.random.choice([-1, 1], size=image.ndim, replace=True))\n",
    "    img = np.flip(imgvol, axis=flip_axes)\n",
    "    lbl = np.flip(lblvol, axis=flip_axes)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
    "\n",
    "    # Add noise\n",
    "    # Gaussian noise\n",
    "    img = random_noise(img, mode='gaussian', var=0.000001, clip=False)\n",
    "    # Salt & Pepper noise\n",
    "    img = random_noise(img, mode='s&p', salt_vs_pepper=0.5, amount=0.0000005, clip=False)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "def hFlipShearTrans(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    shear = random.uniform(-0.2,0.2)\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10), random.uniform(-10,10))\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(imgvol)\n",
    "    lbl = np.fliplr(lblvol)\n",
    "\n",
    "    # apply shear transformation\n",
    "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, translate[2]], [0, 0, 0, 1]])\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hFlipRotateNoise(image, label):\n",
    "    angle =  random.uniform(-5, 5)\n",
    "    imgvol = np.array( image.dataobj )\n",
    "    lblvol = np.array( label.dataobj )\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(imgvol)\n",
    "    lbl = np.fliplr(lblvol)\n",
    "    \n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lbl, angle, reshape=False)\n",
    "    \n",
    "    # Noise\n",
    "    # # Gaussian noise\n",
    "    # img = random_noise(imgvol, mode='gaussian', var=0.0000001, clip=False)\n",
    "    # # Salt & Pepper noise\n",
    "    # img = random_noise(img, mode='s&p',salt_vs_pepper=0.5, amount=0.00000005, clip=False)\n",
    "\n",
    "\n",
    "    \n",
    "    image = nib.Nifti1Image ( img, image.affine )\n",
    "    label = nib.Nifti1Image ( lblvol, label.affine )\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_rotate_zoom_translate(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
    "    img = np.flip(img, axis=flip_axes)\n",
    "    lbl = np.flip(lbl, axis=flip_axes)\n",
    "\n",
    "    # zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    # Translate\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_rotate_zoom_shear_translate(image, label):\n",
    "    \n",
    "    angle = random.uniform(-5, 5)\n",
    "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "    shear = random.uniform(-0.2,0.2)\n",
    "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    \n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
    "    img = np.flip(img, axis=flip_axes)\n",
    "    lbl = np.flip(lbl, axis=flip_axes)\n",
    "\n",
    "    # zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    # Translate\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_rotate_translate_deform(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
    "    sigma = random.choice([2, 3])\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
    "    img = np.flip(img, axis=flip_axes)\n",
    "    lbl = np.flip(lbl, axis=flip_axes)\n",
    "\n",
    "    # zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    # Elastic deformation\n",
    "    [img, lbl] = elasticdeform.deform_random_grid([img, lbl], sigma=sigma, axis=[(0, 1), (0, 1)], order=[1, 0], mode='constant')\n",
    "    \n",
    "\n",
    "\n",
    "    # Translate\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from skimage.exposure import adjust_gamma, rescale_intensity\n",
    "\n",
    "def random_flip_rotate_zoom_translate_brightness(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    flip_axes = [i for i in range(2) if i != 2 and np.random.choice([0, 1]) == 1]\n",
    "    translate = (random.uniform(-10, 10), random.uniform(-10, 10))\n",
    "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
    "    img = np.flip(img, axis=flip_axes)\n",
    "    lbl = np.flip(lbl, axis=flip_axes)\n",
    "\n",
    "    # Zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    img = ndimage.zoom(img, zoom_factor, order=1)\n",
    "    lbl = ndimage.zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    # Translate\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    # Brightness\n",
    "    gamma = random.uniform(0.8, 1.2)\n",
    "    min_value = np.min(img)\n",
    "    img = img - min_value\n",
    "    img = adjust_gamma(img, gamma)\n",
    "\n",
    "    # Contrast\n",
    "    low = np.percentile(img, 10)\n",
    "    high = np.percentile(img, 98)\n",
    "    img = rescale_intensity(img, in_range=(low, high))\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "def hFlipRotateShearTrans(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    shear = random.uniform(-0.2,0.2)\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(img)\n",
    "    lbl = np.fliplr(lbl)\n",
    "\n",
    "\n",
    "    # apply shear transformation\n",
    "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "import elasticdeform\n",
    "from scipy import ndimage\n",
    "\n",
    "def hFlipRotateTranslateElasticDeform(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    shear = random.uniform(-0.2,0.2)\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(imgvol, angle, reshape=False)\n",
    "    lbl = ndimage.rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # horizontal flip\n",
    "    img = np.fliplr(img)\n",
    "    lbl = np.fliplr(lbl)\n",
    "\n",
    "\n",
    "    # apply shear transformation\n",
    "    matrix = np.array([[1, shear, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    img = affine_transform(img, matrix, order=1)\n",
    "    lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    # Elastic deformation\n",
    "    sigma = random.choice([2, 3])\n",
    "    print(sigma)\n",
    "    # img_deformed = elasticdeform.deform_random_grid(img, sigma=sigma, order=3, axis=(0, 1, 2))\n",
    "    # lbl_deformed = elasticdeform.deform_random_grid(lbl, sigma=sigma, order=0, axis=(0, 1, 2))\n",
    "    [img_deformed, lbl_deformed] = elasticdeform.deform_random_grid([img, lbl], sigma=sigma, axis=[(0, 1), (0, 1)], order=[1, 0], mode='constant')\n",
    "    \n",
    "\n",
    "    image = nib.Nifti1Image(img_deformed, image.affine)\n",
    "    label = nib.Nifti1Image(lbl_deformed, label.affine)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Augmentation.augmentation import changeContrast, vFlipRotate, hFlipRotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image, label from orignal image\n",
    "imagea =nib.load(data[0][\"image\"])\n",
    "labela =nib.load(data[0][\"label\"])\n",
    "\n",
    "imagea, labela = imagea.get_fdata(), labela.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 384, 16) (384, 384, 16)\n"
     ]
    }
   ],
   "source": [
    "# first image, label from orignal image\n",
    "imagea =nib.load(data[0][\"image\"])\n",
    "labela =nib.load(data[0][\"label\"])\n",
    "print(imagea.shape,labela.shape)\n",
    "imagea, labela = random_flip_rotate_zoom_translate_brightness(imagea, labela)\n",
    "imagea, labela = imagea.get_fdata(), labela.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize the data\n",
    "def explore_3dimage(layer):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    channel = 2\n",
    "    # plt.imshow(image11[0,0,:,:,layer], cmap='gray');\n",
    "    # plt.title('Explore Layers of Prostate MRI', fontsize=20)\n",
    "    # plt.axis('off')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "    ax[0].imshow(imagea[:,:,layer], cmap='gray')\n",
    "    ax[0].set_title(f\"Image\", fontsize=15)\n",
    "    ax[0].axis('off');\n",
    "\n",
    "    ax[1].imshow(labela[:,:,layer])\n",
    "    ax[1].axis('off');\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf88925314f48e285bfda6128cf58e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='layer', max=15), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3dimage(layer)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the preprocessed image, label\n",
    "interact(explore_3dimage, layer=(0, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image, label from orignal image\n",
    "image =nib.load(data[0][\"image\"])\n",
    "label =nib.load(data[0][\"label\"])\n",
    "\n",
    "image, label = image.get_fdata(), label.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to visualize the data\n",
    "def explore_3dimage(layer):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    channel = 2\n",
    "    # plt.imshow(image11[0,0,:,:,layer], cmap='gray');\n",
    "    # plt.title('Explore Layers of Prostate MRI', fontsize=20)\n",
    "    # plt.axis('off')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5))\n",
    "\n",
    "    ax[0].imshow(image[:,:,layer], cmap='gray')\n",
    "    ax[0].set_title(f\"Image\", fontsize=15)\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(label[:,:,layer])\n",
    "    ax[1].axis('off')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0034d68d18f42a79dad9485eeca7d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='layer', max=15), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3dimage(layer)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the preprocessed image, label\n",
    "interact(explore_3dimage, layer=(0, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import random\n",
    "import elasticdeform \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from scipy.ndimage import affine_transform, rotate, zoom\n",
    "from skimage.exposure import adjust_gamma, rescale_intensity\n",
    "from skimage.util import random_noise\n",
    "\n",
    "\n",
    "def random_flip_rotate_zoom(image, label):\n",
    "    angle = random.uniform(-5, 5)\n",
    "    flip_axes = [ i for i in range(2) if i!=2 and np.random.choice([0, 1]) == 1]\n",
    "    translate = (random.uniform(-10,10), random.uniform(-10,10))\n",
    "    matrix = np.array([[1, 0, 0, translate[0]], [0, 1, 0, translate[1]], [0, 0, 1,  0], [0, 0, 0, 1]])\n",
    "\n",
    "    imgvol = np.array(image.dataobj)\n",
    "    lblvol = np.array(label.dataobj)\n",
    "\n",
    "    # Rotate\n",
    "    img = rotate(imgvol, angle, reshape=False)\n",
    "    lbl = rotate(lblvol, angle, reshape=False)\n",
    "\n",
    "    # Randomly flip the image and label along one or more axes, except for the z-axis\n",
    "    img = np.flip(img, axis=flip_axes)\n",
    "    lbl = np.flip(lbl, axis=flip_axes)\n",
    "\n",
    "    # zoom\n",
    "    zoom_factor = random.uniform(0.8, 1.2)\n",
    "    img = zoom(img, zoom_factor, order=1)\n",
    "    lbl = zoom(lbl, zoom_factor, order=0)\n",
    "\n",
    "    # # Translate\n",
    "    # img = affine_transform(img, matrix, order=1)\n",
    "    # lbl = affine_transform(lbl, matrix, order=0)\n",
    "\n",
    "    image = nib.Nifti1Image(img, image.affine)\n",
    "    label = nib.Nifti1Image(lbl, label.affine)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Augmentation.combine_augmentation import random_flip_rotate_zoom_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {  'FRZT' : random_flip_rotate_zoom_translate}\n",
    "\n",
    "for type,func in types.items():\n",
    "    # create directries if does not exist\n",
    "    if not os.path.exists(AUG_OUT_DIR + type ):\n",
    "        os.makedirs(AUG_OUT_DIR + type)\n",
    "    if not os.path.exists(AUG_OUT_DIR + type + \"/Images\"):\n",
    "        os.makedirs(AUG_OUT_DIR + type + \"/Images\")\n",
    "    if not os.path.exists(AUG_OUT_DIR + type + \"/mask_prostate\"):\n",
    "        os.makedirs(AUG_OUT_DIR + type + \"/mask_prostate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import load_nifti\n",
    "\n",
    "def augment(func, entry, name, paths):\n",
    "    img, lbl = load_nifti(entry[\"image\"], entry[\"label\"])\n",
    "    \n",
    "    image, label = func(img, lbl)\n",
    "    image_path = entry[\"image\"].replace(\"data/sliced/prostate\", \"data/augmented_test/prostate/\" + name)\n",
    "    label_path = entry[\"label\"].replace(\"data/sliced/prostate\", \"data/augmented_test/prostate/\" + name)\n",
    "    paths.append({\"image\":image_path, \"label\":label_path})\n",
    "    image.to_filename(image_path )\n",
    "    label.to_filename(label_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import save_to_json\n",
    "\n",
    "paths = []\n",
    "for type, func in types.items():\n",
    "    #create augmented data\n",
    "    \n",
    "    for entry in data:\n",
    "        augment(func, entry, type, paths)\n",
    "        \n",
    "   \n",
    "save_to_json({\"path\": paths}, AUG_OUT_DIR + '/config.json')    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(path):\n",
    "  f = open( path + 'config.json')\n",
    "  jdata = json.load(f)\n",
    "  f.close()\n",
    "  return jdata[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_path(SLICED_OUT_DIR)\n",
    "aug_data = get_data_path(AUG_OUT_DIR)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "train_data = data[:train_size] + aug_data[:train_size]\n",
    "test_data = data[train_size:]+ data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixdim =(1.5, 1.5, 1.0)\n",
    "a_min=0\n",
    "a_max=500\n",
    "spatial_size= [128, 128,16] #[384, 384,18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\envy\\Desktop\\Prostate_MRI\\Prostate_MRI_Detection_3D_Model\\packages\\lib\\site-packages\\monai\\utils\\deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "from utils.transform import transform\n",
    "\n",
    "train_loader = transform(train_data, a_min, a_max, spatial_size, pixdim)\n",
    "test_loader = transform(test_data, a_min, a_max, spatial_size, pixdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm import tqdm\n",
    "from utils.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = OUT_DIR \n",
    "data_in = [train_loader, test_loader]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "\n",
    "unet = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=( 64, 128, 256,512), \n",
    "    strides=(2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(unet.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = OUT_DIR + \"unet/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "path = OUT_DIR+ \"unet/\"+ \"best_metric_model.pth\"\n",
    "\n",
    "if (os.path.exists(path)):\n",
    "    unet.load_state_dict(torch.load(\n",
    "        os.path.join(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\envy\\Desktop\\Prostate_MRI\\Prostate_MRI_Detection_3D_Model\\packages\\lib\\site-packages\\monai\\losses\\dice.py:144: UserWarning: single channel prediction, `to_onehot_y=True` ignored.\n",
      "  warnings.warn(\"single channel prediction, `to_onehot_y=True` ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/179, Train_loss: 0.9110 Train_dice: 0.0890\n",
      "2/179, Train_loss: 0.9315 Train_dice: 0.0685\n",
      "3/179, Train_loss: 0.9382 Train_dice: 0.0618\n",
      "4/179, Train_loss: 0.7820 Train_dice: 0.2180\n",
      "5/179, Train_loss: 0.8133 Train_dice: 0.1867\n",
      "6/179, Train_loss: 0.9197 Train_dice: 0.0803\n",
      "7/179, Train_loss: 0.8732 Train_dice: 0.1268\n",
      "8/179, Train_loss: 0.8417 Train_dice: 0.1583\n",
      "9/179, Train_loss: 0.8825 Train_dice: 0.1175\n",
      "10/179, Train_loss: 0.8550 Train_dice: 0.1450\n",
      "11/179, Train_loss: 0.9196 Train_dice: 0.0804\n",
      "12/179, Train_loss: 0.9276 Train_dice: 0.0724\n",
      "13/179, Train_loss: 0.8894 Train_dice: 0.1106\n",
      "14/179, Train_loss: 0.8334 Train_dice: 0.1666\n",
      "15/179, Train_loss: 0.9368 Train_dice: 0.0632\n",
      "16/179, Train_loss: 0.8697 Train_dice: 0.1303\n",
      "17/179, Train_loss: 0.8093 Train_dice: 0.1907\n",
      "18/179, Train_loss: 0.9228 Train_dice: 0.0772\n",
      "19/179, Train_loss: 0.8651 Train_dice: 0.1349\n",
      "20/179, Train_loss: 0.9054 Train_dice: 0.0946\n",
      "21/179, Train_loss: 0.8524 Train_dice: 0.1476\n",
      "22/179, Train_loss: 0.8652 Train_dice: 0.1348\n",
      "23/179, Train_loss: 0.8364 Train_dice: 0.1636\n",
      "24/179, Train_loss: 0.9060 Train_dice: 0.0940\n",
      "25/179, Train_loss: 0.8713 Train_dice: 0.1287\n",
      "26/179, Train_loss: 0.8040 Train_dice: 0.1960\n",
      "27/179, Train_loss: 0.8508 Train_dice: 0.1492\n",
      "28/179, Train_loss: 0.7874 Train_dice: 0.2126\n",
      "29/179, Train_loss: 0.8707 Train_dice: 0.1293\n",
      "30/179, Train_loss: 0.8278 Train_dice: 0.1722\n",
      "31/179, Train_loss: 0.9134 Train_dice: 0.0866\n",
      "32/179, Train_loss: 0.8883 Train_dice: 0.1117\n",
      "33/179, Train_loss: 0.7984 Train_dice: 0.2016\n",
      "34/179, Train_loss: 0.8331 Train_dice: 0.1669\n",
      "35/179, Train_loss: 0.8214 Train_dice: 0.1786\n",
      "36/179, Train_loss: 0.8059 Train_dice: 0.1941\n",
      "37/179, Train_loss: 0.8074 Train_dice: 0.1926\n",
      "38/179, Train_loss: 0.8900 Train_dice: 0.1100\n",
      "39/179, Train_loss: 0.8544 Train_dice: 0.1456\n",
      "40/179, Train_loss: 0.7575 Train_dice: 0.2425\n",
      "41/179, Train_loss: 0.8402 Train_dice: 0.1598\n",
      "42/179, Train_loss: 0.8027 Train_dice: 0.1973\n",
      "43/179, Train_loss: 0.7135 Train_dice: 0.2865\n",
      "44/179, Train_loss: 0.7328 Train_dice: 0.2672\n",
      "45/179, Train_loss: 0.7719 Train_dice: 0.2281\n",
      "46/179, Train_loss: 0.7160 Train_dice: 0.2840\n",
      "47/179, Train_loss: 0.9022 Train_dice: 0.0978\n",
      "48/179, Train_loss: 0.7547 Train_dice: 0.2453\n",
      "49/179, Train_loss: 0.8393 Train_dice: 0.1607\n",
      "50/179, Train_loss: 0.8525 Train_dice: 0.1475\n",
      "51/179, Train_loss: 0.6913 Train_dice: 0.3087\n",
      "52/179, Train_loss: 0.8568 Train_dice: 0.1432\n",
      "53/179, Train_loss: 0.6600 Train_dice: 0.3400\n",
      "54/179, Train_loss: 0.7978 Train_dice: 0.2022\n",
      "55/179, Train_loss: 0.7597 Train_dice: 0.2403\n",
      "56/179, Train_loss: 0.7992 Train_dice: 0.2008\n",
      "57/179, Train_loss: 0.7518 Train_dice: 0.2482\n",
      "58/179, Train_loss: 0.7415 Train_dice: 0.2585\n",
      "59/179, Train_loss: 0.5656 Train_dice: 0.4344\n",
      "60/179, Train_loss: 0.7651 Train_dice: 0.2349\n",
      "61/179, Train_loss: 0.6049 Train_dice: 0.3951\n",
      "62/179, Train_loss: 0.7371 Train_dice: 0.2629\n",
      "63/179, Train_loss: 0.8501 Train_dice: 0.1499\n",
      "64/179, Train_loss: 0.7456 Train_dice: 0.2544\n",
      "65/179, Train_loss: 0.6625 Train_dice: 0.3375\n",
      "66/179, Train_loss: 0.8271 Train_dice: 0.1729\n",
      "67/179, Train_loss: 0.7106 Train_dice: 0.2894\n",
      "68/179, Train_loss: 0.8159 Train_dice: 0.1841\n",
      "69/179, Train_loss: 0.7428 Train_dice: 0.2572\n",
      "70/179, Train_loss: 0.8891 Train_dice: 0.1109\n",
      "71/179, Train_loss: 0.6450 Train_dice: 0.3550\n",
      "72/179, Train_loss: 0.8606 Train_dice: 0.1394\n",
      "73/179, Train_loss: 0.7666 Train_dice: 0.2334\n",
      "74/179, Train_loss: 0.7354 Train_dice: 0.2646\n",
      "75/179, Train_loss: 0.7751 Train_dice: 0.2249\n",
      "76/179, Train_loss: 0.5348 Train_dice: 0.4652\n",
      "77/179, Train_loss: 0.8522 Train_dice: 0.1478\n",
      "78/179, Train_loss: 0.8228 Train_dice: 0.1772\n",
      "79/179, Train_loss: 0.8590 Train_dice: 0.1410\n",
      "80/179, Train_loss: 0.7389 Train_dice: 0.2611\n",
      "81/179, Train_loss: 0.6573 Train_dice: 0.3427\n",
      "82/179, Train_loss: 0.7251 Train_dice: 0.2749\n",
      "83/179, Train_loss: 0.8191 Train_dice: 0.1809\n",
      "84/179, Train_loss: 0.8825 Train_dice: 0.1175\n",
      "85/179, Train_loss: 0.7946 Train_dice: 0.2054\n",
      "86/179, Train_loss: 0.7092 Train_dice: 0.2908\n",
      "87/179, Train_loss: 0.7359 Train_dice: 0.2641\n",
      "88/179, Train_loss: 0.8191 Train_dice: 0.1809\n",
      "89/179, Train_loss: 0.6868 Train_dice: 0.3132\n",
      "90/179, Train_loss: 0.7050 Train_dice: 0.2950\n",
      "91/179, Train_loss: 0.7689 Train_dice: 0.2311\n",
      "92/179, Train_loss: 0.7796 Train_dice: 0.2204\n",
      "93/179, Train_loss: 0.8511 Train_dice: 0.1489\n",
      "94/179, Train_loss: 0.8193 Train_dice: 0.1807\n",
      "95/179, Train_loss: 0.8854 Train_dice: 0.1146\n",
      "96/179, Train_loss: 0.7807 Train_dice: 0.2193\n",
      "97/179, Train_loss: 0.7429 Train_dice: 0.2571\n",
      "98/179, Train_loss: 0.8402 Train_dice: 0.1598\n",
      "99/179, Train_loss: 0.6871 Train_dice: 0.3129\n",
      "100/179, Train_loss: 0.7046 Train_dice: 0.2954\n",
      "101/179, Train_loss: 0.7797 Train_dice: 0.2203\n",
      "102/179, Train_loss: 0.7698 Train_dice: 0.2302\n",
      "103/179, Train_loss: 0.7402 Train_dice: 0.2598\n",
      "104/179, Train_loss: 0.7784 Train_dice: 0.2216\n",
      "105/179, Train_loss: 0.7516 Train_dice: 0.2484\n",
      "106/179, Train_loss: 0.7782 Train_dice: 0.2218\n",
      "107/179, Train_loss: 0.7846 Train_dice: 0.2154\n",
      "108/179, Train_loss: 0.6248 Train_dice: 0.3752\n",
      "109/179, Train_loss: 0.7705 Train_dice: 0.2295\n",
      "110/179, Train_loss: 0.8539 Train_dice: 0.1461\n",
      "111/179, Train_loss: 0.7386 Train_dice: 0.2614\n",
      "112/179, Train_loss: 0.8527 Train_dice: 0.1473\n",
      "113/179, Train_loss: 0.7419 Train_dice: 0.2581\n",
      "114/179, Train_loss: 0.7798 Train_dice: 0.2202\n",
      "115/179, Train_loss: 0.8195 Train_dice: 0.1805\n",
      "116/179, Train_loss: 0.9036 Train_dice: 0.0964\n",
      "117/179, Train_loss: 0.7833 Train_dice: 0.2167\n",
      "118/179, Train_loss: 0.8587 Train_dice: 0.1413\n",
      "119/179, Train_loss: 0.7914 Train_dice: 0.2086\n",
      "120/179, Train_loss: 0.7323 Train_dice: 0.2677\n",
      "121/179, Train_loss: 0.6830 Train_dice: 0.3170\n",
      "122/179, Train_loss: 0.7149 Train_dice: 0.2851\n",
      "123/179, Train_loss: 0.7586 Train_dice: 0.2414\n",
      "124/179, Train_loss: 0.8088 Train_dice: 0.1912\n",
      "125/179, Train_loss: 0.6410 Train_dice: 0.3590\n",
      "126/179, Train_loss: 0.8623 Train_dice: 0.1377\n",
      "127/179, Train_loss: 0.7603 Train_dice: 0.2397\n",
      "128/179, Train_loss: 0.8181 Train_dice: 0.1819\n",
      "129/179, Train_loss: 0.8962 Train_dice: 0.1038\n",
      "130/179, Train_loss: 0.8398 Train_dice: 0.1602\n",
      "131/179, Train_loss: 0.6640 Train_dice: 0.3360\n",
      "132/179, Train_loss: 0.8411 Train_dice: 0.1589\n",
      "133/179, Train_loss: 0.7985 Train_dice: 0.2015\n",
      "134/179, Train_loss: 0.8950 Train_dice: 0.1050\n",
      "135/179, Train_loss: 0.8038 Train_dice: 0.1962\n",
      "136/179, Train_loss: 0.8493 Train_dice: 0.1507\n",
      "137/179, Train_loss: 0.7985 Train_dice: 0.2015\n",
      "138/179, Train_loss: 0.7453 Train_dice: 0.2547\n",
      "139/179, Train_loss: 0.6480 Train_dice: 0.3520\n",
      "140/179, Train_loss: 0.8110 Train_dice: 0.1890\n",
      "141/179, Train_loss: 0.7224 Train_dice: 0.2776\n",
      "142/179, Train_loss: 0.8455 Train_dice: 0.1545\n",
      "143/179, Train_loss: 0.6901 Train_dice: 0.3099\n",
      "144/179, Train_loss: 0.7922 Train_dice: 0.2078\n",
      "145/179, Train_loss: 0.8709 Train_dice: 0.1291\n",
      "146/179, Train_loss: 0.7886 Train_dice: 0.2114\n",
      "147/179, Train_loss: 0.6469 Train_dice: 0.3531\n",
      "148/179, Train_loss: 0.8372 Train_dice: 0.1628\n",
      "149/179, Train_loss: 0.7681 Train_dice: 0.2319\n",
      "150/179, Train_loss: 0.8393 Train_dice: 0.1607\n",
      "151/179, Train_loss: 0.7958 Train_dice: 0.2042\n",
      "152/179, Train_loss: 0.6779 Train_dice: 0.3221\n",
      "153/179, Train_loss: 0.8618 Train_dice: 0.1382\n",
      "154/179, Train_loss: 0.7803 Train_dice: 0.2197\n",
      "155/179, Train_loss: 0.6892 Train_dice: 0.3108\n",
      "156/179, Train_loss: 0.7806 Train_dice: 0.2194\n",
      "157/179, Train_loss: 0.6580 Train_dice: 0.3420\n",
      "158/179, Train_loss: 0.8809 Train_dice: 0.1191\n",
      "159/179, Train_loss: 0.7617 Train_dice: 0.2383\n",
      "160/179, Train_loss: 0.7472 Train_dice: 0.2528\n",
      "161/179, Train_loss: 0.7993 Train_dice: 0.2007\n",
      "162/179, Train_loss: 0.6206 Train_dice: 0.3794\n",
      "163/179, Train_loss: 0.6651 Train_dice: 0.3349\n",
      "164/179, Train_loss: 0.5033 Train_dice: 0.4967\n",
      "165/179, Train_loss: 0.8130 Train_dice: 0.1870\n",
      "166/179, Train_loss: 0.8742 Train_dice: 0.1258\n",
      "167/179, Train_loss: 0.3466 Train_dice: 0.6534\n",
      "168/179, Train_loss: 0.6201 Train_dice: 0.3799\n",
      "169/179, Train_loss: 0.5351 Train_dice: 0.4649\n",
      "170/179, Train_loss: 0.4170 Train_dice: 0.5830\n",
      "171/179, Train_loss: 0.3885 Train_dice: 0.6115\n",
      "172/179, Train_loss: 0.4098 Train_dice: 0.5902\n",
      "173/179, Train_loss: 0.4056 Train_dice: 0.5944\n",
      "174/179, Train_loss: 0.4933 Train_dice: 0.5067\n",
      "175/179, Train_loss: 0.5081 Train_dice: 0.4919\n",
      "176/179, Train_loss: 0.4005 Train_dice: 0.5995\n",
      "177/179, Train_loss: 0.3878 Train_dice: 0.6122\n",
      "178/179, Train_loss: 0.4682 Train_dice: 0.5318\n",
      "179/179, Train_loss: 0.3895 Train_dice: 0.6105\n",
      "--------------------\n",
      "Epoch_loss: 0.7660\n",
      "Epoch_metric: 0.2340\n",
      "----------\n",
      "epoch 2/20\n",
      "1/179, Train_loss: 0.8195 Train_dice: 0.1805\n",
      "2/179, Train_loss: 0.8710 Train_dice: 0.1290\n",
      "3/179, Train_loss: 0.8753 Train_dice: 0.1247\n",
      "4/179, Train_loss: 0.6071 Train_dice: 0.3929\n",
      "5/179, Train_loss: 0.6575 Train_dice: 0.3425\n",
      "6/179, Train_loss: 0.8460 Train_dice: 0.1540\n",
      "7/179, Train_loss: 0.7541 Train_dice: 0.2459\n",
      "8/179, Train_loss: 0.7106 Train_dice: 0.2894\n",
      "9/179, Train_loss: 0.7720 Train_dice: 0.2280\n",
      "10/179, Train_loss: 0.7198 Train_dice: 0.2802\n",
      "11/179, Train_loss: 0.8478 Train_dice: 0.1522\n",
      "12/179, Train_loss: 0.8590 Train_dice: 0.1410\n",
      "13/179, Train_loss: 0.7996 Train_dice: 0.2004\n",
      "14/179, Train_loss: 0.7061 Train_dice: 0.2939\n",
      "15/179, Train_loss: 0.8837 Train_dice: 0.1163\n",
      "16/179, Train_loss: 0.7573 Train_dice: 0.2427\n",
      "17/179, Train_loss: 0.6648 Train_dice: 0.3352\n",
      "18/179, Train_loss: 0.8590 Train_dice: 0.1410\n",
      "19/179, Train_loss: 0.7578 Train_dice: 0.2422\n",
      "20/179, Train_loss: 0.8289 Train_dice: 0.1711\n",
      "21/179, Train_loss: 0.7399 Train_dice: 0.2601\n",
      "22/179, Train_loss: 0.7573 Train_dice: 0.2427\n",
      "23/179, Train_loss: 0.7194 Train_dice: 0.2806\n",
      "24/179, Train_loss: 0.8335 Train_dice: 0.1665\n",
      "25/179, Train_loss: 0.7765 Train_dice: 0.2235\n",
      "26/179, Train_loss: 0.6765 Train_dice: 0.3235\n",
      "27/179, Train_loss: 0.7501 Train_dice: 0.2499\n",
      "28/179, Train_loss: 0.6478 Train_dice: 0.3522\n",
      "29/179, Train_loss: 0.7774 Train_dice: 0.2226\n",
      "30/179, Train_loss: 0.7215 Train_dice: 0.2785\n",
      "31/179, Train_loss: 0.8633 Train_dice: 0.1367\n",
      "32/179, Train_loss: 0.8194 Train_dice: 0.1806\n",
      "33/179, Train_loss: 0.6789 Train_dice: 0.3211\n",
      "34/179, Train_loss: 0.7319 Train_dice: 0.2681\n",
      "35/179, Train_loss: 0.7372 Train_dice: 0.2628\n",
      "36/179, Train_loss: 0.7019 Train_dice: 0.2981\n",
      "37/179, Train_loss: 0.7099 Train_dice: 0.2901\n",
      "38/179, Train_loss: 0.8330 Train_dice: 0.1670\n",
      "39/179, Train_loss: 0.7854 Train_dice: 0.2146\n",
      "40/179, Train_loss: 0.6565 Train_dice: 0.3435\n",
      "41/179, Train_loss: 0.7624 Train_dice: 0.2376\n",
      "42/179, Train_loss: 0.7290 Train_dice: 0.2710\n",
      "43/179, Train_loss: 0.6291 Train_dice: 0.3709\n",
      "44/179, Train_loss: 0.6374 Train_dice: 0.3626\n",
      "45/179, Train_loss: 0.6877 Train_dice: 0.3123\n",
      "46/179, Train_loss: 0.6301 Train_dice: 0.3699\n",
      "47/179, Train_loss: 0.8605 Train_dice: 0.1395\n",
      "48/179, Train_loss: 0.6808 Train_dice: 0.3192\n",
      "49/179, Train_loss: 0.7950 Train_dice: 0.2050\n",
      "50/179, Train_loss: 0.8077 Train_dice: 0.1923\n",
      "51/179, Train_loss: 0.6163 Train_dice: 0.3837\n",
      "52/179, Train_loss: 0.8152 Train_dice: 0.1848\n",
      "53/179, Train_loss: 0.5866 Train_dice: 0.4134\n",
      "54/179, Train_loss: 0.7455 Train_dice: 0.2545\n",
      "55/179, Train_loss: 0.7068 Train_dice: 0.2932\n",
      "56/179, Train_loss: 0.7450 Train_dice: 0.2550\n",
      "57/179, Train_loss: 0.6979 Train_dice: 0.3021\n",
      "58/179, Train_loss: 0.6883 Train_dice: 0.3117\n",
      "59/179, Train_loss: 0.4981 Train_dice: 0.5019\n",
      "60/179, Train_loss: 0.7151 Train_dice: 0.2849\n",
      "61/179, Train_loss: 0.5314 Train_dice: 0.4686\n",
      "62/179, Train_loss: 0.6904 Train_dice: 0.3096\n",
      "63/179, Train_loss: 0.8168 Train_dice: 0.1832\n",
      "64/179, Train_loss: 0.7022 Train_dice: 0.2978\n",
      "65/179, Train_loss: 0.6169 Train_dice: 0.3831\n",
      "66/179, Train_loss: 0.7964 Train_dice: 0.2036\n",
      "67/179, Train_loss: 0.6529 Train_dice: 0.3471\n",
      "68/179, Train_loss: 0.7864 Train_dice: 0.2136\n",
      "69/179, Train_loss: 0.6802 Train_dice: 0.3198\n",
      "70/179, Train_loss: 0.8726 Train_dice: 0.1274\n",
      "71/179, Train_loss: 0.6029 Train_dice: 0.3971\n",
      "72/179, Train_loss: 0.8420 Train_dice: 0.1580\n",
      "73/179, Train_loss: 0.7345 Train_dice: 0.2655\n",
      "74/179, Train_loss: 0.7016 Train_dice: 0.2984\n",
      "75/179, Train_loss: 0.7471 Train_dice: 0.2529\n",
      "76/179, Train_loss: 0.4912 Train_dice: 0.5088\n",
      "77/179, Train_loss: 0.8347 Train_dice: 0.1653\n",
      "78/179, Train_loss: 0.8023 Train_dice: 0.1977\n",
      "79/179, Train_loss: 0.8419 Train_dice: 0.1581\n",
      "80/179, Train_loss: 0.7079 Train_dice: 0.2921\n",
      "81/179, Train_loss: 0.6174 Train_dice: 0.3826\n",
      "82/179, Train_loss: 0.6921 Train_dice: 0.3079\n",
      "83/179, Train_loss: 0.8010 Train_dice: 0.1990\n",
      "84/179, Train_loss: 0.8720 Train_dice: 0.1280\n",
      "85/179, Train_loss: 0.7739 Train_dice: 0.2261\n",
      "86/179, Train_loss: 0.6807 Train_dice: 0.3193\n",
      "87/179, Train_loss: 0.7091 Train_dice: 0.2909\n",
      "88/179, Train_loss: 0.7999 Train_dice: 0.2001\n",
      "89/179, Train_loss: 0.6548 Train_dice: 0.3452\n",
      "90/179, Train_loss: 0.6728 Train_dice: 0.3272\n",
      "91/179, Train_loss: 0.7492 Train_dice: 0.2508\n",
      "92/179, Train_loss: 0.7628 Train_dice: 0.2372\n",
      "93/179, Train_loss: 0.8403 Train_dice: 0.1597\n",
      "94/179, Train_loss: 0.8045 Train_dice: 0.1955\n",
      "95/179, Train_loss: 0.8766 Train_dice: 0.1234\n",
      "96/179, Train_loss: 0.7614 Train_dice: 0.2386\n",
      "97/179, Train_loss: 0.7234 Train_dice: 0.2766\n",
      "98/179, Train_loss: 0.8298 Train_dice: 0.1702\n",
      "99/179, Train_loss: 0.6646 Train_dice: 0.3354\n",
      "100/179, Train_loss: 0.6846 Train_dice: 0.3154\n",
      "101/179, Train_loss: 0.7615 Train_dice: 0.2385\n",
      "102/179, Train_loss: 0.7446 Train_dice: 0.2554\n",
      "103/179, Train_loss: 0.7213 Train_dice: 0.2787\n",
      "104/179, Train_loss: 0.7633 Train_dice: 0.2367\n",
      "105/179, Train_loss: 0.7281 Train_dice: 0.2719\n",
      "106/179, Train_loss: 0.7636 Train_dice: 0.2364\n",
      "107/179, Train_loss: 0.7695 Train_dice: 0.2305\n",
      "108/179, Train_loss: 0.6006 Train_dice: 0.3994\n",
      "109/179, Train_loss: 0.7567 Train_dice: 0.2433\n",
      "110/179, Train_loss: 0.8439 Train_dice: 0.1561\n",
      "111/179, Train_loss: 0.7210 Train_dice: 0.2790\n",
      "112/179, Train_loss: 0.8452 Train_dice: 0.1548\n",
      "113/179, Train_loss: 0.7246 Train_dice: 0.2754\n",
      "114/179, Train_loss: 0.7696 Train_dice: 0.2304\n",
      "115/179, Train_loss: 0.8117 Train_dice: 0.1883\n",
      "116/179, Train_loss: 0.8769 Train_dice: 0.1231\n",
      "117/179, Train_loss: 0.7678 Train_dice: 0.2322\n",
      "118/179, Train_loss: 0.8515 Train_dice: 0.1485\n",
      "119/179, Train_loss: 0.7827 Train_dice: 0.2173\n",
      "120/179, Train_loss: 0.7181 Train_dice: 0.2819\n",
      "121/179, Train_loss: 0.6643 Train_dice: 0.3357\n",
      "122/179, Train_loss: 0.6958 Train_dice: 0.3042\n",
      "123/179, Train_loss: 0.7467 Train_dice: 0.2533\n",
      "124/179, Train_loss: 0.8001 Train_dice: 0.1999\n",
      "125/179, Train_loss: 0.6216 Train_dice: 0.3784\n",
      "126/179, Train_loss: 0.8503 Train_dice: 0.1497\n",
      "127/179, Train_loss: 0.7484 Train_dice: 0.2516\n",
      "128/179, Train_loss: 0.8100 Train_dice: 0.1900\n",
      "129/179, Train_loss: 0.8905 Train_dice: 0.1095\n",
      "130/179, Train_loss: 0.8315 Train_dice: 0.1685\n",
      "131/179, Train_loss: 0.6503 Train_dice: 0.3497\n",
      "132/179, Train_loss: 0.8329 Train_dice: 0.1671\n",
      "133/179, Train_loss: 0.7891 Train_dice: 0.2109\n",
      "134/179, Train_loss: 0.8905 Train_dice: 0.1095\n",
      "135/179, Train_loss: 0.7962 Train_dice: 0.2038\n",
      "136/179, Train_loss: 0.8421 Train_dice: 0.1579\n",
      "137/179, Train_loss: 0.7914 Train_dice: 0.2086\n",
      "138/179, Train_loss: 0.7333 Train_dice: 0.2667\n",
      "139/179, Train_loss: 0.6341 Train_dice: 0.3659\n",
      "140/179, Train_loss: 0.8033 Train_dice: 0.1967\n",
      "141/179, Train_loss: 0.7104 Train_dice: 0.2896\n",
      "142/179, Train_loss: 0.8401 Train_dice: 0.1599\n",
      "143/179, Train_loss: 0.6761 Train_dice: 0.3239\n",
      "144/179, Train_loss: 0.7825 Train_dice: 0.2175\n",
      "145/179, Train_loss: 0.8667 Train_dice: 0.1333\n",
      "146/179, Train_loss: 0.7809 Train_dice: 0.2191\n",
      "147/179, Train_loss: 0.6341 Train_dice: 0.3659\n",
      "148/179, Train_loss: 0.8303 Train_dice: 0.1697\n",
      "149/179, Train_loss: 0.7600 Train_dice: 0.2400\n",
      "150/179, Train_loss: 0.8341 Train_dice: 0.1659\n",
      "151/179, Train_loss: 0.7885 Train_dice: 0.2115\n",
      "152/179, Train_loss: 0.6619 Train_dice: 0.3381\n",
      "153/179, Train_loss: 0.8555 Train_dice: 0.1445\n",
      "154/179, Train_loss: 0.7722 Train_dice: 0.2278\n",
      "155/179, Train_loss: 0.6788 Train_dice: 0.3212\n",
      "156/179, Train_loss: 0.7727 Train_dice: 0.2273\n",
      "157/179, Train_loss: 0.6445 Train_dice: 0.3555\n",
      "158/179, Train_loss: 0.8749 Train_dice: 0.1251\n",
      "159/179, Train_loss: 0.7504 Train_dice: 0.2496\n",
      "160/179, Train_loss: 0.7356 Train_dice: 0.2644\n",
      "161/179, Train_loss: 0.7926 Train_dice: 0.2074\n",
      "162/179, Train_loss: 0.6019 Train_dice: 0.3981\n",
      "163/179, Train_loss: 0.6540 Train_dice: 0.3460\n",
      "164/179, Train_loss: 0.5031 Train_dice: 0.4969\n",
      "165/179, Train_loss: 0.8054 Train_dice: 0.1946\n",
      "166/179, Train_loss: 0.8380 Train_dice: 0.1620\n",
      "167/179, Train_loss: 0.3416 Train_dice: 0.6584\n",
      "168/179, Train_loss: 0.5965 Train_dice: 0.4035\n",
      "169/179, Train_loss: 0.4553 Train_dice: 0.5447\n",
      "170/179, Train_loss: 0.4191 Train_dice: 0.5809\n",
      "171/179, Train_loss: 0.3863 Train_dice: 0.6137\n",
      "172/179, Train_loss: 0.4141 Train_dice: 0.5859\n",
      "173/179, Train_loss: 0.3884 Train_dice: 0.6116\n",
      "174/179, Train_loss: 0.4521 Train_dice: 0.5479\n",
      "175/179, Train_loss: 0.4850 Train_dice: 0.5150\n",
      "176/179, Train_loss: 0.4192 Train_dice: 0.5808\n",
      "177/179, Train_loss: 0.3554 Train_dice: 0.6446\n",
      "178/179, Train_loss: 0.4812 Train_dice: 0.5188\n",
      "179/179, Train_loss: 0.3941 Train_dice: 0.6059\n",
      "--------------------\n",
      "Epoch_loss: 0.7249\n",
      "Epoch_metric: 0.2751\n",
      "----------\n",
      "epoch 3/20\n",
      "1/179, Train_loss: 0.8072 Train_dice: 0.1928\n",
      "2/179, Train_loss: 0.8502 Train_dice: 0.1498\n",
      "3/179, Train_loss: 0.8691 Train_dice: 0.1309\n",
      "4/179, Train_loss: 0.6004 Train_dice: 0.3996\n",
      "5/179, Train_loss: 0.6437 Train_dice: 0.3563\n",
      "6/179, Train_loss: 0.8314 Train_dice: 0.1686\n",
      "7/179, Train_loss: 0.7415 Train_dice: 0.2585\n",
      "8/179, Train_loss: 0.6943 Train_dice: 0.3057\n",
      "9/179, Train_loss: 0.7603 Train_dice: 0.2397\n",
      "10/179, Train_loss: 0.7132 Train_dice: 0.2868\n",
      "11/179, Train_loss: 0.8396 Train_dice: 0.1604\n",
      "12/179, Train_loss: 0.8534 Train_dice: 0.1466\n",
      "13/179, Train_loss: 0.7861 Train_dice: 0.2139\n",
      "14/179, Train_loss: 0.6868 Train_dice: 0.3132\n",
      "15/179, Train_loss: 0.8784 Train_dice: 0.1216\n",
      "16/179, Train_loss: 0.7496 Train_dice: 0.2504\n",
      "17/179, Train_loss: 0.6525 Train_dice: 0.3475\n",
      "18/179, Train_loss: 0.8536 Train_dice: 0.1464\n",
      "19/179, Train_loss: 0.7475 Train_dice: 0.2525\n",
      "20/179, Train_loss: 0.8209 Train_dice: 0.1791\n",
      "21/179, Train_loss: 0.7312 Train_dice: 0.2688\n",
      "22/179, Train_loss: 0.7502 Train_dice: 0.2498\n",
      "23/179, Train_loss: 0.7109 Train_dice: 0.2891\n",
      "24/179, Train_loss: 0.8297 Train_dice: 0.1703\n",
      "25/179, Train_loss: 0.7708 Train_dice: 0.2292\n",
      "26/179, Train_loss: 0.6671 Train_dice: 0.3329\n",
      "27/179, Train_loss: 0.7440 Train_dice: 0.2560\n",
      "28/179, Train_loss: 0.6401 Train_dice: 0.3599\n",
      "29/179, Train_loss: 0.7700 Train_dice: 0.2300\n",
      "30/179, Train_loss: 0.7150 Train_dice: 0.2850\n",
      "31/179, Train_loss: 0.8598 Train_dice: 0.1402\n",
      "32/179, Train_loss: 0.8149 Train_dice: 0.1851\n",
      "33/179, Train_loss: 0.6707 Train_dice: 0.3293\n",
      "34/179, Train_loss: 0.7276 Train_dice: 0.2724\n",
      "35/179, Train_loss: 0.7263 Train_dice: 0.2737\n",
      "36/179, Train_loss: 0.6954 Train_dice: 0.3046\n",
      "37/179, Train_loss: 0.7039 Train_dice: 0.2961\n",
      "38/179, Train_loss: 0.8290 Train_dice: 0.1710\n",
      "39/179, Train_loss: 0.7815 Train_dice: 0.2185\n",
      "40/179, Train_loss: 0.6481 Train_dice: 0.3519\n",
      "41/179, Train_loss: 0.7492 Train_dice: 0.2508\n",
      "42/179, Train_loss: 0.7214 Train_dice: 0.2786\n",
      "43/179, Train_loss: 0.6122 Train_dice: 0.3878\n",
      "44/179, Train_loss: 0.6283 Train_dice: 0.3717\n",
      "45/179, Train_loss: 0.6799 Train_dice: 0.3201\n",
      "46/179, Train_loss: 0.6212 Train_dice: 0.3788\n",
      "47/179, Train_loss: 0.8547 Train_dice: 0.1453\n",
      "48/179, Train_loss: 0.6734 Train_dice: 0.3266\n",
      "49/179, Train_loss: 0.7878 Train_dice: 0.2122\n",
      "50/179, Train_loss: 0.8017 Train_dice: 0.1983\n",
      "51/179, Train_loss: 0.6071 Train_dice: 0.3929\n",
      "52/179, Train_loss: 0.8100 Train_dice: 0.1900\n",
      "53/179, Train_loss: 0.5759 Train_dice: 0.4241\n",
      "54/179, Train_loss: 0.7388 Train_dice: 0.2612\n",
      "55/179, Train_loss: 0.7012 Train_dice: 0.2988\n",
      "56/179, Train_loss: 0.7347 Train_dice: 0.2653\n",
      "57/179, Train_loss: 0.6912 Train_dice: 0.3088\n",
      "58/179, Train_loss: 0.6810 Train_dice: 0.3190\n",
      "59/179, Train_loss: 0.4882 Train_dice: 0.5118\n",
      "60/179, Train_loss: 0.7084 Train_dice: 0.2916\n",
      "61/179, Train_loss: 0.5216 Train_dice: 0.4784\n",
      "62/179, Train_loss: 0.6821 Train_dice: 0.3179\n",
      "63/179, Train_loss: 0.8121 Train_dice: 0.1879\n",
      "64/179, Train_loss: 0.6951 Train_dice: 0.3049\n",
      "65/179, Train_loss: 0.6076 Train_dice: 0.3924\n",
      "66/179, Train_loss: 0.7921 Train_dice: 0.2079\n",
      "67/179, Train_loss: 0.6433 Train_dice: 0.3567\n",
      "68/179, Train_loss: 0.7815 Train_dice: 0.2185\n",
      "69/179, Train_loss: 0.6731 Train_dice: 0.3269\n",
      "70/179, Train_loss: 0.8694 Train_dice: 0.1306\n",
      "71/179, Train_loss: 0.5952 Train_dice: 0.4048\n",
      "72/179, Train_loss: 0.8388 Train_dice: 0.1612\n",
      "73/179, Train_loss: 0.7291 Train_dice: 0.2709\n",
      "74/179, Train_loss: 0.6961 Train_dice: 0.3039\n",
      "75/179, Train_loss: 0.7422 Train_dice: 0.2578\n",
      "76/179, Train_loss: 0.4788 Train_dice: 0.5212\n",
      "77/179, Train_loss: 0.8311 Train_dice: 0.1689\n",
      "78/179, Train_loss: 0.7984 Train_dice: 0.2016\n",
      "79/179, Train_loss: 0.8386 Train_dice: 0.1614\n",
      "80/179, Train_loss: 0.7021 Train_dice: 0.2979\n",
      "81/179, Train_loss: 0.6079 Train_dice: 0.3921\n",
      "82/179, Train_loss: 0.6849 Train_dice: 0.3151\n",
      "83/179, Train_loss: 0.7966 Train_dice: 0.2034\n",
      "84/179, Train_loss: 0.8688 Train_dice: 0.1312\n",
      "85/179, Train_loss: 0.7693 Train_dice: 0.2307\n",
      "86/179, Train_loss: 0.6742 Train_dice: 0.3258\n",
      "87/179, Train_loss: 0.7024 Train_dice: 0.2976\n",
      "88/179, Train_loss: 0.7961 Train_dice: 0.2039\n",
      "89/179, Train_loss: 0.6482 Train_dice: 0.3518\n",
      "90/179, Train_loss: 0.6660 Train_dice: 0.3340\n",
      "91/179, Train_loss: 0.7442 Train_dice: 0.2558\n",
      "92/179, Train_loss: 0.7585 Train_dice: 0.2415\n",
      "93/179, Train_loss: 0.8379 Train_dice: 0.1621\n",
      "94/179, Train_loss: 0.8003 Train_dice: 0.1997\n",
      "95/179, Train_loss: 0.8744 Train_dice: 0.1256\n",
      "96/179, Train_loss: 0.7568 Train_dice: 0.2432\n",
      "97/179, Train_loss: 0.7185 Train_dice: 0.2815\n",
      "98/179, Train_loss: 0.8268 Train_dice: 0.1732\n",
      "99/179, Train_loss: 0.6590 Train_dice: 0.3410\n",
      "100/179, Train_loss: 0.6780 Train_dice: 0.3220\n",
      "101/179, Train_loss: 0.7569 Train_dice: 0.2431\n",
      "102/179, Train_loss: 0.7387 Train_dice: 0.2613\n",
      "103/179, Train_loss: 0.7159 Train_dice: 0.2841\n",
      "104/179, Train_loss: 0.7591 Train_dice: 0.2409\n",
      "105/179, Train_loss: 0.7222 Train_dice: 0.2778\n",
      "106/179, Train_loss: 0.7595 Train_dice: 0.2405\n",
      "107/179, Train_loss: 0.7652 Train_dice: 0.2348\n",
      "108/179, Train_loss: 0.5915 Train_dice: 0.4085\n",
      "109/179, Train_loss: 0.7527 Train_dice: 0.2473\n",
      "110/179, Train_loss: 0.8399 Train_dice: 0.1601\n",
      "111/179, Train_loss: 0.7160 Train_dice: 0.2840\n",
      "112/179, Train_loss: 0.8428 Train_dice: 0.1572\n",
      "113/179, Train_loss: 0.7191 Train_dice: 0.2809\n",
      "114/179, Train_loss: 0.7658 Train_dice: 0.2342\n",
      "115/179, Train_loss: 0.8089 Train_dice: 0.1911\n",
      "116/179, Train_loss: 0.8749 Train_dice: 0.1251\n",
      "117/179, Train_loss: 0.7620 Train_dice: 0.2380\n",
      "118/179, Train_loss: 0.8489 Train_dice: 0.1511\n",
      "119/179, Train_loss: 0.7786 Train_dice: 0.2214\n",
      "120/179, Train_loss: 0.7096 Train_dice: 0.2904\n",
      "121/179, Train_loss: 0.6587 Train_dice: 0.3413\n",
      "122/179, Train_loss: 0.6885 Train_dice: 0.3115\n",
      "123/179, Train_loss: 0.7428 Train_dice: 0.2572\n",
      "124/179, Train_loss: 0.7969 Train_dice: 0.2031\n",
      "125/179, Train_loss: 0.6149 Train_dice: 0.3851\n",
      "126/179, Train_loss: 0.8439 Train_dice: 0.1561\n",
      "127/179, Train_loss: 0.7433 Train_dice: 0.2567\n",
      "128/179, Train_loss: 0.8067 Train_dice: 0.1933\n",
      "129/179, Train_loss: 0.8881 Train_dice: 0.1119\n",
      "130/179, Train_loss: 0.8285 Train_dice: 0.1715\n",
      "131/179, Train_loss: 0.6431 Train_dice: 0.3569\n",
      "132/179, Train_loss: 0.8296 Train_dice: 0.1704\n",
      "133/179, Train_loss: 0.7857 Train_dice: 0.2143\n",
      "134/179, Train_loss: 0.8884 Train_dice: 0.1116\n",
      "135/179, Train_loss: 0.7928 Train_dice: 0.2072\n",
      "136/179, Train_loss: 0.8381 Train_dice: 0.1619\n",
      "137/179, Train_loss: 0.7883 Train_dice: 0.2117\n",
      "138/179, Train_loss: 0.7278 Train_dice: 0.2722\n",
      "139/179, Train_loss: 0.6280 Train_dice: 0.3720\n",
      "140/179, Train_loss: 0.7997 Train_dice: 0.2003\n",
      "141/179, Train_loss: 0.7055 Train_dice: 0.2945\n",
      "142/179, Train_loss: 0.8365 Train_dice: 0.1635\n",
      "143/179, Train_loss: 0.6698 Train_dice: 0.3302\n",
      "144/179, Train_loss: 0.7778 Train_dice: 0.2222\n",
      "145/179, Train_loss: 0.8643 Train_dice: 0.1357\n",
      "146/179, Train_loss: 0.7773 Train_dice: 0.2227\n",
      "147/179, Train_loss: 0.6268 Train_dice: 0.3732\n",
      "148/179, Train_loss: 0.8270 Train_dice: 0.1730\n",
      "149/179, Train_loss: 0.7559 Train_dice: 0.2441\n",
      "150/179, Train_loss: 0.8310 Train_dice: 0.1690\n",
      "151/179, Train_loss: 0.7846 Train_dice: 0.2154\n",
      "152/179, Train_loss: 0.6528 Train_dice: 0.3472\n",
      "153/179, Train_loss: 0.8518 Train_dice: 0.1482\n",
      "154/179, Train_loss: 0.7682 Train_dice: 0.2318\n",
      "155/179, Train_loss: 0.6738 Train_dice: 0.3262\n",
      "156/179, Train_loss: 0.7688 Train_dice: 0.2312\n",
      "157/179, Train_loss: 0.6385 Train_dice: 0.3615\n",
      "158/179, Train_loss: 0.8724 Train_dice: 0.1276\n",
      "159/179, Train_loss: 0.7462 Train_dice: 0.2538\n",
      "160/179, Train_loss: 0.7307 Train_dice: 0.2693\n",
      "161/179, Train_loss: 0.7894 Train_dice: 0.2106\n",
      "162/179, Train_loss: 0.5928 Train_dice: 0.4072\n",
      "163/179, Train_loss: 0.6473 Train_dice: 0.3527\n",
      "164/179, Train_loss: 0.5034 Train_dice: 0.4966\n",
      "165/179, Train_loss: 0.8013 Train_dice: 0.1987\n",
      "166/179, Train_loss: 0.8315 Train_dice: 0.1685\n",
      "167/179, Train_loss: 0.3376 Train_dice: 0.6624\n",
      "168/179, Train_loss: 0.5865 Train_dice: 0.4135\n",
      "169/179, Train_loss: 0.4387 Train_dice: 0.5613\n",
      "170/179, Train_loss: 0.4187 Train_dice: 0.5813\n",
      "171/179, Train_loss: 0.3848 Train_dice: 0.6152\n",
      "172/179, Train_loss: 0.4115 Train_dice: 0.5885\n",
      "173/179, Train_loss: 0.3717 Train_dice: 0.6283\n",
      "174/179, Train_loss: 0.4236 Train_dice: 0.5764\n",
      "175/179, Train_loss: 0.4461 Train_dice: 0.5539\n",
      "176/179, Train_loss: 0.4121 Train_dice: 0.5879\n",
      "177/179, Train_loss: 0.3463 Train_dice: 0.6537\n",
      "178/179, Train_loss: 0.4716 Train_dice: 0.5284\n",
      "179/179, Train_loss: 0.3909 Train_dice: 0.6091\n",
      "--------------------\n",
      "Epoch_loss: 0.7182\n",
      "Epoch_metric: 0.2818\n",
      "----------\n",
      "epoch 4/20\n",
      "1/179, Train_loss: 0.8084 Train_dice: 0.1916\n",
      "2/179, Train_loss: 0.8485 Train_dice: 0.1515\n",
      "3/179, Train_loss: 0.8720 Train_dice: 0.1280\n",
      "4/179, Train_loss: 0.6252 Train_dice: 0.3748\n",
      "5/179, Train_loss: 0.6500 Train_dice: 0.3500\n",
      "6/179, Train_loss: 0.8307 Train_dice: 0.1693\n",
      "7/179, Train_loss: 0.7419 Train_dice: 0.2581\n",
      "8/179, Train_loss: 0.6913 Train_dice: 0.3087\n",
      "9/179, Train_loss: 0.7600 Train_dice: 0.2400\n",
      "10/179, Train_loss: 0.7089 Train_dice: 0.2911\n",
      "11/179, Train_loss: 0.8368 Train_dice: 0.1632\n",
      "12/179, Train_loss: 0.8520 Train_dice: 0.1480\n",
      "13/179, Train_loss: 0.7840 Train_dice: 0.2160\n",
      "14/179, Train_loss: 0.6727 Train_dice: 0.3273\n",
      "15/179, Train_loss: 0.8769 Train_dice: 0.1231\n",
      "16/179, Train_loss: 0.7448 Train_dice: 0.2552\n",
      "17/179, Train_loss: 0.6467 Train_dice: 0.3533\n",
      "18/179, Train_loss: 0.8512 Train_dice: 0.1488\n",
      "19/179, Train_loss: 0.7421 Train_dice: 0.2579\n",
      "20/179, Train_loss: 0.8178 Train_dice: 0.1822\n",
      "21/179, Train_loss: 0.7263 Train_dice: 0.2737\n",
      "22/179, Train_loss: 0.7463 Train_dice: 0.2537\n",
      "23/179, Train_loss: 0.7072 Train_dice: 0.2928\n",
      "24/179, Train_loss: 0.8284 Train_dice: 0.1716\n",
      "25/179, Train_loss: 0.7678 Train_dice: 0.2322\n",
      "26/179, Train_loss: 0.6628 Train_dice: 0.3372\n",
      "27/179, Train_loss: 0.7418 Train_dice: 0.2582\n",
      "28/179, Train_loss: 0.6381 Train_dice: 0.3619\n",
      "29/179, Train_loss: 0.7667 Train_dice: 0.2333\n",
      "30/179, Train_loss: 0.7110 Train_dice: 0.2890\n",
      "31/179, Train_loss: 0.8578 Train_dice: 0.1422\n",
      "32/179, Train_loss: 0.8127 Train_dice: 0.1873\n",
      "33/179, Train_loss: 0.6678 Train_dice: 0.3322\n",
      "34/179, Train_loss: 0.7254 Train_dice: 0.2746\n",
      "35/179, Train_loss: 0.7220 Train_dice: 0.2780\n",
      "36/179, Train_loss: 0.6927 Train_dice: 0.3073\n",
      "37/179, Train_loss: 0.7004 Train_dice: 0.2996\n",
      "38/179, Train_loss: 0.8250 Train_dice: 0.1750\n",
      "39/179, Train_loss: 0.7792 Train_dice: 0.2208\n",
      "40/179, Train_loss: 0.6443 Train_dice: 0.3557\n",
      "41/179, Train_loss: 0.7454 Train_dice: 0.2546\n",
      "42/179, Train_loss: 0.7177 Train_dice: 0.2823\n",
      "43/179, Train_loss: 0.6061 Train_dice: 0.3939\n",
      "44/179, Train_loss: 0.6241 Train_dice: 0.3759\n",
      "45/179, Train_loss: 0.6760 Train_dice: 0.3240\n",
      "46/179, Train_loss: 0.6158 Train_dice: 0.3842\n",
      "47/179, Train_loss: 0.8522 Train_dice: 0.1478\n",
      "48/179, Train_loss: 0.6693 Train_dice: 0.3307\n",
      "49/179, Train_loss: 0.7849 Train_dice: 0.2151\n",
      "50/179, Train_loss: 0.7995 Train_dice: 0.2005\n",
      "51/179, Train_loss: 0.6022 Train_dice: 0.3978\n",
      "52/179, Train_loss: 0.8086 Train_dice: 0.1914\n",
      "53/179, Train_loss: 0.5697 Train_dice: 0.4303\n",
      "54/179, Train_loss: 0.7367 Train_dice: 0.2633\n",
      "55/179, Train_loss: 0.6971 Train_dice: 0.3029\n",
      "56/179, Train_loss: 0.7313 Train_dice: 0.2687\n",
      "57/179, Train_loss: 0.6879 Train_dice: 0.3121\n",
      "58/179, Train_loss: 0.6770 Train_dice: 0.3230\n",
      "59/179, Train_loss: 0.4832 Train_dice: 0.5168\n",
      "60/179, Train_loss: 0.7056 Train_dice: 0.2944\n",
      "61/179, Train_loss: 0.5150 Train_dice: 0.4850\n",
      "62/179, Train_loss: 0.6764 Train_dice: 0.3236\n",
      "63/179, Train_loss: 0.8077 Train_dice: 0.1923\n",
      "64/179, Train_loss: 0.6920 Train_dice: 0.3080\n",
      "65/179, Train_loss: 0.6011 Train_dice: 0.3989\n",
      "66/179, Train_loss: 0.7893 Train_dice: 0.2107\n",
      "67/179, Train_loss: 0.6377 Train_dice: 0.3623\n",
      "68/179, Train_loss: 0.7790 Train_dice: 0.2210\n",
      "69/179, Train_loss: 0.6691 Train_dice: 0.3309\n",
      "70/179, Train_loss: 0.8684 Train_dice: 0.1316\n",
      "71/179, Train_loss: 0.5893 Train_dice: 0.4107\n",
      "72/179, Train_loss: 0.8377 Train_dice: 0.1623\n",
      "73/179, Train_loss: 0.7265 Train_dice: 0.2735\n",
      "74/179, Train_loss: 0.6918 Train_dice: 0.3082\n",
      "75/179, Train_loss: 0.7393 Train_dice: 0.2607\n",
      "76/179, Train_loss: 0.4688 Train_dice: 0.5312\n",
      "77/179, Train_loss: 0.8293 Train_dice: 0.1707\n",
      "78/179, Train_loss: 0.7964 Train_dice: 0.2036\n",
      "79/179, Train_loss: 0.8366 Train_dice: 0.1634\n",
      "80/179, Train_loss: 0.6982 Train_dice: 0.3018\n",
      "81/179, Train_loss: 0.6034 Train_dice: 0.3966\n",
      "82/179, Train_loss: 0.6808 Train_dice: 0.3192\n",
      "83/179, Train_loss: 0.7932 Train_dice: 0.2068\n",
      "84/179, Train_loss: 0.8667 Train_dice: 0.1333\n",
      "85/179, Train_loss: 0.7662 Train_dice: 0.2338\n",
      "86/179, Train_loss: 0.6696 Train_dice: 0.3304\n",
      "87/179, Train_loss: 0.6988 Train_dice: 0.3012\n",
      "88/179, Train_loss: 0.7932 Train_dice: 0.2068\n",
      "89/179, Train_loss: 0.6432 Train_dice: 0.3568\n",
      "90/179, Train_loss: 0.6612 Train_dice: 0.3388\n",
      "91/179, Train_loss: 0.7413 Train_dice: 0.2587\n",
      "92/179, Train_loss: 0.7558 Train_dice: 0.2442\n",
      "93/179, Train_loss: 0.8367 Train_dice: 0.1633\n",
      "94/179, Train_loss: 0.7982 Train_dice: 0.2018\n",
      "95/179, Train_loss: 0.8736 Train_dice: 0.1264\n",
      "96/179, Train_loss: 0.7525 Train_dice: 0.2475\n",
      "97/179, Train_loss: 0.7156 Train_dice: 0.2844\n",
      "98/179, Train_loss: 0.8245 Train_dice: 0.1755\n",
      "99/179, Train_loss: 0.6546 Train_dice: 0.3454\n",
      "100/179, Train_loss: 0.6740 Train_dice: 0.3260\n",
      "101/179, Train_loss: 0.7534 Train_dice: 0.2466\n",
      "102/179, Train_loss: 0.7353 Train_dice: 0.2647\n",
      "103/179, Train_loss: 0.7122 Train_dice: 0.2878\n",
      "104/179, Train_loss: 0.7564 Train_dice: 0.2436\n",
      "105/179, Train_loss: 0.7185 Train_dice: 0.2815\n",
      "106/179, Train_loss: 0.7570 Train_dice: 0.2430\n",
      "107/179, Train_loss: 0.7626 Train_dice: 0.2374\n",
      "108/179, Train_loss: 0.5858 Train_dice: 0.4142\n",
      "109/179, Train_loss: 0.7497 Train_dice: 0.2503\n",
      "110/179, Train_loss: 0.8370 Train_dice: 0.1630\n",
      "111/179, Train_loss: 0.7134 Train_dice: 0.2866\n",
      "112/179, Train_loss: 0.8412 Train_dice: 0.1588\n",
      "113/179, Train_loss: 0.7166 Train_dice: 0.2834\n",
      "114/179, Train_loss: 0.7614 Train_dice: 0.2386\n",
      "115/179, Train_loss: 0.8075 Train_dice: 0.1925\n",
      "116/179, Train_loss: 0.8722 Train_dice: 0.1278\n",
      "117/179, Train_loss: 0.7587 Train_dice: 0.2413\n",
      "118/179, Train_loss: 0.8473 Train_dice: 0.1527\n",
      "119/179, Train_loss: 0.7760 Train_dice: 0.2240\n",
      "120/179, Train_loss: 0.7054 Train_dice: 0.2946\n",
      "121/179, Train_loss: 0.6549 Train_dice: 0.3451\n",
      "122/179, Train_loss: 0.6837 Train_dice: 0.3163\n",
      "123/179, Train_loss: 0.7394 Train_dice: 0.2606\n",
      "124/179, Train_loss: 0.7950 Train_dice: 0.2050\n",
      "125/179, Train_loss: 0.6107 Train_dice: 0.3893\n",
      "126/179, Train_loss: 0.8383 Train_dice: 0.1617\n",
      "127/179, Train_loss: 0.7402 Train_dice: 0.2598\n",
      "128/179, Train_loss: 0.8046 Train_dice: 0.1954\n",
      "129/179, Train_loss: 0.8866 Train_dice: 0.1134\n",
      "130/179, Train_loss: 0.8266 Train_dice: 0.1734\n",
      "131/179, Train_loss: 0.6389 Train_dice: 0.3611\n",
      "132/179, Train_loss: 0.8275 Train_dice: 0.1725\n",
      "133/179, Train_loss: 0.7842 Train_dice: 0.2158\n",
      "134/179, Train_loss: 0.8868 Train_dice: 0.1132\n",
      "135/179, Train_loss: 0.7906 Train_dice: 0.2094\n",
      "136/179, Train_loss: 0.8360 Train_dice: 0.1640\n",
      "137/179, Train_loss: 0.7863 Train_dice: 0.2137\n",
      "138/179, Train_loss: 0.7242 Train_dice: 0.2758\n",
      "139/179, Train_loss: 0.6211 Train_dice: 0.3789\n",
      "140/179, Train_loss: 0.7974 Train_dice: 0.2026\n",
      "141/179, Train_loss: 0.7018 Train_dice: 0.2982\n",
      "142/179, Train_loss: 0.8347 Train_dice: 0.1653\n",
      "143/179, Train_loss: 0.6653 Train_dice: 0.3347\n",
      "144/179, Train_loss: 0.7743 Train_dice: 0.2257\n",
      "145/179, Train_loss: 0.8630 Train_dice: 0.1370\n",
      "146/179, Train_loss: 0.7745 Train_dice: 0.2255\n",
      "147/179, Train_loss: 0.6205 Train_dice: 0.3795\n",
      "148/179, Train_loss: 0.8244 Train_dice: 0.1756\n",
      "149/179, Train_loss: 0.7531 Train_dice: 0.2469\n",
      "150/179, Train_loss: 0.8294 Train_dice: 0.1706\n",
      "151/179, Train_loss: 0.7819 Train_dice: 0.2181\n",
      "152/179, Train_loss: 0.6481 Train_dice: 0.3519\n",
      "153/179, Train_loss: 0.8498 Train_dice: 0.1502\n",
      "154/179, Train_loss: 0.7659 Train_dice: 0.2341\n",
      "155/179, Train_loss: 0.6701 Train_dice: 0.3299\n",
      "156/179, Train_loss: 0.7663 Train_dice: 0.2337\n",
      "157/179, Train_loss: 0.6338 Train_dice: 0.3662\n",
      "158/179, Train_loss: 0.8701 Train_dice: 0.1299\n",
      "159/179, Train_loss: 0.7429 Train_dice: 0.2571\n",
      "160/179, Train_loss: 0.7272 Train_dice: 0.2728\n",
      "161/179, Train_loss: 0.7874 Train_dice: 0.2126\n",
      "162/179, Train_loss: 0.5877 Train_dice: 0.4123\n",
      "163/179, Train_loss: 0.6435 Train_dice: 0.3565\n",
      "164/179, Train_loss: 0.5021 Train_dice: 0.4979\n",
      "165/179, Train_loss: 0.7991 Train_dice: 0.2009\n",
      "166/179, Train_loss: 0.8279 Train_dice: 0.1721\n",
      "167/179, Train_loss: 0.3362 Train_dice: 0.6638\n",
      "168/179, Train_loss: 0.5817 Train_dice: 0.4183\n",
      "169/179, Train_loss: 0.4239 Train_dice: 0.5761\n",
      "170/179, Train_loss: 0.4178 Train_dice: 0.5822\n",
      "171/179, Train_loss: 0.3856 Train_dice: 0.6144\n",
      "172/179, Train_loss: 0.4099 Train_dice: 0.5901\n",
      "173/179, Train_loss: 0.3636 Train_dice: 0.6364\n",
      "174/179, Train_loss: 0.3995 Train_dice: 0.6005\n",
      "175/179, Train_loss: 0.4254 Train_dice: 0.5746\n",
      "176/179, Train_loss: 0.4045 Train_dice: 0.5955\n",
      "177/179, Train_loss: 0.3340 Train_dice: 0.6660\n",
      "178/179, Train_loss: 0.4640 Train_dice: 0.5360\n",
      "179/179, Train_loss: 0.3872 Train_dice: 0.6128\n",
      "--------------------\n",
      "Epoch_loss: 0.7148\n",
      "Epoch_metric: 0.2852\n",
      "----------\n",
      "epoch 5/20\n",
      "1/179, Train_loss: 0.8058 Train_dice: 0.1942\n",
      "2/179, Train_loss: 0.8457 Train_dice: 0.1543\n",
      "3/179, Train_loss: 0.8705 Train_dice: 0.1295\n",
      "4/179, Train_loss: 0.6053 Train_dice: 0.3947\n",
      "5/179, Train_loss: 0.6430 Train_dice: 0.3570\n",
      "6/179, Train_loss: 0.8300 Train_dice: 0.1700\n",
      "7/179, Train_loss: 0.7432 Train_dice: 0.2568\n",
      "8/179, Train_loss: 0.6907 Train_dice: 0.3093\n",
      "9/179, Train_loss: 0.7604 Train_dice: 0.2396\n",
      "10/179, Train_loss: 0.7080 Train_dice: 0.2920\n",
      "11/179, Train_loss: 0.8359 Train_dice: 0.1641\n",
      "12/179, Train_loss: 0.8511 Train_dice: 0.1489\n",
      "13/179, Train_loss: 0.7783 Train_dice: 0.2217\n",
      "14/179, Train_loss: 0.6692 Train_dice: 0.3308\n",
      "15/179, Train_loss: 0.8736 Train_dice: 0.1264\n",
      "16/179, Train_loss: 0.7423 Train_dice: 0.2577\n",
      "17/179, Train_loss: 0.6370 Train_dice: 0.3630\n",
      "18/179, Train_loss: 0.8483 Train_dice: 0.1517\n",
      "19/179, Train_loss: 0.7393 Train_dice: 0.2607\n",
      "20/179, Train_loss: 0.8145 Train_dice: 0.1855\n",
      "21/179, Train_loss: 0.7220 Train_dice: 0.2780\n",
      "22/179, Train_loss: 0.7436 Train_dice: 0.2564\n",
      "23/179, Train_loss: 0.7002 Train_dice: 0.2998\n",
      "24/179, Train_loss: 0.8242 Train_dice: 0.1758\n",
      "25/179, Train_loss: 0.7641 Train_dice: 0.2359\n",
      "26/179, Train_loss: 0.6569 Train_dice: 0.3431\n",
      "27/179, Train_loss: 0.7395 Train_dice: 0.2605\n",
      "28/179, Train_loss: 0.6318 Train_dice: 0.3682\n",
      "29/179, Train_loss: 0.7633 Train_dice: 0.2367\n",
      "30/179, Train_loss: 0.7063 Train_dice: 0.2937\n",
      "31/179, Train_loss: 0.8557 Train_dice: 0.1443\n",
      "32/179, Train_loss: 0.8098 Train_dice: 0.1902\n",
      "33/179, Train_loss: 0.6643 Train_dice: 0.3357\n",
      "34/179, Train_loss: 0.7202 Train_dice: 0.2798\n",
      "35/179, Train_loss: 0.7196 Train_dice: 0.2804\n",
      "36/179, Train_loss: 0.6879 Train_dice: 0.3121\n",
      "37/179, Train_loss: 0.6961 Train_dice: 0.3039\n",
      "38/179, Train_loss: 0.8223 Train_dice: 0.1777\n",
      "39/179, Train_loss: 0.7762 Train_dice: 0.2238\n",
      "40/179, Train_loss: 0.6399 Train_dice: 0.3601\n",
      "41/179, Train_loss: 0.7404 Train_dice: 0.2596\n",
      "42/179, Train_loss: 0.7141 Train_dice: 0.2859\n",
      "43/179, Train_loss: 0.6015 Train_dice: 0.3985\n",
      "44/179, Train_loss: 0.6206 Train_dice: 0.3794\n",
      "45/179, Train_loss: 0.6730 Train_dice: 0.3270\n",
      "46/179, Train_loss: 0.6110 Train_dice: 0.3890\n",
      "47/179, Train_loss: 0.8511 Train_dice: 0.1489\n",
      "48/179, Train_loss: 0.6655 Train_dice: 0.3345\n",
      "49/179, Train_loss: 0.7811 Train_dice: 0.2189\n",
      "50/179, Train_loss: 0.7966 Train_dice: 0.2034\n",
      "51/179, Train_loss: 0.5976 Train_dice: 0.4024\n",
      "52/179, Train_loss: 0.8062 Train_dice: 0.1938\n",
      "53/179, Train_loss: 0.5642 Train_dice: 0.4358\n",
      "54/179, Train_loss: 0.7335 Train_dice: 0.2665\n",
      "55/179, Train_loss: 0.6937 Train_dice: 0.3063\n",
      "56/179, Train_loss: 0.7287 Train_dice: 0.2713\n",
      "57/179, Train_loss: 0.6846 Train_dice: 0.3154\n",
      "58/179, Train_loss: 0.6734 Train_dice: 0.3266\n",
      "59/179, Train_loss: 0.4789 Train_dice: 0.5211\n",
      "60/179, Train_loss: 0.7025 Train_dice: 0.2975\n",
      "61/179, Train_loss: 0.5097 Train_dice: 0.4903\n",
      "62/179, Train_loss: 0.6730 Train_dice: 0.3270\n",
      "63/179, Train_loss: 0.8057 Train_dice: 0.1943\n",
      "64/179, Train_loss: 0.6885 Train_dice: 0.3115\n",
      "65/179, Train_loss: 0.5949 Train_dice: 0.4051\n",
      "66/179, Train_loss: 0.7864 Train_dice: 0.2136\n",
      "67/179, Train_loss: 0.6341 Train_dice: 0.3659\n",
      "68/179, Train_loss: 0.7766 Train_dice: 0.2234\n",
      "69/179, Train_loss: 0.6654 Train_dice: 0.3346\n",
      "70/179, Train_loss: 0.8673 Train_dice: 0.1327\n",
      "71/179, Train_loss: 0.5845 Train_dice: 0.4155\n",
      "72/179, Train_loss: 0.8360 Train_dice: 0.1640\n",
      "73/179, Train_loss: 0.7234 Train_dice: 0.2766\n",
      "74/179, Train_loss: 0.6886 Train_dice: 0.3114\n",
      "75/179, Train_loss: 0.7362 Train_dice: 0.2638\n",
      "76/179, Train_loss: 0.4613 Train_dice: 0.5387\n",
      "77/179, Train_loss: 0.8272 Train_dice: 0.1728\n",
      "78/179, Train_loss: 0.7947 Train_dice: 0.2053\n",
      "79/179, Train_loss: 0.8350 Train_dice: 0.1650\n",
      "80/179, Train_loss: 0.6947 Train_dice: 0.3053\n",
      "81/179, Train_loss: 0.5990 Train_dice: 0.4010\n",
      "82/179, Train_loss: 0.6772 Train_dice: 0.3228\n",
      "83/179, Train_loss: 0.7907 Train_dice: 0.2093\n",
      "84/179, Train_loss: 0.8647 Train_dice: 0.1353\n",
      "85/179, Train_loss: 0.7637 Train_dice: 0.2363\n",
      "86/179, Train_loss: 0.6662 Train_dice: 0.3338\n",
      "87/179, Train_loss: 0.6957 Train_dice: 0.3043\n",
      "88/179, Train_loss: 0.7911 Train_dice: 0.2089\n",
      "89/179, Train_loss: 0.6396 Train_dice: 0.3604\n",
      "90/179, Train_loss: 0.6573 Train_dice: 0.3427\n",
      "91/179, Train_loss: 0.7387 Train_dice: 0.2613\n",
      "92/179, Train_loss: 0.7537 Train_dice: 0.2463\n",
      "93/179, Train_loss: 0.8344 Train_dice: 0.1656\n",
      "94/179, Train_loss: 0.7960 Train_dice: 0.2040\n",
      "95/179, Train_loss: 0.8725 Train_dice: 0.1275\n",
      "96/179, Train_loss: 0.7495 Train_dice: 0.2505\n",
      "97/179, Train_loss: 0.7126 Train_dice: 0.2874\n",
      "98/179, Train_loss: 0.8224 Train_dice: 0.1776\n",
      "99/179, Train_loss: 0.6505 Train_dice: 0.3495\n",
      "100/179, Train_loss: 0.6710 Train_dice: 0.3290\n",
      "101/179, Train_loss: 0.7507 Train_dice: 0.2493\n",
      "102/179, Train_loss: 0.7324 Train_dice: 0.2676\n",
      "103/179, Train_loss: 0.7089 Train_dice: 0.2911\n",
      "104/179, Train_loss: 0.7539 Train_dice: 0.2461\n",
      "105/179, Train_loss: 0.7156 Train_dice: 0.2844\n",
      "106/179, Train_loss: 0.7545 Train_dice: 0.2455\n",
      "107/179, Train_loss: 0.7603 Train_dice: 0.2397\n",
      "108/179, Train_loss: 0.5809 Train_dice: 0.4191\n",
      "109/179, Train_loss: 0.7473 Train_dice: 0.2527\n",
      "110/179, Train_loss: 0.8352 Train_dice: 0.1648\n",
      "111/179, Train_loss: 0.7104 Train_dice: 0.2896\n",
      "112/179, Train_loss: 0.8396 Train_dice: 0.1604\n",
      "113/179, Train_loss: 0.7130 Train_dice: 0.2870\n",
      "114/179, Train_loss: 0.7588 Train_dice: 0.2412\n",
      "115/179, Train_loss: 0.8041 Train_dice: 0.1959\n",
      "116/179, Train_loss: 0.8705 Train_dice: 0.1295\n",
      "117/179, Train_loss: 0.7552 Train_dice: 0.2448\n",
      "118/179, Train_loss: 0.8459 Train_dice: 0.1541\n",
      "119/179, Train_loss: 0.7739 Train_dice: 0.2261\n",
      "120/179, Train_loss: 0.7022 Train_dice: 0.2978\n",
      "121/179, Train_loss: 0.6505 Train_dice: 0.3495\n",
      "122/179, Train_loss: 0.6800 Train_dice: 0.3200\n",
      "123/179, Train_loss: 0.7356 Train_dice: 0.2644\n",
      "124/179, Train_loss: 0.7929 Train_dice: 0.2071\n",
      "125/179, Train_loss: 0.6060 Train_dice: 0.3940\n",
      "126/179, Train_loss: 0.8357 Train_dice: 0.1643\n",
      "127/179, Train_loss: 0.7374 Train_dice: 0.2626\n",
      "128/179, Train_loss: 0.8026 Train_dice: 0.1974\n",
      "129/179, Train_loss: 0.8852 Train_dice: 0.1148\n",
      "130/179, Train_loss: 0.8250 Train_dice: 0.1750\n",
      "131/179, Train_loss: 0.6354 Train_dice: 0.3646\n",
      "132/179, Train_loss: 0.8261 Train_dice: 0.1739\n",
      "133/179, Train_loss: 0.7824 Train_dice: 0.2176\n",
      "134/179, Train_loss: 0.8857 Train_dice: 0.1143\n",
      "135/179, Train_loss: 0.7886 Train_dice: 0.2114\n",
      "136/179, Train_loss: 0.8343 Train_dice: 0.1657\n",
      "137/179, Train_loss: 0.7846 Train_dice: 0.2154\n",
      "138/179, Train_loss: 0.7210 Train_dice: 0.2790\n",
      "139/179, Train_loss: 0.6174 Train_dice: 0.3826\n",
      "140/179, Train_loss: 0.7955 Train_dice: 0.2045\n",
      "141/179, Train_loss: 0.6989 Train_dice: 0.3011\n",
      "142/179, Train_loss: 0.8332 Train_dice: 0.1668\n",
      "143/179, Train_loss: 0.6622 Train_dice: 0.3378\n",
      "144/179, Train_loss: 0.7724 Train_dice: 0.2276\n",
      "145/179, Train_loss: 0.8618 Train_dice: 0.1382\n",
      "146/179, Train_loss: 0.7724 Train_dice: 0.2276\n",
      "147/179, Train_loss: 0.6166 Train_dice: 0.3834\n",
      "148/179, Train_loss: 0.8219 Train_dice: 0.1781\n",
      "149/179, Train_loss: 0.7509 Train_dice: 0.2491\n",
      "150/179, Train_loss: 0.8277 Train_dice: 0.1723\n",
      "151/179, Train_loss: 0.7799 Train_dice: 0.2201\n",
      "152/179, Train_loss: 0.6429 Train_dice: 0.3571\n",
      "153/179, Train_loss: 0.8481 Train_dice: 0.1519\n",
      "154/179, Train_loss: 0.7632 Train_dice: 0.2368\n",
      "155/179, Train_loss: 0.6671 Train_dice: 0.3329\n",
      "156/179, Train_loss: 0.7637 Train_dice: 0.2363\n",
      "157/179, Train_loss: 0.6302 Train_dice: 0.3698\n",
      "158/179, Train_loss: 0.8685 Train_dice: 0.1315\n",
      "159/179, Train_loss: 0.7397 Train_dice: 0.2603\n",
      "160/179, Train_loss: 0.7246 Train_dice: 0.2754\n",
      "161/179, Train_loss: 0.7853 Train_dice: 0.2147\n",
      "162/179, Train_loss: 0.5839 Train_dice: 0.4161\n",
      "163/179, Train_loss: 0.6397 Train_dice: 0.3603\n",
      "164/179, Train_loss: 0.4996 Train_dice: 0.5004\n",
      "165/179, Train_loss: 0.7974 Train_dice: 0.2026\n",
      "166/179, Train_loss: 0.8261 Train_dice: 0.1739\n",
      "167/179, Train_loss: 0.3361 Train_dice: 0.6639\n",
      "168/179, Train_loss: 0.5781 Train_dice: 0.4219\n",
      "169/179, Train_loss: 0.4027 Train_dice: 0.5973\n",
      "170/179, Train_loss: 0.4182 Train_dice: 0.5818\n",
      "171/179, Train_loss: 0.3864 Train_dice: 0.6136\n",
      "172/179, Train_loss: 0.4107 Train_dice: 0.5893\n",
      "173/179, Train_loss: 0.3572 Train_dice: 0.6428\n",
      "174/179, Train_loss: 0.3764 Train_dice: 0.6236\n",
      "175/179, Train_loss: 0.4109 Train_dice: 0.5891\n",
      "176/179, Train_loss: 0.3976 Train_dice: 0.6024\n",
      "177/179, Train_loss: 0.3289 Train_dice: 0.6711\n",
      "178/179, Train_loss: 0.4635 Train_dice: 0.5365\n",
      "179/179, Train_loss: 0.3854 Train_dice: 0.6146\n",
      "--------------------\n",
      "Epoch_loss: 0.7114\n",
      "Epoch_metric: 0.2886\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'jaccard' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(unet, data_in, loss_function, optimizer, \u001b[39m20\u001b[39;49m, model_dir, test_interval\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,start_from\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\envy\\Desktop\\Prostate_MRI\\Prostate_MRI_Detection_3D_Model\\utils\\train.py:160\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_in, loss, optim, max_epochs, model_dir, test_interval, device, start_from, load_from)\u001b[0m\n\u001b[0;32m    157\u001b[0m     test_metric \u001b[39m=\u001b[39m dice_metric(test_outputs, test_label)\n\u001b[0;32m    158\u001b[0m     epoch_metric_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m test_metric\n\u001b[1;32m--> 160\u001b[0m     jaccard_val \u001b[39m=\u001b[39m jaccard(test_outputs, test_label)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    161\u001b[0m     epoch_jaccard_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m jaccard_val\n\u001b[0;32m    163\u001b[0m test_epoch_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m test_step\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'jaccard' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train(unet, data_in, loss_function, optimizer, 20, model_dir, test_interval=5,start_from=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
